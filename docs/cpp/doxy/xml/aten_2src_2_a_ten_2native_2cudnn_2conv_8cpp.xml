<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.14">
  <compounddef id="aten_2src_2_a_ten_2native_2cudnn_2conv_8cpp" kind="file" language="C++">
    <compoundname>Conv.cpp</compoundname>
    <includes refid="_a_ten_8h" local="no">ATen/ATen.h</includes>
    <includes local="no">ATen/NativeFunctions.h</includes>
    <includes refid="_config_8h" local="no">ATen/Config.h</includes>
    <includes refid="_c_u_d_a_config_8h" local="no">ATen/cuda/CUDAConfig.h</includes>
    <includes refid="cuda_2_exceptions_8h" local="no">ATen/cuda/Exceptions.h</includes>
    <incdepgraph>
      <node id="18186">
        <label>ATen/optional.h</label>
        <link refid="optional_8h_source"/>
        <childnode refid="18187" relation="include">
        </childnode>
        <childnode refid="18188" relation="include">
        </childnode>
        <childnode refid="18189" relation="include">
        </childnode>
        <childnode refid="18190" relation="include">
        </childnode>
        <childnode refid="18191" relation="include">
        </childnode>
        <childnode refid="18192" relation="include">
        </childnode>
        <childnode refid="18193" relation="include">
        </childnode>
      </node>
      <node id="18232">
        <label>ATen/detail/CUDAHooksInterface.h</label>
        <link refid="_c_u_d_a_hooks_interface_8h_source"/>
        <childnode refid="18182" relation="include">
        </childnode>
        <childnode refid="18185" relation="include">
        </childnode>
        <childnode refid="18230" relation="include">
        </childnode>
        <childnode refid="18233" relation="include">
        </childnode>
        <childnode refid="18194" relation="include">
        </childnode>
        <childnode refid="18191" relation="include">
        </childnode>
        <childnode refid="18183" relation="include">
        </childnode>
      </node>
      <node id="18200">
        <label>ATen/Device.h</label>
        <link refid="_device_8h_source"/>
        <childnode refid="18185" relation="include">
        </childnode>
        <childnode refid="18201" relation="include">
        </childnode>
        <childnode refid="18194" relation="include">
        </childnode>
        <childnode refid="18216" relation="include">
        </childnode>
        <childnode refid="18192" relation="include">
        </childnode>
        <childnode refid="18191" relation="include">
        </childnode>
      </node>
      <node id="18199">
        <label>atomic</label>
      </node>
      <node id="18191">
        <label>functional</label>
      </node>
      <node id="18237">
        <label>ATen/Backtrace.h</label>
        <link refid="_backtrace_8h_source"/>
        <childnode refid="18194" relation="include">
        </childnode>
        <childnode refid="18192" relation="include">
        </childnode>
        <childnode refid="18227" relation="include">
        </childnode>
        <childnode refid="18180" relation="include">
        </childnode>
      </node>
      <node id="18201">
        <label>ATen/ScalarType.h</label>
        <link refid="_scalar_type_8h_source"/>
        <childnode refid="18202" relation="include">
        </childnode>
        <childnode refid="18180" relation="include">
        </childnode>
        <childnode refid="18212" relation="include">
        </childnode>
        <childnode refid="18214" relation="include">
        </childnode>
        <childnode refid="18218" relation="include">
        </childnode>
      </node>
      <node id="18213">
        <label>limits</label>
      </node>
      <node id="18221">
        <label>assert.h</label>
      </node>
      <node id="18226">
        <label>ATen/Utils.h</label>
        <link refid="aten_2src_2_a_ten_2utils_8h_source"/>
        <childnode refid="18180" relation="include">
        </childnode>
        <childnode refid="18202" relation="include">
        </childnode>
        <childnode refid="18185" relation="include">
        </childnode>
        <childnode refid="18225" relation="include">
        </childnode>
        <childnode refid="18205" relation="include">
        </childnode>
        <childnode refid="18197" relation="include">
        </childnode>
        <childnode refid="18227" relation="include">
        </childnode>
        <childnode refid="18228" relation="include">
        </childnode>
      </node>
      <node id="18208">
        <label>iterator</label>
      </node>
      <node id="18220">
        <label>ATen/Scalar.h</label>
        <link refid="_scalar_8h_source"/>
        <childnode refid="18221" relation="include">
        </childnode>
        <childnode refid="18222" relation="include">
        </childnode>
        <childnode refid="18193" relation="include">
        </childnode>
        <childnode refid="18192" relation="include">
        </childnode>
        <childnode refid="18187" relation="include">
        </childnode>
        <childnode refid="18180" relation="include">
        </childnode>
        <childnode refid="18212" relation="include">
        </childnode>
        <childnode refid="18201" relation="include">
        </childnode>
        <childnode refid="18223" relation="include">
        </childnode>
        <childnode refid="18226" relation="include">
        </childnode>
      </node>
      <node id="18240">
        <label>TH/THStorageFunctions.hpp</label>
      </node>
      <node id="18214">
        <label>cstdint</label>
      </node>
      <node id="18248">
        <label>ATen/Deprecated.h</label>
        <link refid="_deprecated_8h_source"/>
      </node>
      <node id="18222">
        <label>stdint.h</label>
      </node>
      <node id="18259">
        <label>ATen/CUDAGuard.h</label>
        <link refid="_c_u_d_a_guard_8h_source"/>
      </node>
      <node id="18261">
        <label>ATen/cuda/CUDAConfig.h</label>
        <link refid="_c_u_d_a_config_8h_source"/>
      </node>
      <node id="18215">
        <label>cmath</label>
      </node>
      <node id="18190">
        <label>cassert</label>
      </node>
      <node id="18231">
        <label>ATen/Context.h</label>
        <link refid="_context_8h_source"/>
        <childnode refid="18180" relation="include">
        </childnode>
        <childnode refid="18181" relation="include">
        </childnode>
        <childnode refid="18230" relation="include">
        </childnode>
        <childnode refid="18229" relation="include">
        </childnode>
        <childnode refid="18226" relation="include">
        </childnode>
        <childnode refid="18185" relation="include">
        </childnode>
        <childnode refid="18232" relation="include">
        </childnode>
        <childnode refid="18238" relation="include">
        </childnode>
        <childnode refid="18183" relation="include">
        </childnode>
        <childnode refid="18235" relation="include">
        </childnode>
        <childnode refid="18214" relation="include">
        </childnode>
      </node>
      <node id="18217">
        <label>Half-inl.h</label>
        <link refid="_half-inl_8h_source"/>
        <childnode refid="18180" relation="include">
        </childnode>
        <childnode refid="18207" relation="include">
        </childnode>
        <childnode refid="18213" relation="include">
        </childnode>
      </node>
      <node id="18193">
        <label>stdexcept</label>
      </node>
      <node id="18254">
        <label>ATen/TensorOperators.h</label>
        <link refid="_tensor_operators_8h_source"/>
        <childnode refid="18220" relation="include">
        </childnode>
        <childnode refid="18241" relation="include">
        </childnode>
        <childnode refid="18229" relation="include">
        </childnode>
        <childnode refid="18192" relation="include">
        </childnode>
        <childnode refid="18193" relation="include">
        </childnode>
      </node>
      <node id="18228">
        <label>numeric</label>
      </node>
      <node id="18224">
        <label>ATen/TensorImpl.h</label>
        <link refid="_tensor_impl_8h_source"/>
        <childnode refid="18199" relation="include">
        </childnode>
        <childnode refid="18183" relation="include">
        </childnode>
        <childnode refid="18198" relation="include">
        </childnode>
        <childnode refid="18201" relation="include">
        </childnode>
        <childnode refid="18186" relation="include">
        </childnode>
      </node>
      <node id="18212">
        <label>ATen/Half.h</label>
        <link refid="_half_8h_source"/>
        <childnode refid="18180" relation="include">
        </childnode>
        <childnode refid="18213" relation="include">
        </childnode>
        <childnode refid="18192" relation="include">
        </childnode>
        <childnode refid="18214" relation="include">
        </childnode>
        <childnode refid="18193" relation="include">
        </childnode>
        <childnode refid="18187" relation="include">
        </childnode>
        <childnode refid="18215" relation="include">
        </childnode>
        <childnode refid="18216" relation="include">
        </childnode>
        <childnode refid="18217" relation="include">
        </childnode>
      </node>
      <node id="18198">
        <label>ATen/Retainable.h</label>
        <link refid="_retainable_8h_source"/>
        <childnode refid="18199" relation="include">
        </childnode>
      </node>
      <node id="18223">
        <label>ATen/TensorBase.h</label>
        <link refid="_tensor_base_8h_source"/>
        <childnode refid="18224" relation="include">
        </childnode>
        <childnode refid="18225" relation="include">
        </childnode>
      </node>
      <node id="18192">
        <label>string</label>
      </node>
      <node id="18262">
        <label>ATen/cuda/Exceptions.h</label>
        <link refid="cuda_2_exceptions_8h_source"/>
        <childnode refid="18185" relation="include">
        </childnode>
      </node>
      <node id="18257">
        <label>ATen/DimVector.h</label>
        <link refid="_dim_vector_8h_source"/>
        <childnode refid="18203" relation="include">
        </childnode>
        <childnode refid="18222" relation="include">
        </childnode>
      </node>
      <node id="18258">
        <label>ATen/OptionsGuard.h</label>
        <link refid="_options_guard_8h_source"/>
        <childnode refid="18200" relation="include">
        </childnode>
        <childnode refid="18244" relation="include">
        </childnode>
        <childnode refid="18201" relation="include">
        </childnode>
        <childnode refid="18251" relation="include">
        </childnode>
        <childnode refid="18186" relation="include">
        </childnode>
      </node>
      <node id="18260">
        <label>ATen/Config.h</label>
        <link refid="_config_8h_source"/>
      </node>
      <node id="18182">
        <label>ATen/Allocator.h</label>
        <link refid="_allocator_8h_source"/>
        <childnode refid="18183" relation="include">
        </childnode>
        <childnode refid="18184" relation="include">
        </childnode>
        <childnode refid="18185" relation="include">
        </childnode>
        <childnode refid="18198" relation="include">
        </childnode>
        <childnode refid="18200" relation="include">
        </childnode>
        <childnode refid="18219" relation="include">
        </childnode>
      </node>
      <node id="18238">
        <label>ATen/CUDAStream.h</label>
        <link refid="_c_u_d_a_stream_8h_source"/>
      </node>
      <node id="18250">
        <label>ATen/DeviceGuard.h</label>
        <link refid="_device_guard_8h_source"/>
        <childnode refid="18200" relation="include">
        </childnode>
        <childnode refid="18185" relation="include">
        </childnode>
        <childnode refid="18201" relation="include">
        </childnode>
        <childnode refid="18241" relation="include">
        </childnode>
        <childnode refid="18232" relation="include">
        </childnode>
        <childnode refid="18194" relation="include">
        </childnode>
      </node>
      <node id="18195">
        <label>exception</label>
      </node>
      <node id="18184">
        <label>stddef.h</label>
      </node>
      <node id="18225">
        <label>ATen/UndefinedTensor.h</label>
        <link refid="_undefined_tensor_8h_source"/>
        <childnode refid="18224" relation="include">
        </childnode>
      </node>
      <node id="18256">
        <label>ATen/Dispatch.h</label>
        <link refid="_dispatch_8h_source"/>
        <childnode refid="18185" relation="include">
        </childnode>
        <childnode refid="18212" relation="include">
        </childnode>
        <childnode refid="18229" relation="include">
        </childnode>
      </node>
      <node id="18204">
        <label>AlignOf.h</label>
        <link refid="_align_of_8h_source"/>
        <childnode refid="18194" relation="include">
        </childnode>
      </node>
      <node id="18239">
        <label>ATen/Storage.h</label>
        <link refid="_storage_8h_source"/>
        <childnode refid="18220" relation="include">
        </childnode>
        <childnode refid="18240" relation="include">
        </childnode>
      </node>
      <node id="18196">
        <label>ostream</label>
      </node>
      <node id="18181">
        <label>ATen/CPUGeneral.h</label>
        <link refid="_c_p_u_general_8h_source"/>
        <childnode refid="18180" relation="include">
        </childnode>
      </node>
      <node id="18229">
        <label>ATen/Type.h</label>
      </node>
      <node id="18178">
        <label>/Users/robkunkle/fork/goodlux/pytorch/aten/src/ATen/native/cudnn/Conv.cpp</label>
        <link refid="aten_2src_2_a_ten_2native_2cudnn_2conv_8cpp"/>
        <childnode refid="18179" relation="include">
        </childnode>
        <childnode refid="18249" relation="include">
        </childnode>
        <childnode refid="18260" relation="include">
        </childnode>
        <childnode refid="18261" relation="include">
        </childnode>
        <childnode refid="18262" relation="include">
        </childnode>
      </node>
      <node id="18202">
        <label>ATen/ArrayRef.h</label>
        <link refid="_array_ref_8h_source"/>
        <childnode refid="18185" relation="include">
        </childnode>
        <childnode refid="18203" relation="include">
        </childnode>
        <childnode refid="18210" relation="include">
        </childnode>
        <childnode refid="18208" relation="include">
        </childnode>
        <childnode refid="18211" relation="include">
        </childnode>
      </node>
      <node id="18245">
        <label>ATen/TensorGeometry.h</label>
        <link refid="_tensor_geometry_8h_source"/>
        <childnode refid="18229" relation="include">
        </childnode>
        <childnode refid="18246" relation="include">
        </childnode>
      </node>
      <node id="18242">
        <label>ATen/SparseTensorRef.h</label>
        <link refid="_sparse_tensor_ref_8h_source"/>
      </node>
      <node id="18180">
        <label>ATen/ATenGeneral.h</label>
        <link refid="_a_ten_general_8h_source"/>
      </node>
      <node id="18246">
        <label>ATen/WrapDimUtils.h</label>
        <link refid="_wrap_dim_utils_8h_source"/>
        <childnode refid="18224" relation="include">
        </childnode>
        <childnode refid="18197" relation="include">
        </childnode>
      </node>
      <node id="18243">
        <label>ATen/TensorAccessor.h</label>
        <link refid="_tensor_accessor_8h_source"/>
        <childnode refid="18194" relation="include">
        </childnode>
        <childnode refid="18222" relation="include">
        </childnode>
        <childnode refid="18201" relation="include">
        </childnode>
      </node>
      <node id="18227">
        <label>typeinfo</label>
      </node>
      <node id="18234">
        <label>cstdio</label>
      </node>
      <node id="18219">
        <label>ATen/detail/UniqueVoidPtr.h</label>
        <link refid="_unique_void_ptr_8h_source"/>
        <childnode refid="18183" relation="include">
        </childnode>
        <childnode refid="18180" relation="include">
        </childnode>
      </node>
      <node id="18211">
        <label>vector</label>
      </node>
      <node id="18255">
        <label>ATen/TensorMethods.h</label>
      </node>
      <node id="18252">
        <label>THNN/Reduction.h</label>
      </node>
      <node id="18209">
        <label>new</label>
      </node>
      <node id="18187">
        <label>utility</label>
      </node>
      <node id="18210">
        <label>array</label>
      </node>
      <node id="18197">
        <label>sstream</label>
      </node>
      <node id="18247">
        <label>ATen/Functions.h</label>
        <link refid="build_2aten_2src_2_a_ten_2_functions_8h_source"/>
        <childnode refid="18220" relation="include">
        </childnode>
        <childnode refid="18229" relation="include">
        </childnode>
        <childnode refid="18241" relation="include">
        </childnode>
        <childnode refid="18239" relation="include">
        </childnode>
        <childnode refid="18230" relation="include">
        </childnode>
        <childnode refid="18248" relation="include">
        </childnode>
        <childnode refid="18249" relation="include">
        </childnode>
        <childnode refid="18250" relation="include">
        </childnode>
        <childnode refid="18251" relation="include">
        </childnode>
        <childnode refid="18252" relation="include">
        </childnode>
      </node>
      <node id="18249">
        <label>ATen/NativeFunctions.h</label>
      </node>
      <node id="18216">
        <label>iosfwd</label>
      </node>
      <node id="18206">
        <label>cstdlib</label>
      </node>
      <node id="18218">
        <label>iostream</label>
      </node>
      <node id="18194">
        <label>cstddef</label>
      </node>
      <node id="18236">
        <label>unordered_map</label>
      </node>
      <node id="18235">
        <label>mutex</label>
      </node>
      <node id="18179">
        <label>ATen/ATen.h</label>
        <link refid="_a_ten_8h_source"/>
        <childnode refid="18180" relation="include">
        </childnode>
        <childnode refid="18181" relation="include">
        </childnode>
        <childnode refid="18182" relation="include">
        </childnode>
        <childnode refid="18220" relation="include">
        </childnode>
        <childnode refid="18229" relation="include">
        </childnode>
        <childnode refid="18230" relation="include">
        </childnode>
        <childnode refid="18231" relation="include">
        </childnode>
        <childnode refid="18239" relation="include">
        </childnode>
        <childnode refid="18241" relation="include">
        </childnode>
        <childnode refid="18200" relation="include">
        </childnode>
        <childnode refid="18245" relation="include">
        </childnode>
        <childnode refid="18247" relation="include">
        </childnode>
        <childnode refid="18253" relation="include">
        </childnode>
        <childnode refid="18254" relation="include">
        </childnode>
        <childnode refid="18255" relation="include">
        </childnode>
        <childnode refid="18256" relation="include">
        </childnode>
        <childnode refid="18257" relation="include">
        </childnode>
        <childnode refid="18250" relation="include">
        </childnode>
        <childnode refid="18251" relation="include">
        </childnode>
        <childnode refid="18244" relation="include">
        </childnode>
        <childnode refid="18258" relation="include">
        </childnode>
        <childnode refid="18259" relation="include">
        </childnode>
      </node>
      <node id="18233">
        <label>ATen/Registry.h</label>
        <link refid="_registry_8h_source"/>
        <childnode refid="18205" relation="include">
        </childnode>
        <childnode refid="18234" relation="include">
        </childnode>
        <childnode refid="18206" relation="include">
        </childnode>
        <childnode refid="18191" relation="include">
        </childnode>
        <childnode refid="18183" relation="include">
        </childnode>
        <childnode refid="18235" relation="include">
        </childnode>
        <childnode refid="18236" relation="include">
        </childnode>
        <childnode refid="18192" relation="include">
        </childnode>
        <childnode refid="18211" relation="include">
        </childnode>
        <childnode refid="18237" relation="include">
        </childnode>
        <childnode refid="18180" relation="include">
        </childnode>
      </node>
      <node id="18185">
        <label>ATen/Error.h</label>
        <link refid="_error_8h_source"/>
        <childnode refid="18180" relation="include">
        </childnode>
        <childnode refid="18186" relation="include">
        </childnode>
        <childnode refid="18194" relation="include">
        </childnode>
        <childnode refid="18195" relation="include">
        </childnode>
        <childnode refid="18196" relation="include">
        </childnode>
        <childnode refid="18197" relation="include">
        </childnode>
        <childnode refid="18192" relation="include">
        </childnode>
      </node>
      <node id="18251">
        <label>ATen/TensorOptions.h</label>
        <link refid="_tensor_options_8h_source"/>
        <childnode refid="18231" relation="include">
        </childnode>
        <childnode refid="18200" relation="include">
        </childnode>
        <childnode refid="18250" relation="include">
        </childnode>
        <childnode refid="18244" relation="include">
        </childnode>
        <childnode refid="18201" relation="include">
        </childnode>
        <childnode refid="18241" relation="include">
        </childnode>
        <childnode refid="18229" relation="include">
        </childnode>
        <childnode refid="18194" relation="include">
        </childnode>
        <childnode refid="18216" relation="include">
        </childnode>
        <childnode refid="18187" relation="include">
        </childnode>
      </node>
      <node id="18241">
        <label>ATen/Tensor.h</label>
        <link refid="build_2aten_2src_2_a_ten_2tensor_8h_source"/>
        <childnode refid="18230" relation="include">
        </childnode>
        <childnode refid="18220" relation="include">
        </childnode>
        <childnode refid="18201" relation="include">
        </childnode>
        <childnode refid="18242" relation="include">
        </childnode>
        <childnode refid="18239" relation="include">
        </childnode>
        <childnode refid="18243" relation="include">
        </childnode>
        <childnode refid="18223" relation="include">
        </childnode>
        <childnode refid="18224" relation="include">
        </childnode>
        <childnode refid="18226" relation="include">
        </childnode>
        <childnode refid="18200" relation="include">
        </childnode>
        <childnode refid="18244" relation="include">
        </childnode>
        <childnode refid="18186" relation="include">
        </childnode>
      </node>
      <node id="18188">
        <label>type_traits</label>
      </node>
      <node id="18244">
        <label>ATen/Layout.h</label>
        <link refid="_layout_8h_source"/>
        <childnode refid="18201" relation="include">
        </childnode>
        <childnode refid="18185" relation="include">
        </childnode>
        <childnode refid="18218" relation="include">
        </childnode>
      </node>
      <node id="18203">
        <label>ATen/SmallVector.h</label>
        <link refid="_small_vector_8h_source"/>
        <childnode refid="18204" relation="include">
        </childnode>
        <childnode refid="18205" relation="include">
        </childnode>
        <childnode refid="18190" relation="include">
        </childnode>
        <childnode refid="18194" relation="include">
        </childnode>
        <childnode refid="18206" relation="include">
        </childnode>
        <childnode refid="18207" relation="include">
        </childnode>
        <childnode refid="18189" relation="include">
        </childnode>
        <childnode refid="18208" relation="include">
        </childnode>
        <childnode refid="18183" relation="include">
        </childnode>
        <childnode refid="18209" relation="include">
        </childnode>
        <childnode refid="18188" relation="include">
        </childnode>
        <childnode refid="18187" relation="include">
        </childnode>
        <childnode refid="18180" relation="include">
        </childnode>
      </node>
      <node id="18205">
        <label>algorithm</label>
      </node>
      <node id="18230">
        <label>ATen/Generator.h</label>
        <link refid="_generator_8h_source"/>
        <childnode refid="18222" relation="include">
        </childnode>
      </node>
      <node id="18207">
        <label>cstring</label>
      </node>
      <node id="18183">
        <label>memory</label>
      </node>
      <node id="18189">
        <label>initializer_list</label>
      </node>
      <node id="18253">
        <label>ATen/Formatting.h</label>
        <link refid="_formatting_8h_source"/>
        <childnode refid="18218" relation="include">
        </childnode>
        <childnode refid="18229" relation="include">
        </childnode>
        <childnode refid="18220" relation="include">
        </childnode>
      </node>
    </incdepgraph>
    <innernamespace refid="namespaceat">at</innernamespace>
    <innernamespace refid="namespaceat_1_1native">at::native</innernamespace>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <programlisting>
<codeline lineno="1"><highlight class="preprocessor">#include<sp/>&lt;ATen/ATen.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="2"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/NativeFunctions.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="3"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/Config.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="4"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/cuda/CUDAConfig.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="5"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/cuda/Exceptions.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="6"><highlight class="normal"></highlight></codeline>
<codeline lineno="7"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>!AT_CUDNN_ENABLED()</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="8"><highlight class="normal"></highlight></codeline>
<codeline lineno="9"><highlight class="normal"></highlight><highlight class="keyword">namespace<sp/></highlight><highlight class="normal"><ref refid="namespaceat" kindref="compound">at</ref><sp/>{<sp/></highlight><highlight class="keyword">namespace<sp/></highlight><highlight class="normal">native<sp/>{</highlight></codeline>
<codeline lineno="10"><highlight class="normal"></highlight></codeline>
<codeline lineno="11"><highlight class="normal"></highlight><highlight class="comment">//<sp/>See<sp/>Note<sp/>[ATen<sp/>preprocessor<sp/>philosophy]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="12"><highlight class="normal"></highlight></codeline>
<codeline lineno="13"><highlight class="normal"><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref><sp/>cudnn_convolution(</highlight></codeline>
<codeline lineno="14"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>input,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>weight,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>bias<sp/></highlight><highlight class="comment">/*<sp/>optional<sp/>*/</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="15"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,</highlight></codeline>
<codeline lineno="16"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>groups,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)<sp/>{</highlight></codeline>
<codeline lineno="17"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;cudnn_convolution:<sp/>ATen<sp/>not<sp/>compiled<sp/>with<sp/>cuDNN<sp/>support&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="18"><highlight class="normal">}</highlight></codeline>
<codeline lineno="19"><highlight class="normal"></highlight></codeline>
<codeline lineno="20"><highlight class="normal"><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref><sp/>cudnn_convolution_backward_input(</highlight></codeline>
<codeline lineno="21"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>input_size,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>grad_output,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>weight,</highlight></codeline>
<codeline lineno="22"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="23"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)<sp/>{</highlight></codeline>
<codeline lineno="24"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;cudnn_convolution_backward_input:<sp/>ATen<sp/>not<sp/>compiled<sp/>with<sp/>cuDNN<sp/>support&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="25"><highlight class="normal">}</highlight></codeline>
<codeline lineno="26"><highlight class="normal"></highlight></codeline>
<codeline lineno="27"><highlight class="normal"><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref><sp/>cudnn_convolution_backward_weight(</highlight></codeline>
<codeline lineno="28"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>weight_size,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>grad_output,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>input,</highlight></codeline>
<codeline lineno="29"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="30"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)<sp/>{</highlight></codeline>
<codeline lineno="31"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;cudnn_convolution_backward_weight:<sp/>ATen<sp/>not<sp/>compiled<sp/>with<sp/>cuDNN<sp/>support&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="32"><highlight class="normal">}</highlight></codeline>
<codeline lineno="33"><highlight class="normal"></highlight></codeline>
<codeline lineno="34"><highlight class="normal"><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref><sp/>cudnn_convolution_backward_bias(</highlight></codeline>
<codeline lineno="35"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>grad_output)<sp/>{</highlight></codeline>
<codeline lineno="36"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;cudnn_convolution_backward_bias:<sp/>ATen<sp/>not<sp/>compiled<sp/>with<sp/>cuDNN<sp/>support&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="37"><highlight class="normal">}</highlight></codeline>
<codeline lineno="38"><highlight class="normal"></highlight></codeline>
<codeline lineno="39"><highlight class="normal">std::tuple&lt;at::Tensor,at::Tensor,at::Tensor&gt;<sp/>cudnn_convolution_backward(</highlight></codeline>
<codeline lineno="40"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>input,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>grad_output,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>weight,</highlight></codeline>
<codeline lineno="41"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="42"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic,<sp/>std::array&lt;bool,3&gt;<sp/>output_mask)<sp/>{</highlight></codeline>
<codeline lineno="43"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;cudnn_convolution_backward:<sp/>ATen<sp/>not<sp/>compiled<sp/>with<sp/>cuDNN<sp/>support&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="44"><highlight class="normal">}</highlight></codeline>
<codeline lineno="45"><highlight class="normal"></highlight></codeline>
<codeline lineno="46"><highlight class="normal"><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref><sp/>cudnn_convolution_transpose(</highlight></codeline>
<codeline lineno="47"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>input,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>weight,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>bias<sp/></highlight><highlight class="comment">/*<sp/>optional<sp/>*/</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="48"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>output_padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,</highlight></codeline>
<codeline lineno="49"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>groups,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)<sp/>{</highlight></codeline>
<codeline lineno="50"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;cudnn_convolution_transpose:<sp/>ATen<sp/>not<sp/>compiled<sp/>with<sp/>cuDNN<sp/>support&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="51"><highlight class="normal">}</highlight></codeline>
<codeline lineno="52"><highlight class="normal"></highlight></codeline>
<codeline lineno="53"><highlight class="normal"><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref><sp/>cudnn_convolution_transpose_backward_input(</highlight></codeline>
<codeline lineno="54"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>grad_output,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>weight,</highlight></codeline>
<codeline lineno="55"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,</highlight></codeline>
<codeline lineno="56"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>groups,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)<sp/>{</highlight></codeline>
<codeline lineno="57"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;cudnn_convolution_transpose_backward:<sp/>ATen<sp/>not<sp/>compiled<sp/>with<sp/>cuDNN<sp/>support&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="58"><highlight class="normal">}</highlight></codeline>
<codeline lineno="59"><highlight class="normal"></highlight></codeline>
<codeline lineno="60"><highlight class="normal"><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref><sp/>cudnn_convolution_transpose_backward_weight(</highlight></codeline>
<codeline lineno="61"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>weight_size,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>grad_output,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>input,</highlight></codeline>
<codeline lineno="62"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="63"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)<sp/>{</highlight></codeline>
<codeline lineno="64"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;cudnn_convolution_transpose_backward_weight:<sp/>ATen<sp/>not<sp/>compiled<sp/>with<sp/>cuDNN<sp/>support&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="65"><highlight class="normal">}</highlight></codeline>
<codeline lineno="66"><highlight class="normal"></highlight></codeline>
<codeline lineno="67"><highlight class="normal">std::tuple&lt;at::Tensor,at::Tensor,at::Tensor&gt;<sp/>cudnn_convolution_transpose_backward(</highlight></codeline>
<codeline lineno="68"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>input,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>grad_output,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>weight,</highlight></codeline>
<codeline lineno="69"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>output_padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="70"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic,<sp/>std::array&lt;bool,3&gt;<sp/>output_mask)<sp/>{</highlight></codeline>
<codeline lineno="71"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;cudnn_convolution_transpose_backward:<sp/>ATen<sp/>not<sp/>compiled<sp/>with<sp/>cuDNN<sp/>support&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="72"><highlight class="normal">}</highlight></codeline>
<codeline lineno="73"><highlight class="normal"></highlight></codeline>
<codeline lineno="74"><highlight class="normal">}}</highlight></codeline>
<codeline lineno="75"><highlight class="normal"></highlight></codeline>
<codeline lineno="76"><highlight class="normal"></highlight><highlight class="preprocessor">#else<sp/><sp/>//<sp/>AT_CUDNN_ENABLED</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="77"><highlight class="normal"></highlight></codeline>
<codeline lineno="78"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&quot;THC/THC.h&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="79"><highlight class="normal"></highlight></codeline>
<codeline lineno="80"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/cudnn/cudnn-wrapper.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="81"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/cudnn/Descriptors.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="82"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/cudnn/Types.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="83"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/cudnn/Utils.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="84"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&quot;ATen/native/utils/ParamsHash.h&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="85"><highlight class="normal"></highlight></codeline>
<codeline lineno="86"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/TensorUtils.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="87"><highlight class="normal"></highlight></codeline>
<codeline lineno="88"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;functional&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="89"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;iterator&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="90"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;sstream&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="91"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;algorithm&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="92"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;memory&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="93"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;mutex&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="94"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;stdint.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="95"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;unordered_map&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="96"><highlight class="normal"></highlight></codeline>
<codeline lineno="97"><highlight class="normal"></highlight><highlight class="keyword">namespace<sp/></highlight><highlight class="normal"><ref refid="namespaceat" kindref="compound">at</ref><sp/>{<sp/></highlight><highlight class="keyword">namespace<sp/></highlight><highlight class="normal">native<sp/>{</highlight></codeline>
<codeline lineno="98"><highlight class="normal"></highlight></codeline>
<codeline lineno="99"><highlight class="normal"></highlight><highlight class="comment">//<sp/>TODO:<sp/>Go<sp/>through<sp/>all<sp/>the<sp/>checking<sp/>code<sp/>again<sp/>and<sp/>make<sp/>sure</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="100"><highlight class="normal"></highlight><highlight class="comment">//<sp/>we<sp/>haven&apos;t<sp/>missed<sp/>anything.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="101"><highlight class="normal"></highlight></codeline>
<codeline lineno="102"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="103"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="104"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Math</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="105"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="106"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="107"><highlight class="normal"></highlight></codeline>
<codeline lineno="108"><highlight class="normal">constexpr<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>input_batch_size_dim<sp/>=<sp/>0;<sp/><sp/></highlight><highlight class="comment">//<sp/>also<sp/>grad_input</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="109"><highlight class="normal">constexpr<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>input_channels_dim<sp/>=<sp/>1;</highlight></codeline>
<codeline lineno="110"><highlight class="normal">constexpr<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>output_batch_size_dim<sp/>=<sp/>0;<sp/><sp/></highlight><highlight class="comment">//<sp/>also<sp/>grad_output</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="111"><highlight class="normal">constexpr<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>output_channels_dim<sp/>=<sp/>1;</highlight></codeline>
<codeline lineno="112"><highlight class="normal">constexpr<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>weight_output_channels_dim<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="113"><highlight class="normal">constexpr<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>weight_input_channels_dim<sp/>=<sp/>1;</highlight></codeline>
<codeline lineno="114"><highlight class="normal"></highlight></codeline>
<codeline lineno="115"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Often<sp/>written<sp/>as<sp/>2<sp/>+<sp/>max_dim<sp/>(extra<sp/>dims<sp/>for<sp/>batch<sp/>size<sp/>and<sp/>channels)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="116"><highlight class="normal">constexpr<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>max_dim<sp/>=<sp/>3;</highlight></codeline>
<codeline lineno="117"><highlight class="normal"></highlight></codeline>
<codeline lineno="118"><highlight class="normal"></highlight><highlight class="comment">//<sp/>NB:<sp/>conv_output_size<sp/>and<sp/>conv_input_size<sp/>are<sp/>not<sp/>bijections,</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="119"><highlight class="normal"></highlight><highlight class="comment">//<sp/>as<sp/>conv_output_size<sp/>loses<sp/>information;<sp/>this<sp/>is<sp/>why<sp/>conv_input_size</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="120"><highlight class="normal"></highlight><highlight class="comment">//<sp/>takes<sp/>an<sp/>extra<sp/>output_padding<sp/>argument<sp/>to<sp/>resolve<sp/>the<sp/>ambiguity.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="121"><highlight class="normal"></highlight></codeline>
<codeline lineno="122"><highlight class="normal">std::vector&lt;int64_t&gt;<sp/>conv_output_size(</highlight></codeline>
<codeline lineno="123"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>input_size,<sp/>IntList<sp/>weight_size,</highlight></codeline>
<codeline lineno="124"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups</highlight></codeline>
<codeline lineno="125"><highlight class="normal">)<sp/>{</highlight></codeline>
<codeline lineno="126"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>ASSERT(input_size.size()<sp/>&gt;<sp/>2)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="127"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>ASSERT(input_size.size()<sp/>==<sp/>weight_size.size())</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="128"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dim<sp/>=<sp/>input_size.size();</highlight></codeline>
<codeline lineno="129"><highlight class="normal"><sp/><sp/>std::vector&lt;int64_t&gt;<sp/>output_size(dim);</highlight></codeline>
<codeline lineno="130"><highlight class="normal"><sp/><sp/>output_size[0]<sp/>=<sp/>input_size[input_batch_size_dim];</highlight></codeline>
<codeline lineno="131"><highlight class="normal"><sp/><sp/>output_size[1]<sp/>=<sp/>weight_size[weight_output_channels_dim];</highlight></codeline>
<codeline lineno="132"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>2;<sp/>d<sp/>&lt;<sp/>dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="133"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>kernel<sp/>=<sp/>dilation[d<sp/>-<sp/>2]<sp/>*<sp/>(weight_size[d]<sp/>-<sp/>1)<sp/>+<sp/>1;</highlight></codeline>
<codeline lineno="134"><highlight class="normal"><sp/><sp/><sp/><sp/>output_size[d]<sp/>=<sp/>(input_size[d]<sp/>+<sp/>(2<sp/>*<sp/>padding[d<sp/>-<sp/>2])</highlight></codeline>
<codeline lineno="135"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>kernel)<sp/>/<sp/>stride[d<sp/>-<sp/>2]<sp/>+<sp/>1;</highlight></codeline>
<codeline lineno="136"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="137"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>output_size;</highlight></codeline>
<codeline lineno="138"><highlight class="normal">}</highlight></codeline>
<codeline lineno="139"><highlight class="normal"></highlight></codeline>
<codeline lineno="140"><highlight class="normal">std::vector&lt;int64_t&gt;<sp/>conv_input_size(</highlight></codeline>
<codeline lineno="141"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>output_size,<sp/>IntList<sp/>weight_size,</highlight></codeline>
<codeline lineno="142"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>output_padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups</highlight></codeline>
<codeline lineno="143"><highlight class="normal">)<sp/>{</highlight></codeline>
<codeline lineno="144"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>ASSERT(output_size.size()<sp/>&gt;<sp/>2)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="145"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>ASSERT(output_size.size()<sp/>==<sp/>weight_size.size())</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="146"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dim<sp/>=<sp/>output_size.size();</highlight></codeline>
<codeline lineno="147"><highlight class="normal"><sp/><sp/>std::vector&lt;int64_t&gt;<sp/>input_size(dim);</highlight></codeline>
<codeline lineno="148"><highlight class="normal"><sp/><sp/>input_size[0]<sp/>=<sp/>output_size[output_batch_size_dim];</highlight></codeline>
<codeline lineno="149"><highlight class="normal"><sp/><sp/>input_size[1]<sp/>=<sp/>weight_size[weight_input_channels_dim]<sp/>*<sp/>groups;</highlight></codeline>
<codeline lineno="150"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>2;<sp/>d<sp/>&lt;<sp/>dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="151"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>kernel<sp/>=<sp/>dilation[d<sp/>-<sp/>2]<sp/>*<sp/>(weight_size[d]<sp/>-<sp/>1)<sp/>+<sp/>1;</highlight></codeline>
<codeline lineno="152"><highlight class="normal"><sp/><sp/><sp/><sp/>input_size[d]<sp/>=<sp/>(output_size[d]<sp/>-<sp/>1)<sp/>*<sp/>stride[d<sp/>-<sp/>2]<sp/>-<sp/>(2<sp/>*<sp/>padding[d<sp/>-<sp/>2])<sp/>+</highlight></codeline>
<codeline lineno="153"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>kernel<sp/>+<sp/>output_padding[d<sp/>-<sp/>2];</highlight></codeline>
<codeline lineno="154"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="155"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>input_size;</highlight></codeline>
<codeline lineno="156"><highlight class="normal">}</highlight></codeline>
<codeline lineno="157"><highlight class="normal"></highlight></codeline>
<codeline lineno="158"><highlight class="normal">std::vector&lt;int64_t&gt;<sp/>conv_weight_size(</highlight></codeline>
<codeline lineno="159"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>input_size,<sp/>IntList<sp/>output_size,</highlight></codeline>
<codeline lineno="160"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>output_padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups</highlight></codeline>
<codeline lineno="161"><highlight class="normal">)<sp/>{</highlight></codeline>
<codeline lineno="162"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dim<sp/>=<sp/>input_size.size();</highlight></codeline>
<codeline lineno="163"><highlight class="normal"><sp/><sp/>std::vector&lt;int64_t&gt;<sp/>weight_size(dim);</highlight></codeline>
<codeline lineno="164"><highlight class="normal"><sp/><sp/>weight_size[0]<sp/>=<sp/>output_size[1];</highlight></codeline>
<codeline lineno="165"><highlight class="normal"><sp/><sp/>weight_size[1]<sp/>=<sp/>input_size[1]<sp/>/<sp/>groups;</highlight></codeline>
<codeline lineno="166"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>2;<sp/>d<sp/>&lt;<sp/>dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="167"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>kernel<sp/>=<sp/>input_size[d]<sp/>-<sp/>(output_size[d]<sp/>-<sp/>1)<sp/>*<sp/>stride[d<sp/>-<sp/>2]</highlight></codeline>
<codeline lineno="168"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>+<sp/>2<sp/>*<sp/>padding[d<sp/>-<sp/>2]<sp/>-<sp/>output_padding[d<sp/>-<sp/>2];</highlight></codeline>
<codeline lineno="169"><highlight class="normal"><sp/><sp/><sp/><sp/>weight_size[d]<sp/>=<sp/>(kernel<sp/>-<sp/>1)<sp/>/<sp/>dilation[d<sp/>-<sp/>2]<sp/>+<sp/>1;</highlight></codeline>
<codeline lineno="170"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="171"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>weight_size;</highlight></codeline>
<codeline lineno="172"><highlight class="normal">}</highlight></codeline>
<codeline lineno="173"><highlight class="normal"></highlight></codeline>
<codeline lineno="174"><highlight class="normal"></highlight><highlight class="comment">//<sp/>TODO:<sp/>Move<sp/>this<sp/>into<sp/>the<sp/>standard<sp/>library,<sp/>with<sp/>a<sp/>better<sp/>name?</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="175"><highlight class="normal">Tensor<sp/>narrowGroup(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>t,<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>dim,<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>group_idx,<sp/>int64_t<sp/>groups)<sp/>{</highlight></codeline>
<codeline lineno="176"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>group_size<sp/>=<sp/>t.size(dim)<sp/>/<sp/>groups;</highlight></codeline>
<codeline lineno="177"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>t.narrow(dim,<sp/>group_idx<sp/>*<sp/>group_size,<sp/>group_size);</highlight></codeline>
<codeline lineno="178"><highlight class="normal">}</highlight></codeline>
<codeline lineno="179"><highlight class="normal"></highlight></codeline>
<codeline lineno="180"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="181"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="182"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Checking</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="183"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="184"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="185"><highlight class="normal"></highlight></codeline>
<codeline lineno="186"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Note<sp/>[Legacy<sp/>CuDNN<sp/>grouped<sp/>convolution<sp/>support]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="187"><highlight class="normal"></highlight><highlight class="comment">//<sp/>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="188"><highlight class="normal"></highlight><highlight class="comment">//<sp/>CuDNN<sp/>earlier<sp/>than<sp/>CuDNN<sp/>7<sp/>does<sp/>not<sp/>directly<sp/>support<sp/>group</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="189"><highlight class="normal"></highlight><highlight class="comment">//<sp/>convolution,<sp/>so<sp/>we<sp/>provide<sp/>support<sp/>for<sp/>it<sp/>by<sp/>sequentially</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="190"><highlight class="normal"></highlight><highlight class="comment">//<sp/>running<sp/>a<sp/>convolution<sp/>per<sp/>group<sp/><sp/>with<sp/>appropriately</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="191"><highlight class="normal"></highlight><highlight class="comment">//<sp/>adjusted<sp/>sizes.<sp/><sp/>https://blog.yani.io/filter-group-tutorial/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="192"><highlight class="normal"></highlight><highlight class="comment">//<sp/>has<sp/>a<sp/>fairly<sp/>good<sp/>diagram<sp/>explaining<sp/>how<sp/>it<sp/>works.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="193"><highlight class="normal"></highlight></codeline>
<codeline lineno="194"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Used<sp/>on<sp/>pad,<sp/>stride<sp/>and<sp/>dilation</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="195"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>check_args(CheckedFrom<sp/>c,<sp/>IntList<sp/>args,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>expected_size,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">char</highlight><highlight class="normal">*<sp/>arg_name)</highlight></codeline>
<codeline lineno="196"><highlight class="normal">{</highlight></codeline>
<codeline lineno="197"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(args.size()<sp/>&gt;<sp/>expected_size){</highlight></codeline>
<codeline lineno="198"><highlight class="normal"><sp/><sp/><sp/><sp/>std::stringstream<sp/>ss;</highlight></codeline>
<codeline lineno="199"><highlight class="normal"><sp/><sp/><sp/><sp/>ss<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;Too<sp/>many<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>arg_name<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;<sp/>values<sp/>(&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>args.size()<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;)<sp/>supplied,<sp/>expecting<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>expected_size<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;<sp/>(while<sp/>checking<sp/>arguments<sp/>for<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>c<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;)&quot;</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="200"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(ss.str());</highlight></codeline>
<codeline lineno="201"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="202"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(args.size()<sp/>&lt;<sp/>expected_size){</highlight></codeline>
<codeline lineno="203"><highlight class="normal"><sp/><sp/><sp/><sp/>std::stringstream<sp/>ss;</highlight></codeline>
<codeline lineno="204"><highlight class="normal"><sp/><sp/><sp/><sp/>ss<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;Not<sp/>enough<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>arg_name<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;<sp/>values<sp/>(&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>args.size()<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;)<sp/>supplied,<sp/>expecting<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>expected_size<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;<sp/>(while<sp/>checking<sp/>arguments<sp/>for<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>c<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;)&quot;</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="205"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(ss.str());</highlight></codeline>
<codeline lineno="206"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="207"><highlight class="normal"></highlight></codeline>
<codeline lineno="208"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>num_negative_values<sp/>=<sp/>std::count_if(args.begin(),<sp/>args.end(),<sp/>[](</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>x){</highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>x<sp/>&lt;<sp/>0;});</highlight></codeline>
<codeline lineno="209"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(num_negative_values<sp/>&gt;<sp/>0){</highlight></codeline>
<codeline lineno="210"><highlight class="normal"><sp/><sp/><sp/><sp/>std::stringstream<sp/>ss;</highlight></codeline>
<codeline lineno="211"><highlight class="normal"><sp/><sp/><sp/><sp/>ss<sp/>&lt;&lt;<sp/>arg_name<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;<sp/>should<sp/>be<sp/>greater<sp/>than<sp/>zero<sp/>but<sp/>got<sp/>(&quot;</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="212"><highlight class="normal"><sp/><sp/><sp/><sp/>std::copy(args.begin(),<sp/>args.end()<sp/>-<sp/>1,<sp/>std::ostream_iterator&lt;int&gt;(ss,</highlight><highlight class="stringliteral">&quot;,<sp/>&quot;</highlight><highlight class="normal">));</highlight></codeline>
<codeline lineno="213"><highlight class="normal"><sp/><sp/><sp/><sp/>ss<sp/>&lt;&lt;<sp/>args.back()<sp/>&lt;&lt;<sp/><sp/></highlight><highlight class="stringliteral">&quot;)&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;<sp/>(while<sp/>checking<sp/>arguments<sp/>for<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>c<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;)&quot;</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="214"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(ss.str());</highlight></codeline>
<codeline lineno="215"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="216"><highlight class="normal">}</highlight></codeline>
<codeline lineno="217"><highlight class="normal"></highlight></codeline>
<codeline lineno="218"><highlight class="normal"></highlight></codeline>
<codeline lineno="219"><highlight class="normal"></highlight><highlight class="comment">//<sp/>NB:<sp/>For<sp/>many<sp/>call<sp/>sites,<sp/>it<sp/>is<sp/>not<sp/>strictly<sp/>necessary<sp/>to<sp/>check<sp/>all<sp/>of</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="220"><highlight class="normal"></highlight><highlight class="comment">//<sp/>these<sp/>relationships<sp/>(for<sp/>example,<sp/>for<sp/>forward<sp/>convolution,<sp/>we<sp/>compute</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="221"><highlight class="normal"></highlight><highlight class="comment">//<sp/>the<sp/>size<sp/>of<sp/>output<sp/>ourselves,<sp/>so<sp/>we<sp/>don&apos;t<sp/>actually<sp/>need<sp/>to<sp/>check</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="222"><highlight class="normal"></highlight><highlight class="comment">//<sp/>output.<sp/><sp/>However,<sp/>writing<sp/>a<sp/>single<sp/>function<sp/>that<sp/>does<sp/>everything</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="223"><highlight class="normal"></highlight><highlight class="comment">//<sp/>means<sp/>we<sp/>get<sp/>to<sp/>reuse<sp/>it<sp/>for<sp/>both<sp/>forwards<sp/>and<sp/>all<sp/>backwards</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="224"><highlight class="normal"></highlight><highlight class="comment">//<sp/>variants,<sp/>even<sp/>when<sp/>the<sp/>set<sp/>of<sp/>&quot;real&quot;<sp/>inputs<sp/>varies.<sp/><sp/>The<sp/>magic<sp/>of</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="225"><highlight class="normal"></highlight><highlight class="comment">//<sp/>relational<sp/>computing!</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="226"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="227"><highlight class="normal"></highlight><highlight class="comment">//<sp/>(There<sp/>is<sp/>one<sp/>downside,<sp/>which<sp/>is<sp/>that<sp/>it<sp/>is<sp/>slightly<sp/>harder<sp/>to<sp/>write</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="228"><highlight class="normal"></highlight><highlight class="comment">//<sp/>error<sp/>messages<sp/>which<sp/>are<sp/>able<sp/>to<sp/>distinguish<sp/>between<sp/>real<sp/>inputs</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="229"><highlight class="normal"></highlight><highlight class="comment">//<sp/>(which<sp/>the<sp/>user<sp/>can<sp/>change)<sp/>and<sp/>computed<sp/>inputs<sp/>(which<sp/>the<sp/>user<sp/>can</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="230"><highlight class="normal"></highlight><highlight class="comment">//<sp/>only<sp/>indirectly<sp/>affect).<sp/><sp/>It<sp/>would<sp/>be<sp/>an<sp/>interesting<sp/>exercise<sp/>to</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="231"><highlight class="normal"></highlight><highlight class="comment">//<sp/>come<sp/>up<sp/>with<sp/>a<sp/>general<sp/>framework<sp/>to<sp/>handle<sp/>such<sp/>situations.)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="232"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>convolution_shape_check(</highlight></codeline>
<codeline lineno="233"><highlight class="normal"><sp/><sp/><sp/><sp/>CheckedFrom<sp/>c,</highlight></codeline>
<codeline lineno="234"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorGeometryArg&amp;<sp/>input,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorGeometryArg&amp;<sp/>weight,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorGeometryArg&amp;<sp/>output,</highlight></codeline>
<codeline lineno="235"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups)</highlight></codeline>
<codeline lineno="236"><highlight class="normal">{</highlight></codeline>
<codeline lineno="237"><highlight class="normal"><sp/><sp/>check_args(c,<sp/>padding,<sp/>input-&gt;dim()<sp/>-<sp/>2,<sp/></highlight><highlight class="stringliteral">&quot;padding&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="238"><highlight class="normal"><sp/><sp/>check_args(c,<sp/>stride,<sp/>padding.size(),<sp/></highlight><highlight class="stringliteral">&quot;stride&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="239"><highlight class="normal"><sp/><sp/>check_args(c,<sp/>dilation,<sp/>padding.size(),<sp/></highlight><highlight class="stringliteral">&quot;dilation&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="240"><highlight class="normal"></highlight></codeline>
<codeline lineno="241"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Input</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="242"><highlight class="normal"><sp/><sp/>checkDimRange(c,<sp/>input,<sp/>3,<sp/>6<sp/></highlight><highlight class="comment">/*<sp/>exclusive<sp/>*/</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="243"><highlight class="normal"><sp/><sp/>checkSize(c,<sp/>input,<sp/>input_channels_dim,<sp/>weight-&gt;size(1)<sp/>*<sp/>groups);</highlight></codeline>
<codeline lineno="244"><highlight class="normal"></highlight></codeline>
<codeline lineno="245"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Weight</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="246"><highlight class="normal"><sp/><sp/>checkSameDim(c,<sp/>input,<sp/>weight);</highlight></codeline>
<codeline lineno="247"><highlight class="normal"></highlight></codeline>
<codeline lineno="248"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>check<sp/>that<sp/>output-&gt;size()<sp/>matches<sp/>output_sizes</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="249"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>check<sp/>that<sp/>weight<sp/>matches<sp/>output-&gt;sizes()</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="250"><highlight class="normal"><sp/><sp/>checkSameDim(c,<sp/>input,<sp/>output);</highlight></codeline>
<codeline lineno="251"><highlight class="normal">}</highlight></codeline>
<codeline lineno="252"><highlight class="normal"></highlight></codeline>
<codeline lineno="253"><highlight class="normal"></highlight><highlight class="comment">//<sp/>This<sp/>POD<sp/>struct<sp/>is<sp/>used<sp/>to<sp/>let<sp/>us<sp/>easily<sp/>compute<sp/>hashes<sp/>of<sp/>the</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="254"><highlight class="normal"></highlight><highlight class="comment">//<sp/>parameters</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="255"><highlight class="normal"></highlight><highlight class="keyword">struct<sp/></highlight><highlight class="normal">ConvolutionParams</highlight></codeline>
<codeline lineno="256"><highlight class="normal">{</highlight></codeline>
<codeline lineno="257"><highlight class="normal"><sp/><sp/>cudnnDataType_t<sp/>dataType;</highlight></codeline>
<codeline lineno="258"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>input_size[2<sp/>+<sp/>max_dim];</highlight></codeline>
<codeline lineno="259"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>input_stride[2<sp/>+<sp/>max_dim];</highlight></codeline>
<codeline lineno="260"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>weight_size[2<sp/>+<sp/>max_dim];</highlight></codeline>
<codeline lineno="261"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>padding[max_dim];</highlight></codeline>
<codeline lineno="262"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>stride[max_dim];</highlight></codeline>
<codeline lineno="263"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>dilation[max_dim];</highlight></codeline>
<codeline lineno="264"><highlight class="normal"><sp/><sp/>int64_t<sp/>groups;</highlight></codeline>
<codeline lineno="265"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic;</highlight></codeline>
<codeline lineno="266"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>NB:<sp/>transposed<sp/>purposely<sp/>omitted:<sp/>transposed<sp/>just<sp/>swaps</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="267"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>forward<sp/>and<sp/>backward,<sp/>so<sp/>you<sp/>can<sp/>reuse<sp/>the<sp/>benchmark<sp/>entry,</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="268"><highlight class="normal">};</highlight></codeline>
<codeline lineno="269"><highlight class="normal"></highlight></codeline>
<codeline lineno="270"><highlight class="normal"></highlight><highlight class="comment">//<sp/>NB:<sp/>This<sp/>can&apos;t<sp/>be<sp/>a<sp/>constructor,<sp/>because<sp/>then<sp/>ConvolutionParams</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="271"><highlight class="normal"></highlight><highlight class="comment">//<sp/>would<sp/>not<sp/>be<sp/>a<sp/>POD<sp/>anymore.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="272"><highlight class="normal"></highlight><highlight class="comment">//<sp/>TODO:<sp/>Use<sp/>TensorGeometry<sp/>here<sp/>instead<sp/>of<sp/>the<sp/>entire<sp/>Tensor,<sp/>which<sp/>we</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="273"><highlight class="normal"></highlight><highlight class="comment">//<sp/>don&apos;t<sp/>actually<sp/>need.<sp/><sp/>(OTOH:<sp/>We<sp/>can<sp/>always<sp/>pass<sp/>in</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="274"><highlight class="normal"></highlight><highlight class="comment">//<sp/>grad_input/grad_output,<sp/>so<sp/>this<sp/>is<sp/>not<sp/>very<sp/>pressing)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="275"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>setConvolutionParams(</highlight></codeline>
<codeline lineno="276"><highlight class="normal"><sp/><sp/><sp/><sp/>ConvolutionParams*<sp/>params,</highlight></codeline>
<codeline lineno="277"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>input,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>weight,</highlight></codeline>
<codeline lineno="278"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,</highlight></codeline>
<codeline lineno="279"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>groups,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)<sp/>{</highlight></codeline>
<codeline lineno="280"><highlight class="normal"></highlight></codeline>
<codeline lineno="281"><highlight class="normal"><sp/><sp/>cudnnDataType_t<sp/>dataType<sp/>=<sp/>getCudnnDataType(input);</highlight></codeline>
<codeline lineno="282"><highlight class="normal"><sp/><sp/>memset(params,<sp/>0,<sp/></highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(ConvolutionParams));</highlight></codeline>
<codeline lineno="283"><highlight class="normal"><sp/><sp/>params-&gt;dataType<sp/>=<sp/>dataType;</highlight></codeline>
<codeline lineno="284"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>ASSERT(weight.dim()<sp/>==<sp/>input.dim())</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="285"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>!=<sp/>input.dim();<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="286"><highlight class="normal"><sp/><sp/><sp/><sp/>params-&gt;input_size[i]<sp/>=<sp/>(int)<sp/>input.size(i);</highlight></codeline>
<codeline lineno="287"><highlight class="normal"><sp/><sp/><sp/><sp/>params-&gt;input_stride[i]<sp/>=<sp/>(int)<sp/>input.stride(i);</highlight></codeline>
<codeline lineno="288"><highlight class="normal"><sp/><sp/><sp/><sp/>params-&gt;weight_size[i]<sp/>=<sp/>(int)<sp/>weight.size(i);</highlight></codeline>
<codeline lineno="289"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="290"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>ASSERT(padding.size()<sp/>==<sp/>stride.size())</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="291"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>ASSERT(padding.size()<sp/>==<sp/>dilation.size())</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="292"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>!=<sp/>padding.size();<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="293"><highlight class="normal"><sp/><sp/><sp/><sp/>params-&gt;padding[i]<sp/>=<sp/>padding[i];</highlight></codeline>
<codeline lineno="294"><highlight class="normal"><sp/><sp/><sp/><sp/>params-&gt;stride[i]<sp/>=<sp/>stride[i];</highlight></codeline>
<codeline lineno="295"><highlight class="normal"><sp/><sp/><sp/><sp/>params-&gt;dilation[i]<sp/>=<sp/>dilation[i];</highlight></codeline>
<codeline lineno="296"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="297"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>In<sp/>principle,<sp/>we<sp/>shouldn&apos;t<sp/>parametrize<sp/>by<sp/>groups<sp/>for<sp/>legacy</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="298"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>CuDNN,<sp/>but<sp/>it<sp/>doesn&apos;t<sp/>seem<sp/>worth<sp/>the<sp/>effort<sp/>to<sp/>actually<sp/>do<sp/>this.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="299"><highlight class="normal"><sp/><sp/>params-&gt;groups<sp/>=<sp/>groups;</highlight></codeline>
<codeline lineno="300"><highlight class="normal"><sp/><sp/>params-&gt;deterministic<sp/>=<sp/>deterministic;</highlight></codeline>
<codeline lineno="301"><highlight class="normal">}</highlight></codeline>
<codeline lineno="302"><highlight class="normal"></highlight></codeline>
<codeline lineno="303"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Convenience<sp/>struct<sp/>for<sp/>passing<sp/>around<sp/>descriptors<sp/>and<sp/>data</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="304"><highlight class="normal"></highlight><highlight class="comment">//<sp/>pointers</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="305"><highlight class="normal"></highlight><highlight class="keyword">struct<sp/></highlight><highlight class="normal">ConvolutionArgs<sp/>{</highlight></codeline>
<codeline lineno="306"><highlight class="normal"><sp/><sp/>cudnnHandle_t<sp/>handle;</highlight></codeline>
<codeline lineno="307"><highlight class="normal"><sp/><sp/>ConvolutionParams<sp/>params;</highlight></codeline>
<codeline lineno="308"><highlight class="normal"><sp/><sp/>TensorDescriptor<sp/>idesc,<sp/>odesc;</highlight></codeline>
<codeline lineno="309"><highlight class="normal"><sp/><sp/>FilterDescriptor<sp/>wdesc;</highlight></codeline>
<codeline lineno="310"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>input,<sp/>output,<sp/>weight;</highlight></codeline>
<codeline lineno="311"><highlight class="normal"><sp/><sp/>ConvolutionDescriptor<sp/>cdesc;</highlight></codeline>
<codeline lineno="312"><highlight class="normal"></highlight></codeline>
<codeline lineno="313"><highlight class="normal"><sp/><sp/>ConvolutionArgs(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>input,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>output,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>weight)<sp/>:<sp/>input(input),<sp/>output(output),<sp/>weight(weight)<sp/>{</highlight></codeline>
<codeline lineno="314"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="315"><highlight class="normal">};</highlight></codeline>
<codeline lineno="316"><highlight class="normal"></highlight></codeline>
<codeline lineno="317"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="318"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="319"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Benchmarking</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="320"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="321"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="322"><highlight class="normal"></highlight></codeline>
<codeline lineno="323"><highlight class="normal"></highlight><highlight class="comment">//<sp/>TODO:<sp/>Use<sp/>something<sp/>less<sp/>heavy<sp/>duty<sp/>than<sp/>a<sp/>big<sp/>honking<sp/>mutex</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="324"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal"><sp/>&lt;</highlight><highlight class="keyword">typename</highlight><highlight class="normal"><sp/>T&gt;</highlight></codeline>
<codeline lineno="325"><highlight class="normal"></highlight><highlight class="keyword">struct<sp/></highlight><highlight class="normal">BenchmarkCache<sp/>{</highlight></codeline>
<codeline lineno="326"><highlight class="normal"><sp/><sp/>std::mutex<sp/>mutex;</highlight></codeline>
<codeline lineno="327"><highlight class="normal"><sp/><sp/>std::unordered_map&lt;ConvolutionParams,<sp/>T,<sp/>ParamsHash&lt;ConvolutionParams&gt;,<sp/>ParamsEqual&lt;ConvolutionParams&gt;&gt;<sp/>map;</highlight></codeline>
<codeline lineno="328"><highlight class="normal"></highlight></codeline>
<codeline lineno="329"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>find(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionParams&amp;<sp/>params,<sp/>T*<sp/>results)<sp/>{</highlight></codeline>
<codeline lineno="330"><highlight class="normal"><sp/><sp/><sp/><sp/>std::lock_guard&lt;std::mutex&gt;<sp/>guard(mutex);</highlight></codeline>
<codeline lineno="331"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>it<sp/>=<sp/>map.find(params);</highlight></codeline>
<codeline lineno="332"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(it<sp/>==<sp/>map.end())<sp/>{</highlight></codeline>
<codeline lineno="333"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">false</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="334"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="335"><highlight class="normal"><sp/><sp/><sp/><sp/>*results<sp/>=<sp/>it-&gt;second;</highlight></codeline>
<codeline lineno="336"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">true</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="337"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="338"><highlight class="normal"></highlight></codeline>
<codeline lineno="339"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>insert(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionParams&amp;<sp/>params,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>T&amp;<sp/>results)<sp/>{</highlight></codeline>
<codeline lineno="340"><highlight class="normal"><sp/><sp/><sp/><sp/>std::lock_guard&lt;std::mutex&gt;<sp/>guard(mutex);</highlight></codeline>
<codeline lineno="341"><highlight class="normal"><sp/><sp/><sp/><sp/>map[params]<sp/>=<sp/>results;</highlight></codeline>
<codeline lineno="342"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="343"><highlight class="normal">};</highlight></codeline>
<codeline lineno="344"><highlight class="normal"></highlight></codeline>
<codeline lineno="345"><highlight class="normal">BenchmarkCache&lt;cudnnConvolutionFwdAlgo_t&gt;<sp/>fwd_algos;</highlight></codeline>
<codeline lineno="346"><highlight class="normal">BenchmarkCache&lt;cudnnConvolutionBwdDataAlgo_t&gt;<sp/>bwd_data_algos;</highlight></codeline>
<codeline lineno="347"><highlight class="normal">BenchmarkCache&lt;cudnnConvolutionBwdFilterAlgo_t&gt;<sp/>bwd_filter_algos;</highlight></codeline>
<codeline lineno="348"><highlight class="normal"></highlight></codeline>
<codeline lineno="349"><highlight class="normal"></highlight><highlight class="comment">//<sp/>TODO:<sp/>Stop<sp/>manually<sp/>allocating<sp/>CUDA<sp/>memory;<sp/>allocate<sp/>an<sp/>ATen<sp/>byte</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="350"><highlight class="normal"></highlight><highlight class="comment">//<sp/>tensor<sp/>instead.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="351"><highlight class="normal"></highlight><highlight class="keyword">struct<sp/></highlight><highlight class="normal">Workspace<sp/>{</highlight></codeline>
<codeline lineno="352"><highlight class="normal"><sp/><sp/>Workspace(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>size)<sp/>:<sp/>size(size),<sp/>data(NULL)<sp/>{</highlight></codeline>
<codeline lineno="353"><highlight class="normal"><sp/><sp/><sp/><sp/>data<sp/>=<sp/>THCudaMalloc(globalContext().lazyInitCUDA(),<sp/>size);</highlight></codeline>
<codeline lineno="354"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="355"><highlight class="normal"><sp/><sp/>Workspace(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Workspace&amp;)<sp/>=<sp/></highlight><highlight class="keyword">delete</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="356"><highlight class="normal"><sp/><sp/>Workspace(Workspace&amp;&amp;)<sp/>=<sp/></highlight><highlight class="keywordflow">default</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="357"><highlight class="normal"><sp/><sp/>Workspace&amp;<sp/>operator=(Workspace&amp;&amp;)<sp/>=<sp/></highlight><highlight class="keywordflow">default</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="358"><highlight class="normal"><sp/><sp/>~Workspace()<sp/>{</highlight></codeline>
<codeline lineno="359"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(data)<sp/>{</highlight></codeline>
<codeline lineno="360"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>THCudaFree(globalContext().lazyInitCUDA(),<sp/>data);</highlight></codeline>
<codeline lineno="361"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="362"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="363"><highlight class="normal"></highlight></codeline>
<codeline lineno="364"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>size;</highlight></codeline>
<codeline lineno="365"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal">*<sp/>data;</highlight></codeline>
<codeline lineno="366"><highlight class="normal">};</highlight></codeline>
<codeline lineno="367"><highlight class="normal"></highlight></codeline>
<codeline lineno="368"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal">&lt;</highlight><highlight class="keyword">typename</highlight><highlight class="normal"><sp/>algo_t&gt;</highlight></codeline>
<codeline lineno="369"><highlight class="normal"></highlight><highlight class="keyword">struct<sp/></highlight><highlight class="normal">algorithm_search<sp/>{</highlight></codeline>
<codeline lineno="370"><highlight class="normal">};</highlight></codeline>
<codeline lineno="371"><highlight class="normal"></highlight></codeline>
<codeline lineno="372"><highlight class="normal">cudnnStatus_t<sp/>getWorkspaceSize(</highlight></codeline>
<codeline lineno="373"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionArgs&amp;<sp/>args,</highlight></codeline>
<codeline lineno="374"><highlight class="normal"><sp/><sp/><sp/><sp/>cudnnConvolutionFwdAlgo_t<sp/>algo,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">*<sp/>sz)</highlight></codeline>
<codeline lineno="375"><highlight class="normal">{</highlight></codeline>
<codeline lineno="376"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>cudnnGetConvolutionForwardWorkspaceSize(</highlight></codeline>
<codeline lineno="377"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.handle,</highlight></codeline>
<codeline lineno="378"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.idesc.desc(),</highlight></codeline>
<codeline lineno="379"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.wdesc.desc(),</highlight></codeline>
<codeline lineno="380"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.cdesc.desc(),</highlight></codeline>
<codeline lineno="381"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.odesc.desc(),</highlight></codeline>
<codeline lineno="382"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>algo,</highlight></codeline>
<codeline lineno="383"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>sz</highlight></codeline>
<codeline lineno="384"><highlight class="normal"><sp/><sp/><sp/><sp/>);</highlight></codeline>
<codeline lineno="385"><highlight class="normal">}</highlight></codeline>
<codeline lineno="386"><highlight class="normal">cudnnStatus_t<sp/>getWorkspaceSize(</highlight></codeline>
<codeline lineno="387"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionArgs&amp;<sp/>args,</highlight></codeline>
<codeline lineno="388"><highlight class="normal"><sp/><sp/><sp/><sp/>cudnnConvolutionBwdDataAlgo_t<sp/>algo,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">*<sp/>sz)</highlight></codeline>
<codeline lineno="389"><highlight class="normal">{</highlight></codeline>
<codeline lineno="390"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>cudnnGetConvolutionBackwardDataWorkspaceSize(</highlight></codeline>
<codeline lineno="391"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.handle,</highlight></codeline>
<codeline lineno="392"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.wdesc.desc(),</highlight></codeline>
<codeline lineno="393"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.odesc.desc(),</highlight></codeline>
<codeline lineno="394"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.cdesc.desc(),</highlight></codeline>
<codeline lineno="395"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.idesc.desc(),</highlight></codeline>
<codeline lineno="396"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>algo,</highlight></codeline>
<codeline lineno="397"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>sz);</highlight></codeline>
<codeline lineno="398"><highlight class="normal">}</highlight></codeline>
<codeline lineno="399"><highlight class="normal">cudnnStatus_t<sp/>getWorkspaceSize(</highlight></codeline>
<codeline lineno="400"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionArgs&amp;<sp/>args,</highlight></codeline>
<codeline lineno="401"><highlight class="normal"><sp/><sp/><sp/><sp/>cudnnConvolutionBwdFilterAlgo_t<sp/>algo,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">*<sp/>sz)</highlight></codeline>
<codeline lineno="402"><highlight class="normal">{</highlight></codeline>
<codeline lineno="403"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>cudnnGetConvolutionBackwardFilterWorkspaceSize(</highlight></codeline>
<codeline lineno="404"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.handle,</highlight></codeline>
<codeline lineno="405"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.idesc.desc(),</highlight></codeline>
<codeline lineno="406"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.odesc.desc(),</highlight></codeline>
<codeline lineno="407"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.cdesc.desc(),</highlight></codeline>
<codeline lineno="408"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.wdesc.desc(),</highlight></codeline>
<codeline lineno="409"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>algo,</highlight></codeline>
<codeline lineno="410"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>sz);</highlight></codeline>
<codeline lineno="411"><highlight class="normal">}</highlight></codeline>
<codeline lineno="412"><highlight class="normal"></highlight></codeline>
<codeline lineno="413"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal">&lt;</highlight><highlight class="keyword">typename</highlight><highlight class="normal"><sp/>algo_t&gt;</highlight></codeline>
<codeline lineno="414"><highlight class="normal"></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>getMaxWorkspaceSize(</highlight></codeline>
<codeline lineno="415"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionArgs&amp;<sp/>args,</highlight></codeline>
<codeline lineno="416"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>algo_t<sp/>*algo,<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>n_algo)</highlight></codeline>
<codeline lineno="417"><highlight class="normal">{</highlight></codeline>
<codeline lineno="418"><highlight class="normal"><sp/><sp/><sp/><sp/>THCState<sp/>*state<sp/>=<sp/>globalContext().lazyInitCUDA();</highlight></codeline>
<codeline lineno="419"><highlight class="normal"></highlight></codeline>
<codeline lineno="420"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>max_ws_size<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="421"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>max_block_size<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="422"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>total_gpu_mem<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="423"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>free_gpu_mem<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="424"><highlight class="normal"></highlight></codeline>
<codeline lineno="425"><highlight class="normal"><sp/><sp/><sp/><sp/>THCudaCheck(THCudaMemGetInfoCached(state,<sp/>&amp;free_gpu_mem,<sp/>&amp;total_gpu_mem,<sp/>&amp;max_block_size));</highlight></codeline>
<codeline lineno="426"><highlight class="normal"></highlight></codeline>
<codeline lineno="427"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>n_algo;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="428"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cudnnStatus_t<sp/>err;</highlight></codeline>
<codeline lineno="429"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>sz;</highlight></codeline>
<codeline lineno="430"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>err<sp/>=<sp/>getWorkspaceSize(args,<sp/>algo[i],<sp/>&amp;sz);</highlight></codeline>
<codeline lineno="431"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(CUDNN_STATUS_SUCCESS<sp/>!=<sp/>err<sp/>||<sp/>sz<sp/>==<sp/>0</highlight></codeline>
<codeline lineno="432"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>||<sp/>sz<sp/>&lt;<sp/>max_ws_size<sp/>||<sp/>sz<sp/>&gt;<sp/>max_block_size)<sp/></highlight><highlight class="keywordflow">continue</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="433"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>max_ws_size<sp/>=<sp/>sz;</highlight></codeline>
<codeline lineno="434"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="435"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>max_ws_size;</highlight></codeline>
<codeline lineno="436"><highlight class="normal">}</highlight></codeline>
<codeline lineno="437"><highlight class="normal"></highlight></codeline>
<codeline lineno="438"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal">&lt;</highlight><highlight class="keyword">typename</highlight><highlight class="normal"><sp/>perf_t&gt;</highlight></codeline>
<codeline lineno="439"><highlight class="normal">perf_t<sp/>getBestAlgorithm(perf_t<sp/>*perfResults,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic,<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>n_algo)<sp/>{</highlight></codeline>
<codeline lineno="440"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(deterministic)<sp/>{</highlight></codeline>
<codeline lineno="441"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>iterate<sp/>over<sp/>perf<sp/>results<sp/>of<sp/>all<sp/>algorithms<sp/>and<sp/>find<sp/>the<sp/>best<sp/>deterministic<sp/>algo</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="442"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>n_algo;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="443"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>Shouldn&apos;t<sp/>all<sp/>returned<sp/>results<sp/>be<sp/>successful?</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="444"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Double<sp/>check<sp/>documentation<sp/>for<sp/>cudnnFindConvolutionForwardAlgorithmEx</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="445"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(perfResults[i].status<sp/>==<sp/>CUDNN_STATUS_SUCCESS<sp/>&amp;&amp;</highlight></codeline>
<codeline lineno="446"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>perfResults[i].determinism<sp/>==<sp/>CUDNN_DETERMINISTIC)<sp/>{</highlight></codeline>
<codeline lineno="447"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>perfResults[i];</highlight></codeline>
<codeline lineno="448"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="449"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="450"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;no<sp/>deterministic<sp/>convolution<sp/>algorithms<sp/>available<sp/>in<sp/>CuDNN&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="451"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="452"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>perfResults[0];</highlight></codeline>
<codeline lineno="453"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="454"><highlight class="normal">}</highlight></codeline>
<codeline lineno="455"><highlight class="normal"></highlight></codeline>
<codeline lineno="456"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal">&lt;&gt;</highlight></codeline>
<codeline lineno="457"><highlight class="normal"></highlight><highlight class="keyword">struct<sp/></highlight><highlight class="normal">algorithm_search&lt;cudnnConvolutionFwdAlgo_t&gt;<sp/>{</highlight></codeline>
<codeline lineno="458"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">using</highlight><highlight class="normal"><sp/>perf_t<sp/>=<sp/>cudnnConvolutionFwdAlgoPerf_t;</highlight></codeline>
<codeline lineno="459"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">using</highlight><highlight class="normal"><sp/>algo_t<sp/>=<sp/>cudnnConvolutionFwdAlgo_t;</highlight></codeline>
<codeline lineno="460"><highlight class="normal"></highlight></codeline>
<codeline lineno="461"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>constexpr<sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>DEFAULT_ALGO<sp/>=<sp/>CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM;</highlight></codeline>
<codeline lineno="462"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>BenchmarkCache&lt;algo_t&gt;&amp;<sp/>cache()<sp/>{<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>fwd_algos;<sp/>}</highlight></codeline>
<codeline lineno="463"><highlight class="normal"></highlight></codeline>
<codeline lineno="464"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>perf_t<sp/>findAlgorithm(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionArgs&amp;<sp/>args)<sp/>{</highlight></codeline>
<codeline lineno="465"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>algo_t<sp/>algos[]<sp/>=<sp/>{</highlight></codeline>
<codeline lineno="466"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_FWD_ALGO_GEMM,</highlight></codeline>
<codeline lineno="467"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_FWD_ALGO_FFT,</highlight></codeline>
<codeline lineno="468"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING,</highlight></codeline>
<codeline lineno="469"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM,</highlight></codeline>
<codeline lineno="470"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM,</highlight></codeline>
<codeline lineno="471"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_FWD_ALGO_DIRECT,</highlight></codeline>
<codeline lineno="472"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD,</highlight></codeline>
<codeline lineno="473"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED,</highlight></codeline>
<codeline lineno="474"><highlight class="normal"><sp/><sp/><sp/><sp/>};</highlight></codeline>
<codeline lineno="475"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>constexpr<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_algos<sp/>=<sp/>CUDNN_CONVOLUTION_FWD_ALGO_COUNT;</highlight></codeline>
<codeline lineno="476"><highlight class="normal"><sp/><sp/><sp/><sp/>static_assert(</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(algos)<sp/>/<sp/></highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(algos[0])<sp/>==<sp/>num_algos,</highlight></codeline>
<codeline lineno="477"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;Missing<sp/>cuDNN<sp/>convolution<sp/>forward<sp/>algorithms&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="478"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>perf_count;</highlight></codeline>
<codeline lineno="479"><highlight class="normal"><sp/><sp/><sp/><sp/>std::unique_ptr&lt;perf_t[]&gt;<sp/>perf_results(</highlight><highlight class="keyword">new</highlight><highlight class="normal"><sp/>perf_t[num_algos]);</highlight></codeline>
<codeline lineno="480"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>max_ws_size<sp/>=<sp/>getMaxWorkspaceSize(args,<sp/>algos,<sp/>num_algos);</highlight></codeline>
<codeline lineno="481"><highlight class="normal"><sp/><sp/><sp/><sp/>Workspace<sp/>ws(max_ws_size);</highlight></codeline>
<codeline lineno="482"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_CUDNN_CHECK(cudnnFindConvolutionForwardAlgorithmEx(</highlight></codeline>
<codeline lineno="483"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.handle,</highlight></codeline>
<codeline lineno="484"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.idesc.desc(),<sp/>args.input.data_ptr(),</highlight></codeline>
<codeline lineno="485"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.wdesc.desc(),<sp/>args.weight.data_ptr(),</highlight></codeline>
<codeline lineno="486"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.cdesc.desc(),</highlight></codeline>
<codeline lineno="487"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.odesc.desc(),<sp/>args.output.data_ptr(),</highlight></codeline>
<codeline lineno="488"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_algos,</highlight></codeline>
<codeline lineno="489"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&amp;perf_count,</highlight></codeline>
<codeline lineno="490"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>perf_results.get(),</highlight></codeline>
<codeline lineno="491"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>ws.data,</highlight></codeline>
<codeline lineno="492"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>ws.size));</highlight></codeline>
<codeline lineno="493"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>getBestAlgorithm(perf_results.get(),<sp/>args.params.deterministic,<sp/>perf_count);</highlight></codeline>
<codeline lineno="494"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="495"><highlight class="normal"></highlight></codeline>
<codeline lineno="496"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>getAlgorithm(</highlight></codeline>
<codeline lineno="497"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionArgs&amp;<sp/>args,</highlight></codeline>
<codeline lineno="498"><highlight class="normal"><sp/><sp/><sp/><sp/>algo_t*<sp/>algo)</highlight></codeline>
<codeline lineno="499"><highlight class="normal"><sp/><sp/>{</highlight></codeline>
<codeline lineno="500"><highlight class="normal"><sp/><sp/><sp/><sp/>cudnnConvolutionFwdPreference_t<sp/>pref<sp/>=<sp/>CUDNN_CONVOLUTION_FWD_PREFER_FASTEST;</highlight></codeline>
<codeline lineno="501"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_CUDNN_CHECK(cudnnGetConvolutionForwardAlgorithm(</highlight></codeline>
<codeline lineno="502"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.handle,</highlight></codeline>
<codeline lineno="503"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.idesc.desc(),</highlight></codeline>
<codeline lineno="504"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.wdesc.desc(),</highlight></codeline>
<codeline lineno="505"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.cdesc.desc(),</highlight></codeline>
<codeline lineno="506"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.odesc.desc(),</highlight></codeline>
<codeline lineno="507"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>pref,</highlight></codeline>
<codeline lineno="508"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>0,</highlight></codeline>
<codeline lineno="509"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>algo));</highlight></codeline>
<codeline lineno="510"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="511"><highlight class="normal"></highlight></codeline>
<codeline lineno="512"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>getWorkspaceSize(</highlight></codeline>
<codeline lineno="513"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionArgs&amp;<sp/>args,</highlight></codeline>
<codeline lineno="514"><highlight class="normal"><sp/><sp/><sp/><sp/>algo_t<sp/>algo,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">*<sp/>workspaceSize)</highlight></codeline>
<codeline lineno="515"><highlight class="normal"><sp/><sp/>{</highlight></codeline>
<codeline lineno="516"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_CUDNN_CHECK(cudnnGetConvolutionForwardWorkspaceSize(</highlight></codeline>
<codeline lineno="517"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.handle,</highlight></codeline>
<codeline lineno="518"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.idesc.desc(),</highlight></codeline>
<codeline lineno="519"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.wdesc.desc(),</highlight></codeline>
<codeline lineno="520"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.cdesc.desc(),</highlight></codeline>
<codeline lineno="521"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.odesc.desc(),</highlight></codeline>
<codeline lineno="522"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>algo,</highlight></codeline>
<codeline lineno="523"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>workspaceSize));</highlight></codeline>
<codeline lineno="524"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="525"><highlight class="normal">};</highlight></codeline>
<codeline lineno="526"><highlight class="normal"></highlight></codeline>
<codeline lineno="527"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal">&lt;&gt;</highlight></codeline>
<codeline lineno="528"><highlight class="normal"></highlight><highlight class="keyword">struct<sp/></highlight><highlight class="normal">algorithm_search&lt;cudnnConvolutionBwdDataAlgo_t&gt;<sp/>{</highlight></codeline>
<codeline lineno="529"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">using</highlight><highlight class="normal"><sp/>perf_t<sp/>=<sp/>cudnnConvolutionBwdDataAlgoPerf_t;</highlight></codeline>
<codeline lineno="530"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">using</highlight><highlight class="normal"><sp/>algo_t<sp/>=<sp/>cudnnConvolutionBwdDataAlgo_t;</highlight></codeline>
<codeline lineno="531"><highlight class="normal"></highlight></codeline>
<codeline lineno="532"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>constexpr<sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>DEFAULT_ALGO<sp/>=<sp/>CUDNN_CONVOLUTION_BWD_DATA_ALGO_1;</highlight></codeline>
<codeline lineno="533"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>BenchmarkCache&lt;algo_t&gt;&amp;<sp/>cache()<sp/>{<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>bwd_data_algos;<sp/>}</highlight></codeline>
<codeline lineno="534"><highlight class="normal"></highlight></codeline>
<codeline lineno="535"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>perf_t<sp/>findAlgorithm(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionArgs&amp;<sp/>args)<sp/>{</highlight></codeline>
<codeline lineno="536"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>algo_t<sp/>algos[]<sp/>=<sp/>{</highlight></codeline>
<codeline lineno="537"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_BWD_DATA_ALGO_0,</highlight></codeline>
<codeline lineno="538"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_BWD_DATA_ALGO_1,</highlight></codeline>
<codeline lineno="539"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT,</highlight></codeline>
<codeline lineno="540"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT_TILING,</highlight></codeline>
<codeline lineno="541"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD,</highlight></codeline>
<codeline lineno="542"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD_NONFUSED</highlight></codeline>
<codeline lineno="543"><highlight class="normal"><sp/><sp/><sp/><sp/>};</highlight></codeline>
<codeline lineno="544"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>constexpr<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_algos<sp/>=<sp/>CUDNN_CONVOLUTION_BWD_DATA_ALGO_COUNT;</highlight></codeline>
<codeline lineno="545"><highlight class="normal"><sp/><sp/><sp/><sp/>static_assert(</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(algos)<sp/>/<sp/></highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(algos[0])<sp/>==<sp/>num_algos,</highlight></codeline>
<codeline lineno="546"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;Missing<sp/>cuDNN<sp/>convolution<sp/>backward<sp/>data<sp/>algorithms.&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="547"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>perf_count;</highlight></codeline>
<codeline lineno="548"><highlight class="normal"><sp/><sp/><sp/><sp/>std::unique_ptr&lt;perf_t[]&gt;<sp/>perf_results(</highlight><highlight class="keyword">new</highlight><highlight class="normal"><sp/>perf_t[num_algos]);</highlight></codeline>
<codeline lineno="549"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>max_ws_size<sp/>=<sp/>getMaxWorkspaceSize(args,<sp/>algos,<sp/>num_algos);</highlight></codeline>
<codeline lineno="550"><highlight class="normal"><sp/><sp/><sp/><sp/>Workspace<sp/>ws(max_ws_size);</highlight></codeline>
<codeline lineno="551"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_CUDNN_CHECK(cudnnFindConvolutionBackwardDataAlgorithmEx(</highlight></codeline>
<codeline lineno="552"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.handle,</highlight></codeline>
<codeline lineno="553"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.wdesc.desc(),<sp/>args.weight.data_ptr(),</highlight></codeline>
<codeline lineno="554"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.odesc.desc(),<sp/>args.output.data_ptr(),</highlight></codeline>
<codeline lineno="555"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.cdesc.desc(),</highlight></codeline>
<codeline lineno="556"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.idesc.desc(),<sp/>args.input.data_ptr(),</highlight></codeline>
<codeline lineno="557"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_algos,</highlight></codeline>
<codeline lineno="558"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&amp;perf_count,</highlight></codeline>
<codeline lineno="559"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>perf_results.get(),</highlight></codeline>
<codeline lineno="560"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>ws.data,</highlight></codeline>
<codeline lineno="561"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>ws.size));</highlight></codeline>
<codeline lineno="562"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>getBestAlgorithm(perf_results.get(),<sp/>args.params.deterministic,<sp/>perf_count);</highlight></codeline>
<codeline lineno="563"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="564"><highlight class="normal"></highlight></codeline>
<codeline lineno="565"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>getAlgorithm(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionArgs&amp;<sp/>args,<sp/>algo_t*<sp/>algo)<sp/>{</highlight></codeline>
<codeline lineno="566"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_CUDNN_CHECK(cudnnGetConvolutionBackwardDataAlgorithm(</highlight></codeline>
<codeline lineno="567"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.handle,</highlight></codeline>
<codeline lineno="568"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.wdesc.desc(),</highlight></codeline>
<codeline lineno="569"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.odesc.desc(),</highlight></codeline>
<codeline lineno="570"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.cdesc.desc(),</highlight></codeline>
<codeline lineno="571"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.idesc.desc(),</highlight></codeline>
<codeline lineno="572"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_BWD_DATA_PREFER_FASTEST,</highlight></codeline>
<codeline lineno="573"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>0,</highlight></codeline>
<codeline lineno="574"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>algo));</highlight></codeline>
<codeline lineno="575"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="576"><highlight class="normal"></highlight></codeline>
<codeline lineno="577"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>getWorkspaceSize(</highlight></codeline>
<codeline lineno="578"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionArgs&amp;<sp/>args,</highlight></codeline>
<codeline lineno="579"><highlight class="normal"><sp/><sp/><sp/><sp/>cudnnConvolutionBwdDataAlgo_t<sp/>algo,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">*<sp/>workspaceSize)</highlight></codeline>
<codeline lineno="580"><highlight class="normal"><sp/><sp/>{</highlight></codeline>
<codeline lineno="581"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_CUDNN_CHECK(cudnnGetConvolutionBackwardDataWorkspaceSize(</highlight></codeline>
<codeline lineno="582"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.handle,</highlight></codeline>
<codeline lineno="583"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.wdesc.desc(),</highlight></codeline>
<codeline lineno="584"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.odesc.desc(),</highlight></codeline>
<codeline lineno="585"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.cdesc.desc(),</highlight></codeline>
<codeline lineno="586"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.idesc.desc(),</highlight></codeline>
<codeline lineno="587"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>algo,</highlight></codeline>
<codeline lineno="588"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>workspaceSize));</highlight></codeline>
<codeline lineno="589"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="590"><highlight class="normal">};</highlight></codeline>
<codeline lineno="591"><highlight class="normal"></highlight></codeline>
<codeline lineno="592"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal">&lt;&gt;</highlight></codeline>
<codeline lineno="593"><highlight class="normal"></highlight><highlight class="keyword">struct<sp/></highlight><highlight class="normal">algorithm_search&lt;cudnnConvolutionBwdFilterAlgo_t&gt;<sp/>{</highlight></codeline>
<codeline lineno="594"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">using</highlight><highlight class="normal"><sp/>perf_t<sp/>=<sp/>cudnnConvolutionBwdFilterAlgoPerf_t;</highlight></codeline>
<codeline lineno="595"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">using</highlight><highlight class="normal"><sp/>algo_t<sp/>=<sp/>cudnnConvolutionBwdFilterAlgo_t;</highlight></codeline>
<codeline lineno="596"><highlight class="normal"></highlight></codeline>
<codeline lineno="597"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>constexpr<sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>DEFAULT_ALGO<sp/>=<sp/>CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1;</highlight></codeline>
<codeline lineno="598"><highlight class="normal"></highlight></codeline>
<codeline lineno="599"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>BenchmarkCache&lt;algo_t&gt;&amp;<sp/>cache()<sp/>{<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>bwd_filter_algos;<sp/>}</highlight></codeline>
<codeline lineno="600"><highlight class="normal"></highlight></codeline>
<codeline lineno="601"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>perf_t<sp/>findAlgorithm(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionArgs&amp;<sp/>args)<sp/>{</highlight></codeline>
<codeline lineno="602"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>algo_t<sp/>algos[]<sp/>=<sp/>{</highlight></codeline>
<codeline lineno="603"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0,</highlight></codeline>
<codeline lineno="604"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1,</highlight></codeline>
<codeline lineno="605"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_BWD_FILTER_ALGO_FFT,</highlight></codeline>
<codeline lineno="606"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_BWD_FILTER_ALGO_3,</highlight></codeline>
<codeline lineno="607"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD_NONFUSED,</highlight></codeline>
<codeline lineno="608"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>CUDNN_VERSION<sp/>&gt;=<sp/>6000</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="609"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_BWD_FILTER_ALGO_FFT_TILING,</highlight></codeline>
<codeline lineno="610"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="611"><highlight class="normal"><sp/><sp/><sp/><sp/>};</highlight></codeline>
<codeline lineno="612"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>NOTE:<sp/>-<sp/>1<sp/>because<sp/>ALGO_WINOGRAD<sp/>is<sp/>not<sp/>implemented</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="613"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/>constexpr<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_algos<sp/>=<sp/>CUDNN_CONVOLUTION_BWD_FILTER_ALGO_COUNT<sp/>-<sp/>1;</highlight></codeline>
<codeline lineno="614"><highlight class="normal"><sp/><sp/><sp/><sp/>static_assert(</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(algos)<sp/>/<sp/></highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(algos[0])<sp/>==<sp/>num_algos,</highlight></codeline>
<codeline lineno="615"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;Missing<sp/>cuDNN<sp/>convolution<sp/>backward<sp/>filter<sp/>algorithms.&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="616"><highlight class="normal"><sp/><sp/><sp/><sp/>std::unique_ptr&lt;perf_t[]&gt;<sp/>perf_results(</highlight><highlight class="keyword">new</highlight><highlight class="normal"><sp/>perf_t[num_algos]);</highlight></codeline>
<codeline lineno="617"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>max_ws_size<sp/>=<sp/>getMaxWorkspaceSize(args,<sp/>algos,<sp/>num_algos);</highlight></codeline>
<codeline lineno="618"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>perf_count;</highlight></codeline>
<codeline lineno="619"><highlight class="normal"><sp/><sp/><sp/><sp/>Workspace<sp/>ws(max_ws_size);</highlight></codeline>
<codeline lineno="620"><highlight class="normal"></highlight></codeline>
<codeline lineno="621"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_CUDNN_CHECK(cudnnFindConvolutionBackwardFilterAlgorithmEx(</highlight></codeline>
<codeline lineno="622"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.handle,</highlight></codeline>
<codeline lineno="623"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.idesc.desc(),<sp/>args.input.data_ptr(),</highlight></codeline>
<codeline lineno="624"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.odesc.desc(),<sp/>args.output.data_ptr(),</highlight></codeline>
<codeline lineno="625"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.cdesc.desc(),</highlight></codeline>
<codeline lineno="626"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.wdesc.desc(),<sp/>args.weight.data_ptr(),</highlight></codeline>
<codeline lineno="627"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_algos,</highlight></codeline>
<codeline lineno="628"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&amp;perf_count,</highlight></codeline>
<codeline lineno="629"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>perf_results.get(),</highlight></codeline>
<codeline lineno="630"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>ws.data,</highlight></codeline>
<codeline lineno="631"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>ws.size));</highlight></codeline>
<codeline lineno="632"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>getBestAlgorithm&lt;perf_t&gt;(perf_results.get(),<sp/>args.params.deterministic,<sp/>perf_count);</highlight></codeline>
<codeline lineno="633"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="634"><highlight class="normal"></highlight></codeline>
<codeline lineno="635"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>getAlgorithm(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionArgs&amp;<sp/>args,<sp/>algo_t*<sp/>algo)<sp/>{</highlight></codeline>
<codeline lineno="636"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_CUDNN_CHECK(cudnnGetConvolutionBackwardFilterAlgorithm(</highlight></codeline>
<codeline lineno="637"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.handle,</highlight></codeline>
<codeline lineno="638"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.idesc.desc(),</highlight></codeline>
<codeline lineno="639"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.odesc.desc(),</highlight></codeline>
<codeline lineno="640"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.cdesc.desc(),</highlight></codeline>
<codeline lineno="641"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.wdesc.desc(),</highlight></codeline>
<codeline lineno="642"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDNN_CONVOLUTION_BWD_FILTER_PREFER_FASTEST,</highlight></codeline>
<codeline lineno="643"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>0,</highlight></codeline>
<codeline lineno="644"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>algo)</highlight></codeline>
<codeline lineno="645"><highlight class="normal"><sp/><sp/><sp/><sp/>);</highlight></codeline>
<codeline lineno="646"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="647"><highlight class="normal"></highlight></codeline>
<codeline lineno="648"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>getWorkspaceSize(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionArgs&amp;<sp/>args,<sp/>algo_t<sp/>algo,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">*<sp/>workspaceSize)</highlight></codeline>
<codeline lineno="649"><highlight class="normal"><sp/><sp/>{</highlight></codeline>
<codeline lineno="650"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_CUDNN_CHECK(cudnnGetConvolutionBackwardFilterWorkspaceSize(</highlight></codeline>
<codeline lineno="651"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.handle,</highlight></codeline>
<codeline lineno="652"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.idesc.desc(),</highlight></codeline>
<codeline lineno="653"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.odesc.desc(),</highlight></codeline>
<codeline lineno="654"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.cdesc.desc(),</highlight></codeline>
<codeline lineno="655"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>args.wdesc.desc(),</highlight></codeline>
<codeline lineno="656"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>algo,</highlight></codeline>
<codeline lineno="657"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>workspaceSize));</highlight></codeline>
<codeline lineno="658"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="659"><highlight class="normal">};</highlight></codeline>
<codeline lineno="660"><highlight class="normal"></highlight></codeline>
<codeline lineno="661"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal">&lt;</highlight><highlight class="keyword">typename</highlight><highlight class="normal"><sp/>algo_t&gt;</highlight></codeline>
<codeline lineno="662"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>findAlgorithm(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionArgs&amp;<sp/>args,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/>algo_t*<sp/>algo)<sp/>{</highlight></codeline>
<codeline lineno="663"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">using</highlight><highlight class="normal"><sp/>search<sp/>=<sp/>algorithm_search&lt;algo_t&gt;;</highlight></codeline>
<codeline lineno="664"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal">&amp;<sp/>cache<sp/>=<sp/>search::cache();</highlight></codeline>
<codeline lineno="665"><highlight class="normal"></highlight></codeline>
<codeline lineno="666"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cache.find(args.params,<sp/>algo))<sp/>{</highlight></codeline>
<codeline lineno="667"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="668"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="669"><highlight class="normal"></highlight></codeline>
<codeline lineno="670"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(args.params.deterministic<sp/>&amp;&amp;<sp/>!benchmark)<sp/>{</highlight></codeline>
<codeline lineno="671"><highlight class="normal"><sp/><sp/><sp/><sp/>*algo<sp/>=<sp/>search::DEFAULT_ALGO;</highlight></codeline>
<codeline lineno="672"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="673"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="674"><highlight class="normal"></highlight></codeline>
<codeline lineno="675"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!benchmark)<sp/>{</highlight></codeline>
<codeline lineno="676"><highlight class="normal"><sp/><sp/><sp/><sp/>search::getAlgorithm(args,<sp/>algo);</highlight></codeline>
<codeline lineno="677"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="678"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="679"><highlight class="normal"></highlight></codeline>
<codeline lineno="680"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cache.find(args.params,<sp/>algo))<sp/>{</highlight></codeline>
<codeline lineno="681"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>re-check<sp/>cache<sp/>since<sp/>another<sp/>thread<sp/>may<sp/>have<sp/>benchmarked<sp/>the<sp/>algorithm</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="682"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="683"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="684"><highlight class="normal"></highlight></codeline>
<codeline lineno="685"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>perfResults<sp/>=<sp/>search::findAlgorithm(args);</highlight></codeline>
<codeline lineno="686"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>for<sp/>deterministic<sp/>algo,<sp/>look<sp/>at<sp/>all<sp/>the<sp/>perf<sp/>results<sp/>and<sp/>return<sp/>the<sp/>best</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="687"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>deterministic<sp/>algo</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="688"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(perfResults.status<sp/>==<sp/>CUDNN_STATUS_SUCCESS<sp/>&amp;&amp;</highlight></codeline>
<codeline lineno="689"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>!(args.params.deterministic<sp/>&amp;&amp;<sp/>perfResults.determinism<sp/>!=<sp/>CUDNN_DETERMINISTIC))<sp/>{</highlight></codeline>
<codeline lineno="690"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>*algo<sp/>=<sp/>perfResults.algo;</highlight></codeline>
<codeline lineno="691"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="692"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>*algo<sp/>=<sp/>search::DEFAULT_ALGO;</highlight></codeline>
<codeline lineno="693"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="694"><highlight class="normal"><sp/><sp/>cache.insert(args.params,<sp/>*algo);</highlight></codeline>
<codeline lineno="695"><highlight class="normal"></highlight></codeline>
<codeline lineno="696"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Free<sp/>the<sp/>cached<sp/>blocks<sp/>in<sp/>our<sp/>caching<sp/>allocator.<sp/>They<sp/>are</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="697"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>needed<sp/>here<sp/>because<sp/>the<sp/>above<sp/>benchmarking<sp/>uses<sp/>a<sp/>huge<sp/>amount<sp/>of<sp/>memory,</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="698"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>e.g.<sp/>a<sp/>few<sp/>GBs.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="699"><highlight class="normal"><sp/><sp/>THCCachingAllocator_emptyCache();</highlight></codeline>
<codeline lineno="700"><highlight class="normal">}</highlight></codeline>
<codeline lineno="701"><highlight class="normal"></highlight></codeline>
<codeline lineno="702"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal">&lt;</highlight><highlight class="keyword">typename</highlight><highlight class="normal"><sp/>algo_t&gt;</highlight></codeline>
<codeline lineno="703"><highlight class="normal">Workspace<sp/>chooseAlgorithm(</highlight></codeline>
<codeline lineno="704"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>ConvolutionArgs&amp;<sp/>args,</highlight></codeline>
<codeline lineno="705"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,</highlight></codeline>
<codeline lineno="706"><highlight class="normal"><sp/><sp/><sp/><sp/>algo_t*<sp/>algo)</highlight></codeline>
<codeline lineno="707"><highlight class="normal">{</highlight></codeline>
<codeline lineno="708"><highlight class="normal"><sp/><sp/>findAlgorithm(args,<sp/>benchmark,<sp/>algo);</highlight></codeline>
<codeline lineno="709"><highlight class="normal"></highlight></codeline>
<codeline lineno="710"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">using</highlight><highlight class="normal"><sp/>search<sp/>=<sp/>algorithm_search&lt;algo_t&gt;;</highlight></codeline>
<codeline lineno="711"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>workspace_size;</highlight></codeline>
<codeline lineno="712"><highlight class="normal"><sp/><sp/>search::getWorkspaceSize(args,<sp/>*algo,<sp/>&amp;workspace_size);</highlight></codeline>
<codeline lineno="713"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">try</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="714"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>Workspace(workspace_size);</highlight></codeline>
<codeline lineno="715"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">catch</highlight><highlight class="normal"><sp/>(std::runtime_error&amp;<sp/>e)<sp/>{</highlight></codeline>
<codeline lineno="716"><highlight class="normal"><sp/><sp/><sp/><sp/>cudaGetLastError();<sp/></highlight><highlight class="comment">//<sp/>clear<sp/>OOM<sp/>error</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="717"><highlight class="normal"></highlight></codeline>
<codeline lineno="718"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>switch<sp/>to<sp/>default<sp/>algorithm<sp/>and<sp/>record<sp/>it<sp/>in<sp/>the<sp/>cache<sp/>to<sp/>prevent</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="719"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>further<sp/>OOM<sp/>errors</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="720"><highlight class="normal"><sp/><sp/><sp/><sp/>*algo<sp/>=<sp/>search::DEFAULT_ALGO;</highlight></codeline>
<codeline lineno="721"><highlight class="normal"><sp/><sp/><sp/><sp/>search::cache().insert(args.params,<sp/>*algo);</highlight></codeline>
<codeline lineno="722"><highlight class="normal"></highlight></codeline>
<codeline lineno="723"><highlight class="normal"><sp/><sp/><sp/><sp/>search::getWorkspaceSize(args,<sp/>*algo,<sp/>&amp;workspace_size);</highlight></codeline>
<codeline lineno="724"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>Workspace(workspace_size);</highlight></codeline>
<codeline lineno="725"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="726"><highlight class="normal">}</highlight></codeline>
<codeline lineno="727"><highlight class="normal"></highlight></codeline>
<codeline lineno="728"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="729"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="730"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Bias<sp/>addition</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="731"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="732"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="733"><highlight class="normal"></highlight></codeline>
<codeline lineno="734"><highlight class="normal"></highlight><highlight class="comment">//<sp/>In-place!</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="735"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>cudnn_convolution_add_bias_(CheckedFrom<sp/>c,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorArg&amp;<sp/>output,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorArg&amp;<sp/>bias)</highlight></codeline>
<codeline lineno="736"><highlight class="normal">{</highlight></codeline>
<codeline lineno="737"><highlight class="normal"><sp/><sp/>checkAllSameType(c,<sp/>{output,<sp/>bias});</highlight></codeline>
<codeline lineno="738"><highlight class="normal"><sp/><sp/>checkAllSameGPU(c,<sp/>{output,<sp/>bias});</highlight></codeline>
<codeline lineno="739"><highlight class="normal"><sp/><sp/>checkSize(c,<sp/>bias,<sp/>{<sp/>output-&gt;size(output_channels_dim)<sp/>});</highlight></codeline>
<codeline lineno="740"><highlight class="normal"></highlight></codeline>
<codeline lineno="741"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>See<sp/>Note<sp/>[CuDNN<sp/>broadcast<sp/>padding].<sp/><sp/>Handle<sp/>the<sp/>left<sp/>padding</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="742"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>ourselves,<sp/>but<sp/>use<sp/>TensorDescriptor&apos;s<sp/>padding<sp/>argument<sp/>to<sp/>do<sp/>the<sp/>rest.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="743"><highlight class="normal"><sp/><sp/>TensorDescriptor<sp/>bdesc,<sp/>odesc;</highlight></codeline>
<codeline lineno="744"><highlight class="normal"><sp/><sp/>bdesc.set(bias-&gt;expand({1,<sp/>bias-&gt;size(0)}),<sp/>output-&gt;dim());</highlight></codeline>
<codeline lineno="745"><highlight class="normal"><sp/><sp/>odesc.set(*output);</highlight></codeline>
<codeline lineno="746"><highlight class="normal"></highlight></codeline>
<codeline lineno="747"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>handle<sp/>=<sp/>getCudnnHandle();</highlight></codeline>
<codeline lineno="748"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dataType<sp/>=<sp/>getCudnnDataType(*bias);</highlight></codeline>
<codeline lineno="749"><highlight class="normal"><sp/><sp/>Constant<sp/>one(dataType,<sp/>1);</highlight></codeline>
<codeline lineno="750"><highlight class="normal"></highlight></codeline>
<codeline lineno="751"><highlight class="normal"><sp/><sp/>AT_CUDNN_CHECK(cudnnAddTensor(handle,<sp/>&amp;one,<sp/>bdesc.desc(),<sp/>bias-&gt;data_ptr(),</highlight></codeline>
<codeline lineno="752"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&amp;one,<sp/>odesc.desc(),<sp/>output-&gt;data_ptr()));</highlight></codeline>
<codeline lineno="753"><highlight class="normal">}</highlight></codeline>
<codeline lineno="754"><highlight class="normal"></highlight></codeline>
<codeline lineno="755"><highlight class="normal"></highlight><highlight class="comment">//<sp/>The<sp/>general<sp/>strategy:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="756"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="757"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>-<sp/>cudnn_convolution<sp/>(Tensor)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="758"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/><sp/>Entry<sp/>points<sp/>for<sp/>clients,<sp/>takes<sp/>bias</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="759"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="760"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>-<sp/>cudnn_convolution_forward<sp/>(TensorArg)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="761"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/><sp/>Entry<sp/>point,<sp/>which<sp/>may<sp/>be<sp/>reused<sp/>between<sp/>regular</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="762"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/><sp/>convolution<sp/>and<sp/>transposed<sp/>convolution.<sp/><sp/>Does<sp/>NOT<sp/>take<sp/>bias.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="763"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="764"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>-<sp/>raw_cudnn_convolution_forward_out<sp/>(Tensor)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="765"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/><sp/>Low<sp/>level<sp/>function<sp/>which<sp/>invokes<sp/>CuDNN,<sp/>and<sp/>takes<sp/>an<sp/>output</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="766"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/><sp/>tensor<sp/>which<sp/>is<sp/>directly<sp/>written<sp/>to<sp/>(thus<sp/>_out).</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="767"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="768"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Where<sp/>does<sp/>argument<sp/>checking<sp/>happen?<sp/><sp/>Here&apos;s<sp/>the<sp/>division<sp/>of</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="769"><highlight class="normal"></highlight><highlight class="comment">//<sp/>responsibility:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="770"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/>-<sp/>Things<sp/>that<sp/>happen<sp/>in<sp/>at::Tensor</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="771"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>-<sp/>TensorArg<sp/>allocation</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="772"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>-<sp/>setCuDNNStreamToCurrent</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="773"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/>-<sp/>Things<sp/>that<sp/>happen<sp/>in<sp/>TensorArg</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="774"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>-<sp/>Check<sp/>arguments<sp/>(type,<sp/>GPU,<sp/>shape)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="775"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="776"><highlight class="normal"></highlight><highlight class="comment">//<sp/>TODO:<sp/>Consider<sp/>renaming<sp/>zero-indexed<sp/>arguments<sp/>to<sp/>&quot;self&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="777"><highlight class="normal"></highlight></codeline>
<codeline lineno="778"><highlight class="normal"></highlight></codeline>
<codeline lineno="779"><highlight class="normal"></highlight></codeline>
<codeline lineno="780"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="781"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="782"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Convolution<sp/>forward<sp/>/<sp/>Transposed<sp/>convolution<sp/>backward</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="783"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="784"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="785"><highlight class="normal"></highlight></codeline>
<codeline lineno="786"><highlight class="normal"></highlight><highlight class="comment">//<sp/>The<sp/>raw<sp/>API<sp/>directly<sp/>invokes<sp/>CuDNN<sp/>and<sp/>does<sp/>not<sp/>emulate<sp/>support</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="787"><highlight class="normal"></highlight><highlight class="comment">//<sp/>for<sp/>group<sp/>convolution<sp/>on<sp/>old<sp/>versions<sp/>of<sp/>CuDNN.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="788"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="789"><highlight class="normal"></highlight><highlight class="comment">//<sp/>There<sp/>are<sp/>a<sp/>few<sp/>reasons<sp/>this<sp/>should<sp/>never<sp/>be<sp/>directly<sp/>exposed</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="790"><highlight class="normal"></highlight><highlight class="comment">//<sp/>via<sp/>ATen:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="791"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="792"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>-<sp/>It<sp/>takes<sp/>output<sp/>as<sp/>a<sp/>parameter<sp/>(this<sp/>should<sp/>be<sp/>computed!)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="793"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>-<sp/>It<sp/>doesn&apos;t<sp/>do<sp/>input<sp/>checking</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="794"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>-<sp/>It<sp/>doesn&apos;t<sp/>resize<sp/>output<sp/>(it<sp/>is<sp/>assumed<sp/>to<sp/>be<sp/>correctly<sp/>sized)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="795"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>-<sp/>It<sp/>takes<sp/>a<sp/>ConvolutionParams<sp/>struct</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="796"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="797"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>raw_cudnn_convolution_forward_out(</highlight></codeline>
<codeline lineno="798"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>output,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>input,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>weight,</highlight></codeline>
<codeline lineno="799"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="800"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)<sp/>{</highlight></codeline>
<codeline lineno="801"><highlight class="normal"></highlight></codeline>
<codeline lineno="802"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dataType<sp/>=<sp/>getCudnnDataType(input);</highlight></codeline>
<codeline lineno="803"><highlight class="normal"></highlight></codeline>
<codeline lineno="804"><highlight class="normal"><sp/><sp/>ConvolutionArgs<sp/>args{<sp/>input,<sp/>output,<sp/>weight<sp/>};</highlight></codeline>
<codeline lineno="805"><highlight class="normal"><sp/><sp/>args.handle<sp/>=<sp/>getCudnnHandle();</highlight></codeline>
<codeline lineno="806"><highlight class="normal"><sp/><sp/>setConvolutionParams(&amp;args.params,<sp/>input,<sp/>weight,<sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>deterministic);</highlight></codeline>
<codeline lineno="807"><highlight class="normal"><sp/><sp/>args.idesc.set(input);</highlight></codeline>
<codeline lineno="808"><highlight class="normal"><sp/><sp/>args.wdesc.set(weight);</highlight></codeline>
<codeline lineno="809"><highlight class="normal"><sp/><sp/>args.odesc.set(output);</highlight></codeline>
<codeline lineno="810"><highlight class="normal"><sp/><sp/>args.cdesc.set(dataType,<sp/>input.dim()<sp/>-<sp/>2,<sp/>args.params.padding,<sp/>args.params.stride,<sp/>args.params.dilation,<sp/>args.params.groups);</highlight></codeline>
<codeline lineno="811"><highlight class="normal"></highlight></codeline>
<codeline lineno="812"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>when<sp/>we<sp/>do<sp/>legacy<sp/>group<sp/>convolution<sp/>support,<sp/>we&apos;ll<sp/>repeatedly</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="813"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>reinitialize<sp/>the<sp/>workspace<sp/>for<sp/>each<sp/>convolution<sp/>we<sp/>do.<sp/><sp/>This<sp/>is</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="814"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>wasteful;<sp/>we&apos;d<sp/>rather<sp/>reuse<sp/>the<sp/>workspace.<sp/><sp/>OTOH,<sp/>legacy<sp/>group</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="815"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>convolution<sp/>support<sp/>is<sp/>already<sp/>pretty<sp/>slow,<sp/>so<sp/>this<sp/>might<sp/>not</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="816"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>matter.<sp/><sp/>(This<sp/>applies<sp/>to<sp/>raw_cudnn_convolution_backward_input<sp/>as<sp/>well.)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="817"><highlight class="normal"><sp/><sp/>cudnnConvolutionFwdAlgo_t<sp/>fwdAlg;</highlight></codeline>
<codeline lineno="818"><highlight class="normal"><sp/><sp/>Workspace<sp/>workspace<sp/>=<sp/>chooseAlgorithm(args,<sp/>benchmark,<sp/>&amp;fwdAlg);</highlight></codeline>
<codeline lineno="819"><highlight class="normal"></highlight></codeline>
<codeline lineno="820"><highlight class="normal"><sp/><sp/>Constant<sp/>one(dataType,<sp/>1);</highlight></codeline>
<codeline lineno="821"><highlight class="normal"><sp/><sp/>Constant<sp/>zero(dataType,<sp/>0);</highlight></codeline>
<codeline lineno="822"><highlight class="normal"></highlight></codeline>
<codeline lineno="823"><highlight class="normal"><sp/><sp/>AT_CUDNN_CHECK(cudnnConvolutionForward(</highlight></codeline>
<codeline lineno="824"><highlight class="normal"><sp/><sp/><sp/><sp/>args.handle,</highlight></codeline>
<codeline lineno="825"><highlight class="normal"><sp/><sp/><sp/><sp/>&amp;one,<sp/>args.idesc.desc(),<sp/>input.data_ptr(),</highlight></codeline>
<codeline lineno="826"><highlight class="normal"><sp/><sp/><sp/><sp/>args.wdesc.desc(),<sp/>weight.data_ptr(),</highlight></codeline>
<codeline lineno="827"><highlight class="normal"><sp/><sp/><sp/><sp/>args.cdesc.desc(),<sp/>fwdAlg,<sp/>workspace.data,<sp/>workspace.size,</highlight></codeline>
<codeline lineno="828"><highlight class="normal"><sp/><sp/><sp/><sp/>&amp;zero,<sp/>args.odesc.desc(),<sp/>output.data_ptr()));</highlight></codeline>
<codeline lineno="829"><highlight class="normal">}</highlight></codeline>
<codeline lineno="830"><highlight class="normal"></highlight></codeline>
<codeline lineno="831"><highlight class="normal">Tensor<sp/>cudnn_convolution_forward(</highlight></codeline>
<codeline lineno="832"><highlight class="normal"><sp/><sp/><sp/><sp/>CheckedFrom<sp/>c,</highlight></codeline>
<codeline lineno="833"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorArg&amp;<sp/>input,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorArg&amp;<sp/>weight,</highlight></codeline>
<codeline lineno="834"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="835"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)</highlight></codeline>
<codeline lineno="836"><highlight class="normal">{</highlight></codeline>
<codeline lineno="837"><highlight class="normal"><sp/><sp/>checkAllSameType(c,<sp/>{input,<sp/>weight});</highlight></codeline>
<codeline lineno="838"><highlight class="normal"><sp/><sp/>checkAllSameGPU(c,<sp/>{input,<sp/>weight});</highlight></codeline>
<codeline lineno="839"><highlight class="normal"></highlight></codeline>
<codeline lineno="840"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>output_t<sp/>=<sp/>input-&gt;type().tensor(</highlight></codeline>
<codeline lineno="841"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>conv_output_size(input-&gt;sizes(),<sp/>weight-&gt;sizes(),</highlight></codeline>
<codeline lineno="842"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups));</highlight></codeline>
<codeline lineno="843"><highlight class="normal"></highlight></codeline>
<codeline lineno="844"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Avoid<sp/>ambiguity<sp/>of<sp/>&quot;output&quot;<sp/>when<sp/>this<sp/>is<sp/>being<sp/>used<sp/>as<sp/>backwards</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="845"><highlight class="normal"><sp/><sp/>TensorArg<sp/>output{<sp/>output_t,<sp/></highlight><highlight class="stringliteral">&quot;result&quot;</highlight><highlight class="normal">,<sp/>0<sp/>};</highlight></codeline>
<codeline lineno="846"><highlight class="normal"><sp/><sp/>convolution_shape_check(c,<sp/>input,<sp/>weight,<sp/>output,<sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups);</highlight></codeline>
<codeline lineno="847"><highlight class="normal"></highlight></codeline>
<codeline lineno="848"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>See<sp/>#4500</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="849"><highlight class="normal"><sp/><sp/>Tensor<sp/>weight_contig<sp/>=<sp/>weight-&gt;contiguous();</highlight></codeline>
<codeline lineno="850"><highlight class="normal"></highlight></codeline>
<codeline lineno="851"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>CUDNN_VERSION<sp/>&lt;<sp/>7000</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="852"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>groups;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="853"><highlight class="normal"><sp/><sp/><sp/><sp/>raw_cudnn_convolution_forward_out(</highlight></codeline>
<codeline lineno="854"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>narrowGroup(*output,<sp/>output_channels_dim,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>i,<sp/>groups),</highlight></codeline>
<codeline lineno="855"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>narrowGroup(*input,<sp/><sp/>input_channels_dim,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>i,<sp/>groups),</highlight></codeline>
<codeline lineno="856"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>narrowGroup(weight_contig,<sp/>weight_output_channels_dim,<sp/>i,<sp/>groups),</highlight></codeline>
<codeline lineno="857"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>padding,<sp/>stride,<sp/>dilation,<sp/>1,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="858"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="859"><highlight class="normal"></highlight><highlight class="preprocessor">#else</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="860"><highlight class="normal"><sp/><sp/>raw_cudnn_convolution_forward_out(</highlight></codeline>
<codeline lineno="861"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>*output,<sp/>*input,<sp/>weight_contig,</highlight></codeline>
<codeline lineno="862"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="863"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="864"><highlight class="normal"></highlight></codeline>
<codeline lineno="865"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>*output;</highlight></codeline>
<codeline lineno="866"><highlight class="normal">}</highlight></codeline>
<codeline lineno="867"><highlight class="normal"></highlight></codeline>
<codeline lineno="868"><highlight class="normal">Tensor<sp/>cudnn_convolution(</highlight></codeline>
<codeline lineno="869"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>input_t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>weight_t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>bias_t,</highlight></codeline>
<codeline lineno="870"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,</highlight></codeline>
<codeline lineno="871"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>groups,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)</highlight></codeline>
<codeline lineno="872"><highlight class="normal">{</highlight></codeline>
<codeline lineno="873"><highlight class="normal"><sp/><sp/>TensorArg<sp/>input<sp/><sp/>{<sp/>input_t,<sp/><sp/></highlight><highlight class="stringliteral">&quot;input&quot;</highlight><highlight class="normal">,<sp/><sp/>1<sp/>},</highlight></codeline>
<codeline lineno="874"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>weight<sp/>{<sp/>weight_t,<sp/></highlight><highlight class="stringliteral">&quot;weight&quot;</highlight><highlight class="normal">,<sp/>2<sp/>},</highlight></codeline>
<codeline lineno="875"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>bias<sp/><sp/><sp/>{<sp/>bias_t,<sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;bias&quot;</highlight><highlight class="normal">,<sp/><sp/><sp/>3<sp/>};</highlight></codeline>
<codeline lineno="876"><highlight class="normal"><sp/><sp/>setCuDNNStreamToCurrent();</highlight></codeline>
<codeline lineno="877"><highlight class="normal"><sp/><sp/>CheckedFrom<sp/>c<sp/>=<sp/></highlight><highlight class="stringliteral">&quot;cudnn_convolution&quot;</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="878"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>output_t<sp/>=<sp/>cudnn_convolution_forward(</highlight></codeline>
<codeline lineno="879"><highlight class="normal"><sp/><sp/><sp/><sp/>c,<sp/>input,<sp/>weight,<sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="880"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(bias-&gt;defined())<sp/>{</highlight></codeline>
<codeline lineno="881"><highlight class="normal"><sp/><sp/><sp/><sp/>cudnn_convolution_add_bias_(c,<sp/>{<sp/>output_t,<sp/></highlight><highlight class="stringliteral">&quot;result&quot;</highlight><highlight class="normal">,<sp/>0<sp/>},<sp/>bias);</highlight></codeline>
<codeline lineno="882"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="883"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>output_t;</highlight></codeline>
<codeline lineno="884"><highlight class="normal">}</highlight></codeline>
<codeline lineno="885"><highlight class="normal"></highlight></codeline>
<codeline lineno="886"><highlight class="normal"></highlight><highlight class="comment">//<sp/>NB:<sp/>output_padding<sp/>not<sp/>needed<sp/>here,<sp/>as<sp/>there<sp/>is<sp/>no<sp/>ambiguity<sp/>to</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="887"><highlight class="normal"></highlight><highlight class="comment">//<sp/>resolve</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="888"><highlight class="normal">Tensor<sp/>cudnn_convolution_transpose_backward_input(</highlight></codeline>
<codeline lineno="889"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_output_t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>weight_t,</highlight></codeline>
<codeline lineno="890"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,</highlight></codeline>
<codeline lineno="891"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>groups,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)</highlight></codeline>
<codeline lineno="892"><highlight class="normal">{</highlight></codeline>
<codeline lineno="893"><highlight class="normal"><sp/><sp/>TensorArg<sp/>grad_output<sp/>{<sp/>grad_output_t,<sp/><sp/></highlight><highlight class="stringliteral">&quot;grad_output&quot;</highlight><highlight class="normal">,<sp/>1<sp/>},</highlight></codeline>
<codeline lineno="894"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>weight<sp/><sp/><sp/><sp/><sp/><sp/>{<sp/>weight_t,<sp/></highlight><highlight class="stringliteral">&quot;weight&quot;</highlight><highlight class="normal">,<sp/>2<sp/>};</highlight></codeline>
<codeline lineno="895"><highlight class="normal"><sp/><sp/>setCuDNNStreamToCurrent();</highlight></codeline>
<codeline lineno="896"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>cudnn_convolution_forward(</highlight></codeline>
<codeline lineno="897"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;cudnn_convolution_transpose_backward_input&quot;</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="898"><highlight class="normal"><sp/><sp/><sp/><sp/>grad_output,<sp/>weight,<sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="899"><highlight class="normal">}</highlight></codeline>
<codeline lineno="900"><highlight class="normal"></highlight></codeline>
<codeline lineno="901"><highlight class="normal">std::tuple&lt;at::Tensor,at::Tensor,at::Tensor&gt;<sp/>cudnn_convolution_transpose_backward(</highlight></codeline>
<codeline lineno="902"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>input,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>grad_output_t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>weight,</highlight></codeline>
<codeline lineno="903"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>output_padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="904"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic,<sp/>std::array&lt;bool,3&gt;<sp/>output_mask)<sp/>{</highlight></codeline>
<codeline lineno="905"><highlight class="normal"></highlight></codeline>
<codeline lineno="906"><highlight class="normal"><sp/><sp/>Tensor<sp/>grad_output<sp/>=<sp/>grad_output_t.contiguous();</highlight></codeline>
<codeline lineno="907"><highlight class="normal"></highlight></codeline>
<codeline lineno="908"><highlight class="normal"><sp/><sp/>Tensor<sp/>grad_input,<sp/>grad_weight,<sp/>grad_bias;</highlight></codeline>
<codeline lineno="909"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(output_mask[0])<sp/>{</highlight></codeline>
<codeline lineno="910"><highlight class="normal"><sp/><sp/><sp/><sp/>grad_input<sp/>=<sp/>at::cudnn_convolution_transpose_backward_input(grad_output,<sp/>weight,<sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="911"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="912"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(output_mask[1])<sp/>{</highlight></codeline>
<codeline lineno="913"><highlight class="normal"><sp/><sp/><sp/><sp/>grad_weight<sp/>=<sp/>at::cudnn_convolution_transpose_backward_weight(weight.sizes(),<sp/>grad_output,<sp/>input,<sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="914"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="915"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(output_mask[2])<sp/>{</highlight></codeline>
<codeline lineno="916"><highlight class="normal"><sp/><sp/><sp/><sp/>grad_bias<sp/>=<sp/>at::cudnn_convolution_backward_bias(grad_output);</highlight></codeline>
<codeline lineno="917"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="918"><highlight class="normal"></highlight></codeline>
<codeline lineno="919"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>std::tuple&lt;Tensor,Tensor,Tensor&gt;{grad_input,<sp/>grad_weight,<sp/>grad_bias};</highlight></codeline>
<codeline lineno="920"><highlight class="normal">}</highlight></codeline>
<codeline lineno="921"><highlight class="normal"></highlight></codeline>
<codeline lineno="922"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="923"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="924"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Convolution<sp/>backward<sp/>/<sp/>Transposed<sp/>convolution<sp/>forward</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="925"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="926"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="927"><highlight class="normal"></highlight></codeline>
<codeline lineno="928"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>raw_cudnn_convolution_backward_input_out(</highlight></codeline>
<codeline lineno="929"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>grad_input,</highlight></codeline>
<codeline lineno="930"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>grad_output,</highlight></codeline>
<codeline lineno="931"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>weight,</highlight></codeline>
<codeline lineno="932"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="933"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)<sp/>{</highlight></codeline>
<codeline lineno="934"><highlight class="normal"></highlight></codeline>
<codeline lineno="935"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dataType<sp/>=<sp/>getCudnnDataType(grad_output);</highlight></codeline>
<codeline lineno="936"><highlight class="normal"></highlight></codeline>
<codeline lineno="937"><highlight class="normal"><sp/><sp/>ConvolutionArgs<sp/>args{<sp/>grad_input,<sp/>grad_output,<sp/>weight<sp/>};</highlight></codeline>
<codeline lineno="938"><highlight class="normal"><sp/><sp/>args.handle<sp/>=<sp/>getCudnnHandle();</highlight></codeline>
<codeline lineno="939"><highlight class="normal"><sp/><sp/>setConvolutionParams(&amp;args.params,<sp/>grad_input,<sp/>weight,<sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>deterministic);</highlight></codeline>
<codeline lineno="940"><highlight class="normal"><sp/><sp/>args.idesc.set(grad_input);</highlight></codeline>
<codeline lineno="941"><highlight class="normal"><sp/><sp/>args.wdesc.set(weight);</highlight></codeline>
<codeline lineno="942"><highlight class="normal"><sp/><sp/>args.odesc.set(grad_output);</highlight></codeline>
<codeline lineno="943"><highlight class="normal"><sp/><sp/>args.cdesc.set(dataType,<sp/>grad_output.dim()<sp/>-<sp/>2,<sp/>args.params.padding,<sp/>args.params.stride,<sp/>args.params.dilation,<sp/>args.params.groups);</highlight></codeline>
<codeline lineno="944"><highlight class="normal"></highlight></codeline>
<codeline lineno="945"><highlight class="normal"><sp/><sp/>cudnnConvolutionBwdDataAlgo_t<sp/>bwdDataAlg;</highlight></codeline>
<codeline lineno="946"><highlight class="normal"><sp/><sp/>Workspace<sp/>workspace<sp/>=<sp/>chooseAlgorithm(args,<sp/>benchmark,<sp/>&amp;bwdDataAlg);</highlight></codeline>
<codeline lineno="947"><highlight class="normal"></highlight></codeline>
<codeline lineno="948"><highlight class="normal"><sp/><sp/>Constant<sp/>one(dataType,<sp/>1);</highlight></codeline>
<codeline lineno="949"><highlight class="normal"><sp/><sp/>Constant<sp/>zero(dataType,<sp/>0);</highlight></codeline>
<codeline lineno="950"><highlight class="normal"></highlight></codeline>
<codeline lineno="951"><highlight class="normal"><sp/><sp/>AT_CUDNN_CHECK(cudnnConvolutionBackwardData(</highlight></codeline>
<codeline lineno="952"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>args.handle,</highlight></codeline>
<codeline lineno="953"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>&amp;one,<sp/>args.wdesc.desc(),<sp/>weight.data_ptr(),</highlight></codeline>
<codeline lineno="954"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>args.odesc.desc(),<sp/>grad_output.data_ptr(),</highlight></codeline>
<codeline lineno="955"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>args.cdesc.desc(),<sp/>bwdDataAlg,<sp/>workspace.data,<sp/>workspace.size,</highlight></codeline>
<codeline lineno="956"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>&amp;zero,<sp/>args.idesc.desc(),<sp/>grad_input.data_ptr()));</highlight></codeline>
<codeline lineno="957"><highlight class="normal">}</highlight></codeline>
<codeline lineno="958"><highlight class="normal"></highlight></codeline>
<codeline lineno="959"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Backward<sp/>and<sp/>transpose<sp/>are<sp/>algorithmically<sp/>equivalent,<sp/>but<sp/>they</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="960"><highlight class="normal"></highlight><highlight class="comment">//<sp/>compute<sp/>their<sp/>geometry<sp/>differently.<sp/><sp/>In<sp/>a<sp/>backwards,<sp/>you<sp/>knew<sp/>what</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="961"><highlight class="normal"></highlight><highlight class="comment">//<sp/>the<sp/>original<sp/>size<sp/>of<sp/>the<sp/>input<sp/>tensor<sp/>was,<sp/>so<sp/>you<sp/>can<sp/>cache<sp/>that</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="962"><highlight class="normal"></highlight><highlight class="comment">//<sp/>geometry<sp/>and<sp/>fill<sp/>it<sp/>directly.<sp/><sp/>In<sp/>transposed<sp/>convolution,<sp/>it<sp/>is</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="963"><highlight class="normal"></highlight><highlight class="comment">//<sp/>more<sp/>conventional<sp/>to<sp/>not<sp/>explicitly<sp/>specify<sp/>the<sp/>output<sp/>(previously</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="964"><highlight class="normal"></highlight><highlight class="comment">//<sp/>input)<sp/>size,<sp/>and<sp/>compute<sp/>it.<sp/><sp/>This,<sp/>however,<sp/>leaves<sp/>a<sp/>degree<sp/>of</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="965"><highlight class="normal"></highlight><highlight class="comment">//<sp/>freedom;<sp/>this<sp/>degree<sp/>of<sp/>freedom<sp/>is<sp/>resolved<sp/>using<sp/>the</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="966"><highlight class="normal"></highlight><highlight class="comment">//<sp/>output_padding<sp/>parameter.<sp/><sp/>Both<sp/>of<sp/>these<sp/>interfaces<sp/>are<sp/>equivalent,</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="967"><highlight class="normal"></highlight><highlight class="comment">//<sp/>but<sp/>they<sp/>are<sp/>differently<sp/>convenient<sp/>depending<sp/>on<sp/>the<sp/>use<sp/>case.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="968"><highlight class="normal"></highlight></codeline>
<codeline lineno="969"><highlight class="normal">Tensor<sp/>cudnn_convolution_backward_input(</highlight></codeline>
<codeline lineno="970"><highlight class="normal"><sp/><sp/><sp/><sp/>CheckedFrom<sp/>c,</highlight></codeline>
<codeline lineno="971"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>input_size,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorArg&amp;<sp/>grad_output,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorArg&amp;<sp/>weight,</highlight></codeline>
<codeline lineno="972"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="973"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)</highlight></codeline>
<codeline lineno="974"><highlight class="normal">{</highlight></codeline>
<codeline lineno="975"><highlight class="normal"><sp/><sp/>checkAllSameType(c,<sp/>{grad_output,<sp/>weight});</highlight></codeline>
<codeline lineno="976"><highlight class="normal"><sp/><sp/>checkAllSameGPU(c,<sp/>{grad_output,<sp/>weight});</highlight></codeline>
<codeline lineno="977"><highlight class="normal"></highlight></codeline>
<codeline lineno="978"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>grad_input_t<sp/>=<sp/>grad_output-&gt;type().tensor(input_size);</highlight></codeline>
<codeline lineno="979"><highlight class="normal"></highlight></codeline>
<codeline lineno="980"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Avoid<sp/>&quot;grad_input&quot;<sp/>when<sp/>this<sp/>is<sp/>being<sp/>used<sp/>as<sp/>transposed<sp/>convolution</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="981"><highlight class="normal"><sp/><sp/>TensorArg<sp/>grad_input{<sp/>grad_input_t,<sp/></highlight><highlight class="stringliteral">&quot;result&quot;</highlight><highlight class="normal">,<sp/>0<sp/>};</highlight></codeline>
<codeline lineno="982"><highlight class="normal"><sp/><sp/>convolution_shape_check(c,<sp/>grad_input,<sp/>weight,<sp/>grad_output,<sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups);</highlight></codeline>
<codeline lineno="983"><highlight class="normal"></highlight></codeline>
<codeline lineno="984"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>See<sp/>#4500</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="985"><highlight class="normal"><sp/><sp/>Tensor<sp/>weight_contig<sp/>=<sp/>weight-&gt;contiguous();</highlight></codeline>
<codeline lineno="986"><highlight class="normal"></highlight></codeline>
<codeline lineno="987"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>CUDNN_VERSION<sp/>&lt;<sp/>7000</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="988"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>groups;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="989"><highlight class="normal"><sp/><sp/><sp/><sp/>raw_cudnn_convolution_backward_input_out(</highlight></codeline>
<codeline lineno="990"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>narrowGroup(*grad_input,<sp/>input_channels_dim,<sp/>i,<sp/>groups),</highlight></codeline>
<codeline lineno="991"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>narrowGroup(*grad_output,<sp/>output_channels_dim,<sp/>i,<sp/>groups),</highlight></codeline>
<codeline lineno="992"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>narrowGroup(weight_contig,<sp/>weight_output_channels_dim,<sp/>i,<sp/>groups),</highlight></codeline>
<codeline lineno="993"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>padding,<sp/>stride,<sp/>dilation,<sp/>1,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="994"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="995"><highlight class="normal"></highlight><highlight class="preprocessor">#else</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="996"><highlight class="normal"><sp/><sp/>raw_cudnn_convolution_backward_input_out(</highlight></codeline>
<codeline lineno="997"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>*grad_input,<sp/>*grad_output,<sp/>weight_contig,</highlight></codeline>
<codeline lineno="998"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="999"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1000"><highlight class="normal"></highlight></codeline>
<codeline lineno="1001"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>*grad_input;</highlight></codeline>
<codeline lineno="1002"><highlight class="normal">}</highlight></codeline>
<codeline lineno="1003"><highlight class="normal"></highlight></codeline>
<codeline lineno="1004"><highlight class="normal">Tensor<sp/>cudnn_convolution_transpose_forward(</highlight></codeline>
<codeline lineno="1005"><highlight class="normal"><sp/><sp/><sp/><sp/>CheckedFrom<sp/>c,</highlight></codeline>
<codeline lineno="1006"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorArg&amp;<sp/>grad_output,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorArg&amp;<sp/>weight,</highlight></codeline>
<codeline lineno="1007"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>output_padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="1008"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)</highlight></codeline>
<codeline lineno="1009"><highlight class="normal">{</highlight></codeline>
<codeline lineno="1010"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>input_size<sp/>=<sp/>conv_input_size(grad_output-&gt;sizes(),<sp/>weight-&gt;sizes(),</highlight></codeline>
<codeline lineno="1011"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>padding,<sp/>output_padding,<sp/>stride,<sp/>dilation,<sp/>groups);</highlight></codeline>
<codeline lineno="1012"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>cudnn_convolution_backward_input(c,<sp/>input_size,<sp/>grad_output,<sp/>weight,</highlight></codeline>
<codeline lineno="1013"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="1014"><highlight class="normal">}</highlight></codeline>
<codeline lineno="1015"><highlight class="normal"></highlight></codeline>
<codeline lineno="1016"><highlight class="normal">Tensor<sp/>cudnn_convolution_backward_input(</highlight></codeline>
<codeline lineno="1017"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>input_size,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_output_t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>weight_t,</highlight></codeline>
<codeline lineno="1018"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="1019"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)</highlight></codeline>
<codeline lineno="1020"><highlight class="normal">{</highlight></codeline>
<codeline lineno="1021"><highlight class="normal"><sp/><sp/>TensorArg<sp/>grad_output{<sp/>grad_output_t,<sp/></highlight><highlight class="stringliteral">&quot;grad_output&quot;</highlight><highlight class="normal">,<sp/>1<sp/>},</highlight></codeline>
<codeline lineno="1022"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>weight{<sp/>weight_t,<sp/></highlight><highlight class="stringliteral">&quot;weight&quot;</highlight><highlight class="normal">,<sp/>2<sp/>};</highlight></codeline>
<codeline lineno="1023"><highlight class="normal"><sp/><sp/>setCuDNNStreamToCurrent();</highlight></codeline>
<codeline lineno="1024"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>cudnn_convolution_backward_input(</highlight></codeline>
<codeline lineno="1025"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;cudnn_convolution_backward_input&quot;</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="1026"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>input_size,<sp/>grad_output,<sp/>weight,</highlight></codeline>
<codeline lineno="1027"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="1028"><highlight class="normal">}</highlight></codeline>
<codeline lineno="1029"><highlight class="normal"></highlight></codeline>
<codeline lineno="1030"><highlight class="normal">std::tuple&lt;at::Tensor,at::Tensor,at::Tensor&gt;<sp/>cudnn_convolution_backward(</highlight></codeline>
<codeline lineno="1031"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>input,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>grad_output_t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/><ref refid="structat_1_1_tensor" kindref="compound">at::Tensor</ref>&amp;<sp/>weight,</highlight></codeline>
<codeline lineno="1032"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="1033"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic,<sp/>std::array&lt;bool,3&gt;<sp/>output_mask)<sp/>{</highlight></codeline>
<codeline lineno="1034"><highlight class="normal"></highlight></codeline>
<codeline lineno="1035"><highlight class="normal"><sp/><sp/>Tensor<sp/>grad_output<sp/>=<sp/>grad_output_t.contiguous();</highlight></codeline>
<codeline lineno="1036"><highlight class="normal"></highlight></codeline>
<codeline lineno="1037"><highlight class="normal"><sp/><sp/>Tensor<sp/>grad_input,<sp/>grad_weight,<sp/>grad_bias;</highlight></codeline>
<codeline lineno="1038"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(output_mask[0])<sp/>{</highlight></codeline>
<codeline lineno="1039"><highlight class="normal"><sp/><sp/><sp/><sp/>grad_input<sp/>=<sp/>at::cudnn_convolution_backward_input(input.sizes(),<sp/>grad_output,<sp/>weight,<sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="1040"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="1041"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(output_mask[1])<sp/>{</highlight></codeline>
<codeline lineno="1042"><highlight class="normal"><sp/><sp/><sp/><sp/>grad_weight<sp/>=<sp/>at::cudnn_convolution_backward_weight(weight.sizes(),<sp/>grad_output,<sp/>input,<sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="1043"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="1044"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(output_mask[2])<sp/>{</highlight></codeline>
<codeline lineno="1045"><highlight class="normal"><sp/><sp/><sp/><sp/>grad_bias<sp/>=<sp/>at::cudnn_convolution_backward_bias(grad_output);</highlight></codeline>
<codeline lineno="1046"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="1047"><highlight class="normal"></highlight></codeline>
<codeline lineno="1048"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>std::tuple&lt;Tensor,Tensor,Tensor&gt;{grad_input,<sp/>grad_weight,<sp/>grad_bias};</highlight></codeline>
<codeline lineno="1049"><highlight class="normal">}</highlight></codeline>
<codeline lineno="1050"><highlight class="normal"></highlight></codeline>
<codeline lineno="1051"><highlight class="normal">Tensor<sp/>cudnn_convolution_transpose(</highlight></codeline>
<codeline lineno="1052"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>input_t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>weight_t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>bias_t,</highlight></codeline>
<codeline lineno="1053"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>output_padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,</highlight></codeline>
<codeline lineno="1054"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>groups,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)</highlight></codeline>
<codeline lineno="1055"><highlight class="normal">{</highlight></codeline>
<codeline lineno="1056"><highlight class="normal"><sp/><sp/>TensorArg<sp/>input<sp/><sp/>{<sp/>input_t,<sp/><sp/></highlight><highlight class="stringliteral">&quot;input&quot;</highlight><highlight class="normal">,<sp/><sp/>1<sp/>},</highlight></codeline>
<codeline lineno="1057"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>weight<sp/>{<sp/>weight_t,<sp/></highlight><highlight class="stringliteral">&quot;weight&quot;</highlight><highlight class="normal">,<sp/>2<sp/>},</highlight></codeline>
<codeline lineno="1058"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>bias<sp/><sp/><sp/>{<sp/>bias_t,<sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;bias&quot;</highlight><highlight class="normal">,<sp/><sp/><sp/>3<sp/>};</highlight></codeline>
<codeline lineno="1059"><highlight class="normal"><sp/><sp/>CheckedFrom<sp/>c<sp/>=<sp/></highlight><highlight class="stringliteral">&quot;cudnn_convolution_transpose&quot;</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="1060"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>output_t<sp/>=<sp/>cudnn_convolution_transpose_forward(</highlight></codeline>
<codeline lineno="1061"><highlight class="normal"><sp/><sp/><sp/><sp/>c,<sp/>input,<sp/>weight,<sp/>padding,<sp/>output_padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="1062"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(bias-&gt;defined())<sp/>{</highlight></codeline>
<codeline lineno="1063"><highlight class="normal"><sp/><sp/><sp/><sp/>cudnn_convolution_add_bias_(c,<sp/>{<sp/>output_t,<sp/></highlight><highlight class="stringliteral">&quot;result&quot;</highlight><highlight class="normal">,<sp/>0<sp/>},<sp/>bias);</highlight></codeline>
<codeline lineno="1064"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="1065"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>output_t;</highlight></codeline>
<codeline lineno="1066"><highlight class="normal">}</highlight></codeline>
<codeline lineno="1067"><highlight class="normal"></highlight></codeline>
<codeline lineno="1068"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1069"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1070"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Convolution<sp/>backward<sp/>(weight)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1071"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1072"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1073"><highlight class="normal"></highlight></codeline>
<codeline lineno="1074"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>raw_cudnn_convolution_backward_weight_out(</highlight></codeline>
<codeline lineno="1075"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_weight,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_output,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>input,</highlight></codeline>
<codeline lineno="1076"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="1077"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)<sp/>{</highlight></codeline>
<codeline lineno="1078"><highlight class="normal"></highlight></codeline>
<codeline lineno="1079"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dataType<sp/>=<sp/>getCudnnDataType(input);</highlight></codeline>
<codeline lineno="1080"><highlight class="normal"></highlight></codeline>
<codeline lineno="1081"><highlight class="normal"><sp/><sp/>ConvolutionArgs<sp/>args{<sp/>input,<sp/>grad_output,<sp/>grad_weight<sp/>};</highlight></codeline>
<codeline lineno="1082"><highlight class="normal"><sp/><sp/>args.handle<sp/>=<sp/>getCudnnHandle();</highlight></codeline>
<codeline lineno="1083"><highlight class="normal"><sp/><sp/>setConvolutionParams(&amp;args.params,<sp/>input,<sp/>grad_weight,<sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>deterministic);</highlight></codeline>
<codeline lineno="1084"><highlight class="normal"><sp/><sp/>args.idesc.set(input);</highlight></codeline>
<codeline lineno="1085"><highlight class="normal"><sp/><sp/>args.wdesc.set(grad_weight);</highlight></codeline>
<codeline lineno="1086"><highlight class="normal"><sp/><sp/>args.odesc.set(grad_output);</highlight></codeline>
<codeline lineno="1087"><highlight class="normal"><sp/><sp/>args.cdesc.set(dataType,<sp/>input.dim()<sp/>-<sp/>2,<sp/>args.params.padding,<sp/>args.params.stride,<sp/>args.params.dilation,<sp/>args.params.groups);</highlight></codeline>
<codeline lineno="1088"><highlight class="normal"></highlight></codeline>
<codeline lineno="1089"><highlight class="normal"><sp/><sp/>cudnnConvolutionBwdFilterAlgo_t<sp/>bwdFilterAlg;</highlight></codeline>
<codeline lineno="1090"><highlight class="normal"><sp/><sp/>Workspace<sp/>workspace<sp/>=<sp/>chooseAlgorithm(args,<sp/>benchmark,<sp/>&amp;bwdFilterAlg);</highlight></codeline>
<codeline lineno="1091"><highlight class="normal"></highlight></codeline>
<codeline lineno="1092"><highlight class="normal"><sp/><sp/>Constant<sp/>one(dataType,<sp/>1);</highlight></codeline>
<codeline lineno="1093"><highlight class="normal"><sp/><sp/>Constant<sp/>zero(dataType,<sp/>0);</highlight></codeline>
<codeline lineno="1094"><highlight class="normal"></highlight></codeline>
<codeline lineno="1095"><highlight class="normal"><sp/><sp/>AT_CUDNN_CHECK(cudnnConvolutionBackwardFilter(</highlight></codeline>
<codeline lineno="1096"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>args.handle,</highlight></codeline>
<codeline lineno="1097"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>&amp;one,<sp/>args.idesc.desc(),<sp/>input.data_ptr(),</highlight></codeline>
<codeline lineno="1098"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>args.odesc.desc(),<sp/>grad_output.data_ptr(),</highlight></codeline>
<codeline lineno="1099"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>args.cdesc.desc(),<sp/>bwdFilterAlg,<sp/>workspace.data,<sp/>workspace.size,</highlight></codeline>
<codeline lineno="1100"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>&amp;zero,<sp/>args.wdesc.desc(),<sp/>grad_weight.data_ptr()));</highlight></codeline>
<codeline lineno="1101"><highlight class="normal">}</highlight></codeline>
<codeline lineno="1102"><highlight class="normal"></highlight></codeline>
<codeline lineno="1103"><highlight class="normal">Tensor<sp/>cudnn_convolution_backward_weight(</highlight></codeline>
<codeline lineno="1104"><highlight class="normal"><sp/><sp/><sp/><sp/>CheckedFrom<sp/>c,</highlight></codeline>
<codeline lineno="1105"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>weight_size,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorArg&amp;<sp/>grad_output,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorArg&amp;<sp/>input,</highlight></codeline>
<codeline lineno="1106"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="1107"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)</highlight></codeline>
<codeline lineno="1108"><highlight class="normal">{</highlight></codeline>
<codeline lineno="1109"><highlight class="normal"></highlight></codeline>
<codeline lineno="1110"><highlight class="normal"><sp/><sp/>checkAllSameType(c,<sp/>{grad_output,<sp/>input});</highlight></codeline>
<codeline lineno="1111"><highlight class="normal"><sp/><sp/>checkAllSameGPU(c,<sp/>{grad_output,<sp/>input});</highlight></codeline>
<codeline lineno="1112"><highlight class="normal"></highlight></codeline>
<codeline lineno="1113"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>grad_weight_t<sp/>=<sp/>grad_output-&gt;type().tensor(weight_size);</highlight></codeline>
<codeline lineno="1114"><highlight class="normal"></highlight></codeline>
<codeline lineno="1115"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>For<sp/>uniformity<sp/>with<sp/>everything<sp/>else,<sp/>although<sp/>it<sp/>seems<sp/>grad_weight</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1116"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>would<sp/>be<sp/>unambiguous<sp/>too.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1117"><highlight class="normal"><sp/><sp/>TensorArg<sp/>grad_weight{<sp/>grad_weight_t,<sp/></highlight><highlight class="stringliteral">&quot;result&quot;</highlight><highlight class="normal">,<sp/>0<sp/>};</highlight></codeline>
<codeline lineno="1118"><highlight class="normal"><sp/><sp/>convolution_shape_check(c,<sp/>input,<sp/>grad_weight,<sp/>grad_output,<sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups);</highlight></codeline>
<codeline lineno="1119"><highlight class="normal"></highlight></codeline>
<codeline lineno="1120"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>CUDNN_VERSION<sp/>&lt;<sp/>7000</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1121"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>groups;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="1122"><highlight class="normal"><sp/><sp/><sp/><sp/>raw_cudnn_convolution_backward_weight_out(</highlight></codeline>
<codeline lineno="1123"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>narrowGroup(*grad_weight,<sp/>weight_output_channels_dim,<sp/>i,<sp/>groups),</highlight></codeline>
<codeline lineno="1124"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>narrowGroup(*grad_output,<sp/>output_channels_dim,<sp/>i,<sp/>groups),</highlight></codeline>
<codeline lineno="1125"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>narrowGroup(*input,<sp/>input_channels_dim,<sp/>i,<sp/>groups),</highlight></codeline>
<codeline lineno="1126"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="1127"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="1128"><highlight class="normal"></highlight><highlight class="preprocessor">#else</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1129"><highlight class="normal"><sp/><sp/>raw_cudnn_convolution_backward_weight_out(</highlight></codeline>
<codeline lineno="1130"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>*grad_weight,<sp/>*grad_output,<sp/>*input,</highlight></codeline>
<codeline lineno="1131"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="1132"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1133"><highlight class="normal"></highlight></codeline>
<codeline lineno="1134"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>grad_weight_t;</highlight></codeline>
<codeline lineno="1135"><highlight class="normal">}</highlight></codeline>
<codeline lineno="1136"><highlight class="normal"></highlight></codeline>
<codeline lineno="1137"><highlight class="normal">Tensor<sp/>cudnn_convolution_backward_weight(</highlight></codeline>
<codeline lineno="1138"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>weight_size,</highlight></codeline>
<codeline lineno="1139"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_output_t,</highlight></codeline>
<codeline lineno="1140"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>input_t,</highlight></codeline>
<codeline lineno="1141"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="1142"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)</highlight></codeline>
<codeline lineno="1143"><highlight class="normal">{</highlight></codeline>
<codeline lineno="1144"><highlight class="normal"><sp/><sp/>TensorArg<sp/>grad_output{<sp/>grad_output_t,<sp/></highlight><highlight class="stringliteral">&quot;grad_output&quot;</highlight><highlight class="normal">,<sp/>1<sp/>},</highlight></codeline>
<codeline lineno="1145"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>input{<sp/>input_t,<sp/></highlight><highlight class="stringliteral">&quot;input&quot;</highlight><highlight class="normal">,<sp/>2<sp/>};</highlight></codeline>
<codeline lineno="1146"><highlight class="normal"><sp/><sp/>setCuDNNStreamToCurrent();</highlight></codeline>
<codeline lineno="1147"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>cudnn_convolution_backward_weight(</highlight></codeline>
<codeline lineno="1148"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;cudnn_convolution_backward_weight&quot;</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="1149"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>weight_size,<sp/>grad_output,<sp/>input,</highlight></codeline>
<codeline lineno="1150"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="1151"><highlight class="normal">}</highlight></codeline>
<codeline lineno="1152"><highlight class="normal"></highlight></codeline>
<codeline lineno="1153"><highlight class="normal">Tensor<sp/>cudnn_convolution_transpose_backward_weight(</highlight></codeline>
<codeline lineno="1154"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>weight_size,</highlight></codeline>
<codeline lineno="1155"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_output_t,</highlight></codeline>
<codeline lineno="1156"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>input_t,</highlight></codeline>
<codeline lineno="1157"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>padding,<sp/>IntList<sp/>stride,<sp/>IntList<sp/>dilation,<sp/>int64_t<sp/>groups,</highlight></codeline>
<codeline lineno="1158"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>benchmark,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>deterministic)</highlight></codeline>
<codeline lineno="1159"><highlight class="normal">{</highlight></codeline>
<codeline lineno="1160"><highlight class="normal"><sp/><sp/>TensorArg<sp/>grad_output{<sp/>grad_output_t,<sp/></highlight><highlight class="stringliteral">&quot;grad_output&quot;</highlight><highlight class="normal">,<sp/>1<sp/>},</highlight></codeline>
<codeline lineno="1161"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>input{<sp/>input_t,<sp/></highlight><highlight class="stringliteral">&quot;input&quot;</highlight><highlight class="normal">,<sp/>2<sp/>};</highlight></codeline>
<codeline lineno="1162"><highlight class="normal"><sp/><sp/>setCuDNNStreamToCurrent();</highlight></codeline>
<codeline lineno="1163"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>cudnn_convolution_backward_weight(</highlight></codeline>
<codeline lineno="1164"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;cudnn_convolution_backward_weight&quot;</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="1165"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>weight_size,<sp/>input,<sp/>grad_output,</highlight></codeline>
<codeline lineno="1166"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>padding,<sp/>stride,<sp/>dilation,<sp/>groups,<sp/>benchmark,<sp/>deterministic);</highlight></codeline>
<codeline lineno="1167"><highlight class="normal">}</highlight></codeline>
<codeline lineno="1168"><highlight class="normal"></highlight></codeline>
<codeline lineno="1169"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1170"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1171"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Convolution<sp/>backward<sp/>(bias)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1172"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1173"><highlight class="normal"></highlight><highlight class="comment">//<sp/>---------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1174"><highlight class="normal"></highlight></codeline>
<codeline lineno="1175"><highlight class="normal">Tensor<sp/>cudnn_convolution_backward_bias(</highlight></codeline>
<codeline lineno="1176"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_output_t)</highlight></codeline>
<codeline lineno="1177"><highlight class="normal">{</highlight></codeline>
<codeline lineno="1178"><highlight class="normal"><sp/><sp/>TensorArg<sp/>grad_output{<sp/>grad_output_t,<sp/></highlight><highlight class="stringliteral">&quot;grad_output&quot;</highlight><highlight class="normal">,<sp/>1<sp/>};</highlight></codeline>
<codeline lineno="1179"><highlight class="normal"><sp/><sp/>setCuDNNStreamToCurrent();</highlight></codeline>
<codeline lineno="1180"><highlight class="normal"></highlight></codeline>
<codeline lineno="1181"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>grad_bias_t<sp/>=<sp/>grad_output-&gt;type().tensor(</highlight></codeline>
<codeline lineno="1182"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>{<sp/>grad_output-&gt;size(output_channels_dim)<sp/>});</highlight></codeline>
<codeline lineno="1183"><highlight class="normal"></highlight></codeline>
<codeline lineno="1184"><highlight class="normal"><sp/><sp/>TensorArg<sp/>grad_bias{<sp/>grad_bias_t,<sp/></highlight><highlight class="stringliteral">&quot;result&quot;</highlight><highlight class="normal">,<sp/>0<sp/>};</highlight></codeline>
<codeline lineno="1185"><highlight class="normal"></highlight></codeline>
<codeline lineno="1186"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>See<sp/>Note<sp/>[CuDNN<sp/>broadcast<sp/>padding].<sp/><sp/>Handle<sp/>the<sp/>left<sp/>padding</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1187"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>ourselves,<sp/>but<sp/>use<sp/>TensorDescriptor&apos;s<sp/>pad<sp/>argument<sp/>to<sp/>do<sp/>the<sp/>rest.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1188"><highlight class="normal"><sp/><sp/>TensorDescriptor<sp/>bdesc{grad_bias-&gt;expand({1,<sp/>grad_bias-&gt;size(0)}),</highlight></codeline>
<codeline lineno="1189"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>static_cast&lt;size_t&gt;(grad_output-&gt;dim())};</highlight></codeline>
<codeline lineno="1190"><highlight class="normal"><sp/><sp/>TensorDescriptor<sp/>odesc{*grad_output};</highlight></codeline>
<codeline lineno="1191"><highlight class="normal"></highlight></codeline>
<codeline lineno="1192"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>handle<sp/>=<sp/>getCudnnHandle();</highlight></codeline>
<codeline lineno="1193"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dataType<sp/>=<sp/>getCudnnDataType(*grad_bias);</highlight></codeline>
<codeline lineno="1194"><highlight class="normal"><sp/><sp/>Constant<sp/>one(dataType,<sp/>1);</highlight></codeline>
<codeline lineno="1195"><highlight class="normal"><sp/><sp/>Constant<sp/>zero(dataType,<sp/>0);</highlight></codeline>
<codeline lineno="1196"><highlight class="normal"></highlight></codeline>
<codeline lineno="1197"><highlight class="normal"><sp/><sp/>AT_CUDNN_CHECK(cudnnConvolutionBackwardBias(handle,<sp/>&amp;one,<sp/>odesc.desc(),<sp/>grad_output-&gt;data_ptr(),</highlight></codeline>
<codeline lineno="1198"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&amp;zero,<sp/>bdesc.desc(),<sp/>grad_bias-&gt;data_ptr()));</highlight></codeline>
<codeline lineno="1199"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>*grad_bias;</highlight></codeline>
<codeline lineno="1200"><highlight class="normal">}</highlight></codeline>
<codeline lineno="1201"><highlight class="normal"></highlight></codeline>
<codeline lineno="1202"><highlight class="normal"></highlight></codeline>
<codeline lineno="1203"><highlight class="normal">}}<sp/><sp/></highlight><highlight class="comment">//<sp/>namespace</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1204"><highlight class="normal"></highlight></codeline>
<codeline lineno="1205"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight></codeline>
    </programlisting>
    <location file="/Users/robkunkle/fork/goodlux/pytorch/aten/src/ATen/native/cudnn/Conv.cpp"/>
  </compounddef>
</doxygen>
