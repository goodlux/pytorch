<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.14">
  <compounddef id="structtorch_1_1optim_1_1_adagrad_options" kind="struct" language="C++" prot="public" abstract="yes">
    <compoundname>torch::optim::AdagradOptions</compoundname>
      <sectiondef kind="public-func">
      <memberdef kind="function" id="structtorch_1_1optim_1_1_adagrad_options_1aa718f374597ba35ec46641050c26409a" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type></type>
        <definition>torch::optim::AdagradOptions::AdagradOptions</definition>
        <argsstring>(double learning_rate)</argsstring>
        <name>AdagradOptions</name>
        <param>
          <type>double</type>
          <declname>learning_rate</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/Users/robkunkle/fork/goodlux/pytorch/torch/csrc/api/include/torch/optim/adagrad.h" line="19" column="1" bodyfile="/Users/robkunkle/fork/goodlux/pytorch/torch/csrc/api/src/optim/adagrad.cpp" bodystart="12" bodyend="13"/>
      </memberdef>
      <memberdef kind="function" id="structtorch_1_1optim_1_1_adagrad_options_1a3eabd39f8b6b02457caceef5005bd7ab" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type></type>
        <definition>torch::optim::AdagradOptions::TORCH_ARG</definition>
        <argsstring>(double, learning_rate)</argsstring>
        <name>TORCH_ARG</name>
        <param>
          <type>double</type>
        </param>
        <param>
          <type>learning_rate</type>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/Users/robkunkle/fork/goodlux/pytorch/torch/csrc/api/include/torch/optim/adagrad.h" line="20" column="1"/>
      </memberdef>
      <memberdef kind="function" id="structtorch_1_1optim_1_1_adagrad_options_1a4a21b358c193561e1cc03819cea6b410" prot="public" static="no" const="no" explicit="no" inline="no" virt="pure-virtual">
        <type></type>
        <definition>torch::optim::AdagradOptions::TORCH_ARG</definition>
        <argsstring>(double, lr_decay)=0</argsstring>
        <name>TORCH_ARG</name>
        <param>
          <type>double</type>
        </param>
        <param>
          <type>lr_decay</type>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/Users/robkunkle/fork/goodlux/pytorch/torch/csrc/api/include/torch/optim/adagrad.h" line="21" column="1"/>
      </memberdef>
      <memberdef kind="function" id="structtorch_1_1optim_1_1_adagrad_options_1aadf6217d6269cd6c4e87e99fe23d4dd3" prot="public" static="no" const="no" explicit="no" inline="no" virt="pure-virtual">
        <type></type>
        <definition>torch::optim::AdagradOptions::TORCH_ARG</definition>
        <argsstring>(double, weight_decay)=0</argsstring>
        <name>TORCH_ARG</name>
        <param>
          <type>double</type>
        </param>
        <param>
          <type>weight_decay</type>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/Users/robkunkle/fork/goodlux/pytorch/torch/csrc/api/include/torch/optim/adagrad.h" line="22" column="1"/>
      </memberdef>
      </sectiondef>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <location file="/Users/robkunkle/fork/goodlux/pytorch/torch/csrc/api/include/torch/optim/adagrad.h" line="18" column="1" bodyfile="/Users/robkunkle/fork/goodlux/pytorch/torch/csrc/api/include/torch/optim/adagrad.h" bodystart="18" bodyend="23"/>
    <listofallmembers>
      <member refid="structtorch_1_1optim_1_1_adagrad_options_1aa718f374597ba35ec46641050c26409a" prot="public" virt="non-virtual"><scope>torch::optim::AdagradOptions</scope><name>AdagradOptions</name></member>
      <member refid="structtorch_1_1optim_1_1_adagrad_options_1a3eabd39f8b6b02457caceef5005bd7ab" prot="public" virt="non-virtual"><scope>torch::optim::AdagradOptions</scope><name>TORCH_ARG</name></member>
      <member refid="structtorch_1_1optim_1_1_adagrad_options_1a4a21b358c193561e1cc03819cea6b410" prot="public" virt="pure-virtual"><scope>torch::optim::AdagradOptions</scope><name>TORCH_ARG</name></member>
      <member refid="structtorch_1_1optim_1_1_adagrad_options_1aadf6217d6269cd6c4e87e99fe23d4dd3" prot="public" virt="pure-virtual"><scope>torch::optim::AdagradOptions</scope><name>TORCH_ARG</name></member>
    </listofallmembers>
  </compounddef>
</doxygen>
