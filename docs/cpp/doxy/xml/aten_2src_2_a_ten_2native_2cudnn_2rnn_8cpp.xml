<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.14">
  <compounddef id="aten_2src_2_a_ten_2native_2cudnn_2rnn_8cpp" kind="file" language="C++">
    <compoundname>RNN.cpp</compoundname>
    <includes refid="_a_ten_8h" local="no">ATen/ATen.h</includes>
    <includes refid="_tensor_utils_8h" local="no">ATen/TensorUtils.h</includes>
    <includes refid="_config_8h" local="no">ATen/Config.h</includes>
    <includes refid="_error_8h" local="no">ATen/Error.h</includes>
    <includes refid="_matrix_ref_8h" local="no">ATen/MatrixRef.h</includes>
    <includes local="no">ATen/NativeFunctions.h</includes>
    <includes refid="_c_u_d_a_config_8h" local="no">ATen/cuda/CUDAConfig.h</includes>
    <includes refid="cuda_2_exceptions_8h" local="no">ATen/cuda/Exceptions.h</includes>
    <incdepgraph>
      <node id="19001">
        <label>ATen/optional.h</label>
        <link refid="optional_8h_source"/>
        <childnode refid="19002" relation="include">
        </childnode>
        <childnode refid="19003" relation="include">
        </childnode>
        <childnode refid="19004" relation="include">
        </childnode>
        <childnode refid="19005" relation="include">
        </childnode>
        <childnode refid="19006" relation="include">
        </childnode>
        <childnode refid="19007" relation="include">
        </childnode>
        <childnode refid="19008" relation="include">
        </childnode>
      </node>
      <node id="19047">
        <label>ATen/detail/CUDAHooksInterface.h</label>
        <link refid="_c_u_d_a_hooks_interface_8h_source"/>
        <childnode refid="18997" relation="include">
        </childnode>
        <childnode refid="19000" relation="include">
        </childnode>
        <childnode refid="19045" relation="include">
        </childnode>
        <childnode refid="19048" relation="include">
        </childnode>
        <childnode refid="19009" relation="include">
        </childnode>
        <childnode refid="19006" relation="include">
        </childnode>
        <childnode refid="18998" relation="include">
        </childnode>
      </node>
      <node id="19015">
        <label>ATen/Device.h</label>
        <link refid="_device_8h_source"/>
        <childnode refid="19000" relation="include">
        </childnode>
        <childnode refid="19016" relation="include">
        </childnode>
        <childnode refid="19009" relation="include">
        </childnode>
        <childnode refid="19031" relation="include">
        </childnode>
        <childnode refid="19007" relation="include">
        </childnode>
        <childnode refid="19006" relation="include">
        </childnode>
      </node>
      <node id="19014">
        <label>atomic</label>
      </node>
      <node id="19006">
        <label>functional</label>
      </node>
      <node id="19052">
        <label>ATen/Backtrace.h</label>
        <link refid="_backtrace_8h_source"/>
        <childnode refid="19009" relation="include">
        </childnode>
        <childnode refid="19007" relation="include">
        </childnode>
        <childnode refid="19042" relation="include">
        </childnode>
        <childnode refid="18995" relation="include">
        </childnode>
      </node>
      <node id="19016">
        <label>ATen/ScalarType.h</label>
        <link refid="_scalar_type_8h_source"/>
        <childnode refid="19017" relation="include">
        </childnode>
        <childnode refid="18995" relation="include">
        </childnode>
        <childnode refid="19027" relation="include">
        </childnode>
        <childnode refid="19029" relation="include">
        </childnode>
        <childnode refid="19033" relation="include">
        </childnode>
      </node>
      <node id="19028">
        <label>limits</label>
      </node>
      <node id="19036">
        <label>assert.h</label>
      </node>
      <node id="19041">
        <label>ATen/Utils.h</label>
        <link refid="aten_2src_2_a_ten_2utils_8h_source"/>
        <childnode refid="18995" relation="include">
        </childnode>
        <childnode refid="19017" relation="include">
        </childnode>
        <childnode refid="19000" relation="include">
        </childnode>
        <childnode refid="19040" relation="include">
        </childnode>
        <childnode refid="19020" relation="include">
        </childnode>
        <childnode refid="19012" relation="include">
        </childnode>
        <childnode refid="19042" relation="include">
        </childnode>
        <childnode refid="19043" relation="include">
        </childnode>
      </node>
      <node id="19023">
        <label>iterator</label>
      </node>
      <node id="19035">
        <label>ATen/Scalar.h</label>
        <link refid="_scalar_8h_source"/>
        <childnode refid="19036" relation="include">
        </childnode>
        <childnode refid="19037" relation="include">
        </childnode>
        <childnode refid="19008" relation="include">
        </childnode>
        <childnode refid="19007" relation="include">
        </childnode>
        <childnode refid="19002" relation="include">
        </childnode>
        <childnode refid="18995" relation="include">
        </childnode>
        <childnode refid="19027" relation="include">
        </childnode>
        <childnode refid="19016" relation="include">
        </childnode>
        <childnode refid="19038" relation="include">
        </childnode>
        <childnode refid="19041" relation="include">
        </childnode>
      </node>
      <node id="19055">
        <label>TH/THStorageFunctions.hpp</label>
      </node>
      <node id="19029">
        <label>cstdint</label>
      </node>
      <node id="19063">
        <label>ATen/Deprecated.h</label>
        <link refid="_deprecated_8h_source"/>
      </node>
      <node id="19037">
        <label>stdint.h</label>
      </node>
      <node id="19074">
        <label>ATen/CUDAGuard.h</label>
        <link refid="_c_u_d_a_guard_8h_source"/>
      </node>
      <node id="19078">
        <label>ATen/cuda/CUDAConfig.h</label>
        <link refid="_c_u_d_a_config_8h_source"/>
      </node>
      <node id="19030">
        <label>cmath</label>
      </node>
      <node id="19005">
        <label>cassert</label>
      </node>
      <node id="19046">
        <label>ATen/Context.h</label>
        <link refid="_context_8h_source"/>
        <childnode refid="18995" relation="include">
        </childnode>
        <childnode refid="18996" relation="include">
        </childnode>
        <childnode refid="19045" relation="include">
        </childnode>
        <childnode refid="19044" relation="include">
        </childnode>
        <childnode refid="19041" relation="include">
        </childnode>
        <childnode refid="19000" relation="include">
        </childnode>
        <childnode refid="19047" relation="include">
        </childnode>
        <childnode refid="19053" relation="include">
        </childnode>
        <childnode refid="18998" relation="include">
        </childnode>
        <childnode refid="19050" relation="include">
        </childnode>
        <childnode refid="19029" relation="include">
        </childnode>
      </node>
      <node id="19032">
        <label>Half-inl.h</label>
        <link refid="_half-inl_8h_source"/>
        <childnode refid="18995" relation="include">
        </childnode>
        <childnode refid="19022" relation="include">
        </childnode>
        <childnode refid="19028" relation="include">
        </childnode>
      </node>
      <node id="19008">
        <label>stdexcept</label>
      </node>
      <node id="19069">
        <label>ATen/TensorOperators.h</label>
        <link refid="_tensor_operators_8h_source"/>
        <childnode refid="19035" relation="include">
        </childnode>
        <childnode refid="19056" relation="include">
        </childnode>
        <childnode refid="19044" relation="include">
        </childnode>
        <childnode refid="19007" relation="include">
        </childnode>
        <childnode refid="19008" relation="include">
        </childnode>
      </node>
      <node id="19043">
        <label>numeric</label>
      </node>
      <node id="19039">
        <label>ATen/TensorImpl.h</label>
        <link refid="_tensor_impl_8h_source"/>
        <childnode refid="19014" relation="include">
        </childnode>
        <childnode refid="18998" relation="include">
        </childnode>
        <childnode refid="19013" relation="include">
        </childnode>
        <childnode refid="19016" relation="include">
        </childnode>
        <childnode refid="19001" relation="include">
        </childnode>
      </node>
      <node id="19027">
        <label>ATen/Half.h</label>
        <link refid="_half_8h_source"/>
        <childnode refid="18995" relation="include">
        </childnode>
        <childnode refid="19028" relation="include">
        </childnode>
        <childnode refid="19007" relation="include">
        </childnode>
        <childnode refid="19029" relation="include">
        </childnode>
        <childnode refid="19008" relation="include">
        </childnode>
        <childnode refid="19002" relation="include">
        </childnode>
        <childnode refid="19030" relation="include">
        </childnode>
        <childnode refid="19031" relation="include">
        </childnode>
        <childnode refid="19032" relation="include">
        </childnode>
      </node>
      <node id="19013">
        <label>ATen/Retainable.h</label>
        <link refid="_retainable_8h_source"/>
        <childnode refid="19014" relation="include">
        </childnode>
      </node>
      <node id="19038">
        <label>ATen/TensorBase.h</label>
        <link refid="_tensor_base_8h_source"/>
        <childnode refid="19039" relation="include">
        </childnode>
        <childnode refid="19040" relation="include">
        </childnode>
      </node>
      <node id="19007">
        <label>string</label>
      </node>
      <node id="19079">
        <label>ATen/cuda/Exceptions.h</label>
        <link refid="cuda_2_exceptions_8h_source"/>
        <childnode refid="19000" relation="include">
        </childnode>
      </node>
      <node id="19072">
        <label>ATen/DimVector.h</label>
        <link refid="_dim_vector_8h_source"/>
        <childnode refid="19018" relation="include">
        </childnode>
        <childnode refid="19037" relation="include">
        </childnode>
      </node>
      <node id="19073">
        <label>ATen/OptionsGuard.h</label>
        <link refid="_options_guard_8h_source"/>
        <childnode refid="19015" relation="include">
        </childnode>
        <childnode refid="19059" relation="include">
        </childnode>
        <childnode refid="19016" relation="include">
        </childnode>
        <childnode refid="19066" relation="include">
        </childnode>
        <childnode refid="19001" relation="include">
        </childnode>
      </node>
      <node id="19076">
        <label>ATen/Config.h</label>
        <link refid="_config_8h_source"/>
      </node>
      <node id="18997">
        <label>ATen/Allocator.h</label>
        <link refid="_allocator_8h_source"/>
        <childnode refid="18998" relation="include">
        </childnode>
        <childnode refid="18999" relation="include">
        </childnode>
        <childnode refid="19000" relation="include">
        </childnode>
        <childnode refid="19013" relation="include">
        </childnode>
        <childnode refid="19015" relation="include">
        </childnode>
        <childnode refid="19034" relation="include">
        </childnode>
      </node>
      <node id="19053">
        <label>ATen/CUDAStream.h</label>
        <link refid="_c_u_d_a_stream_8h_source"/>
      </node>
      <node id="19065">
        <label>ATen/DeviceGuard.h</label>
        <link refid="_device_guard_8h_source"/>
        <childnode refid="19015" relation="include">
        </childnode>
        <childnode refid="19000" relation="include">
        </childnode>
        <childnode refid="19016" relation="include">
        </childnode>
        <childnode refid="19056" relation="include">
        </childnode>
        <childnode refid="19047" relation="include">
        </childnode>
        <childnode refid="19009" relation="include">
        </childnode>
      </node>
      <node id="19010">
        <label>exception</label>
      </node>
      <node id="18999">
        <label>stddef.h</label>
      </node>
      <node id="19040">
        <label>ATen/UndefinedTensor.h</label>
        <link refid="_undefined_tensor_8h_source"/>
        <childnode refid="19039" relation="include">
        </childnode>
      </node>
      <node id="19071">
        <label>ATen/Dispatch.h</label>
        <link refid="_dispatch_8h_source"/>
        <childnode refid="19000" relation="include">
        </childnode>
        <childnode refid="19027" relation="include">
        </childnode>
        <childnode refid="19044" relation="include">
        </childnode>
      </node>
      <node id="19019">
        <label>AlignOf.h</label>
        <link refid="_align_of_8h_source"/>
        <childnode refid="19009" relation="include">
        </childnode>
      </node>
      <node id="19054">
        <label>ATen/Storage.h</label>
        <link refid="_storage_8h_source"/>
        <childnode refid="19035" relation="include">
        </childnode>
        <childnode refid="19055" relation="include">
        </childnode>
      </node>
      <node id="19011">
        <label>ostream</label>
      </node>
      <node id="18996">
        <label>ATen/CPUGeneral.h</label>
        <link refid="_c_p_u_general_8h_source"/>
        <childnode refid="18995" relation="include">
        </childnode>
      </node>
      <node id="19044">
        <label>ATen/Type.h</label>
      </node>
      <node id="19017">
        <label>ATen/ArrayRef.h</label>
        <link refid="_array_ref_8h_source"/>
        <childnode refid="19000" relation="include">
        </childnode>
        <childnode refid="19018" relation="include">
        </childnode>
        <childnode refid="19025" relation="include">
        </childnode>
        <childnode refid="19023" relation="include">
        </childnode>
        <childnode refid="19026" relation="include">
        </childnode>
      </node>
      <node id="19060">
        <label>ATen/TensorGeometry.h</label>
        <link refid="_tensor_geometry_8h_source"/>
        <childnode refid="19044" relation="include">
        </childnode>
        <childnode refid="19061" relation="include">
        </childnode>
      </node>
      <node id="19057">
        <label>ATen/SparseTensorRef.h</label>
        <link refid="_sparse_tensor_ref_8h_source"/>
      </node>
      <node id="19075">
        <label>ATen/TensorUtils.h</label>
        <link refid="_tensor_utils_8h_source"/>
        <childnode refid="19056" relation="include">
        </childnode>
        <childnode refid="19060" relation="include">
        </childnode>
        <childnode refid="19041" relation="include">
        </childnode>
      </node>
      <node id="19077">
        <label>ATen/MatrixRef.h</label>
        <link refid="_matrix_ref_8h_source"/>
        <childnode refid="19017" relation="include">
        </childnode>
        <childnode refid="19041" relation="include">
        </childnode>
        <childnode refid="19026" relation="include">
        </childnode>
      </node>
      <node id="18995">
        <label>ATen/ATenGeneral.h</label>
        <link refid="_a_ten_general_8h_source"/>
      </node>
      <node id="19061">
        <label>ATen/WrapDimUtils.h</label>
        <link refid="_wrap_dim_utils_8h_source"/>
        <childnode refid="19039" relation="include">
        </childnode>
        <childnode refid="19012" relation="include">
        </childnode>
      </node>
      <node id="19058">
        <label>ATen/TensorAccessor.h</label>
        <link refid="_tensor_accessor_8h_source"/>
        <childnode refid="19009" relation="include">
        </childnode>
        <childnode refid="19037" relation="include">
        </childnode>
        <childnode refid="19016" relation="include">
        </childnode>
      </node>
      <node id="19042">
        <label>typeinfo</label>
      </node>
      <node id="19049">
        <label>cstdio</label>
      </node>
      <node id="19034">
        <label>ATen/detail/UniqueVoidPtr.h</label>
        <link refid="_unique_void_ptr_8h_source"/>
        <childnode refid="18998" relation="include">
        </childnode>
        <childnode refid="18995" relation="include">
        </childnode>
      </node>
      <node id="19026">
        <label>vector</label>
      </node>
      <node id="19070">
        <label>ATen/TensorMethods.h</label>
      </node>
      <node id="19067">
        <label>THNN/Reduction.h</label>
      </node>
      <node id="19024">
        <label>new</label>
      </node>
      <node id="19002">
        <label>utility</label>
      </node>
      <node id="19025">
        <label>array</label>
      </node>
      <node id="19012">
        <label>sstream</label>
      </node>
      <node id="19062">
        <label>ATen/Functions.h</label>
        <link refid="build_2aten_2src_2_a_ten_2_functions_8h_source"/>
        <childnode refid="19035" relation="include">
        </childnode>
        <childnode refid="19044" relation="include">
        </childnode>
        <childnode refid="19056" relation="include">
        </childnode>
        <childnode refid="19054" relation="include">
        </childnode>
        <childnode refid="19045" relation="include">
        </childnode>
        <childnode refid="19063" relation="include">
        </childnode>
        <childnode refid="19064" relation="include">
        </childnode>
        <childnode refid="19065" relation="include">
        </childnode>
        <childnode refid="19066" relation="include">
        </childnode>
        <childnode refid="19067" relation="include">
        </childnode>
      </node>
      <node id="19064">
        <label>ATen/NativeFunctions.h</label>
      </node>
      <node id="19031">
        <label>iosfwd</label>
      </node>
      <node id="19021">
        <label>cstdlib</label>
      </node>
      <node id="19033">
        <label>iostream</label>
      </node>
      <node id="19009">
        <label>cstddef</label>
      </node>
      <node id="19051">
        <label>unordered_map</label>
      </node>
      <node id="19050">
        <label>mutex</label>
      </node>
      <node id="18994">
        <label>ATen/ATen.h</label>
        <link refid="_a_ten_8h_source"/>
        <childnode refid="18995" relation="include">
        </childnode>
        <childnode refid="18996" relation="include">
        </childnode>
        <childnode refid="18997" relation="include">
        </childnode>
        <childnode refid="19035" relation="include">
        </childnode>
        <childnode refid="19044" relation="include">
        </childnode>
        <childnode refid="19045" relation="include">
        </childnode>
        <childnode refid="19046" relation="include">
        </childnode>
        <childnode refid="19054" relation="include">
        </childnode>
        <childnode refid="19056" relation="include">
        </childnode>
        <childnode refid="19015" relation="include">
        </childnode>
        <childnode refid="19060" relation="include">
        </childnode>
        <childnode refid="19062" relation="include">
        </childnode>
        <childnode refid="19068" relation="include">
        </childnode>
        <childnode refid="19069" relation="include">
        </childnode>
        <childnode refid="19070" relation="include">
        </childnode>
        <childnode refid="19071" relation="include">
        </childnode>
        <childnode refid="19072" relation="include">
        </childnode>
        <childnode refid="19065" relation="include">
        </childnode>
        <childnode refid="19066" relation="include">
        </childnode>
        <childnode refid="19059" relation="include">
        </childnode>
        <childnode refid="19073" relation="include">
        </childnode>
        <childnode refid="19074" relation="include">
        </childnode>
      </node>
      <node id="19048">
        <label>ATen/Registry.h</label>
        <link refid="_registry_8h_source"/>
        <childnode refid="19020" relation="include">
        </childnode>
        <childnode refid="19049" relation="include">
        </childnode>
        <childnode refid="19021" relation="include">
        </childnode>
        <childnode refid="19006" relation="include">
        </childnode>
        <childnode refid="18998" relation="include">
        </childnode>
        <childnode refid="19050" relation="include">
        </childnode>
        <childnode refid="19051" relation="include">
        </childnode>
        <childnode refid="19007" relation="include">
        </childnode>
        <childnode refid="19026" relation="include">
        </childnode>
        <childnode refid="19052" relation="include">
        </childnode>
        <childnode refid="18995" relation="include">
        </childnode>
      </node>
      <node id="19000">
        <label>ATen/Error.h</label>
        <link refid="_error_8h_source"/>
        <childnode refid="18995" relation="include">
        </childnode>
        <childnode refid="19001" relation="include">
        </childnode>
        <childnode refid="19009" relation="include">
        </childnode>
        <childnode refid="19010" relation="include">
        </childnode>
        <childnode refid="19011" relation="include">
        </childnode>
        <childnode refid="19012" relation="include">
        </childnode>
        <childnode refid="19007" relation="include">
        </childnode>
      </node>
      <node id="19066">
        <label>ATen/TensorOptions.h</label>
        <link refid="_tensor_options_8h_source"/>
        <childnode refid="19046" relation="include">
        </childnode>
        <childnode refid="19015" relation="include">
        </childnode>
        <childnode refid="19065" relation="include">
        </childnode>
        <childnode refid="19059" relation="include">
        </childnode>
        <childnode refid="19016" relation="include">
        </childnode>
        <childnode refid="19056" relation="include">
        </childnode>
        <childnode refid="19044" relation="include">
        </childnode>
        <childnode refid="19009" relation="include">
        </childnode>
        <childnode refid="19031" relation="include">
        </childnode>
        <childnode refid="19002" relation="include">
        </childnode>
      </node>
      <node id="19056">
        <label>ATen/Tensor.h</label>
        <link refid="build_2aten_2src_2_a_ten_2tensor_8h_source"/>
        <childnode refid="19045" relation="include">
        </childnode>
        <childnode refid="19035" relation="include">
        </childnode>
        <childnode refid="19016" relation="include">
        </childnode>
        <childnode refid="19057" relation="include">
        </childnode>
        <childnode refid="19054" relation="include">
        </childnode>
        <childnode refid="19058" relation="include">
        </childnode>
        <childnode refid="19038" relation="include">
        </childnode>
        <childnode refid="19039" relation="include">
        </childnode>
        <childnode refid="19041" relation="include">
        </childnode>
        <childnode refid="19015" relation="include">
        </childnode>
        <childnode refid="19059" relation="include">
        </childnode>
        <childnode refid="19001" relation="include">
        </childnode>
      </node>
      <node id="19003">
        <label>type_traits</label>
      </node>
      <node id="19059">
        <label>ATen/Layout.h</label>
        <link refid="_layout_8h_source"/>
        <childnode refid="19016" relation="include">
        </childnode>
        <childnode refid="19000" relation="include">
        </childnode>
        <childnode refid="19033" relation="include">
        </childnode>
      </node>
      <node id="18993">
        <label>/Users/robkunkle/fork/goodlux/pytorch/aten/src/ATen/native/cudnn/RNN.cpp</label>
        <link refid="aten_2src_2_a_ten_2native_2cudnn_2rnn_8cpp"/>
        <childnode refid="18994" relation="include">
        </childnode>
        <childnode refid="19075" relation="include">
        </childnode>
        <childnode refid="19076" relation="include">
        </childnode>
        <childnode refid="19000" relation="include">
        </childnode>
        <childnode refid="19077" relation="include">
        </childnode>
        <childnode refid="19064" relation="include">
        </childnode>
        <childnode refid="19078" relation="include">
        </childnode>
        <childnode refid="19079" relation="include">
        </childnode>
      </node>
      <node id="19018">
        <label>ATen/SmallVector.h</label>
        <link refid="_small_vector_8h_source"/>
        <childnode refid="19019" relation="include">
        </childnode>
        <childnode refid="19020" relation="include">
        </childnode>
        <childnode refid="19005" relation="include">
        </childnode>
        <childnode refid="19009" relation="include">
        </childnode>
        <childnode refid="19021" relation="include">
        </childnode>
        <childnode refid="19022" relation="include">
        </childnode>
        <childnode refid="19004" relation="include">
        </childnode>
        <childnode refid="19023" relation="include">
        </childnode>
        <childnode refid="18998" relation="include">
        </childnode>
        <childnode refid="19024" relation="include">
        </childnode>
        <childnode refid="19003" relation="include">
        </childnode>
        <childnode refid="19002" relation="include">
        </childnode>
        <childnode refid="18995" relation="include">
        </childnode>
      </node>
      <node id="19020">
        <label>algorithm</label>
      </node>
      <node id="19045">
        <label>ATen/Generator.h</label>
        <link refid="_generator_8h_source"/>
        <childnode refid="19037" relation="include">
        </childnode>
      </node>
      <node id="19022">
        <label>cstring</label>
      </node>
      <node id="18998">
        <label>memory</label>
      </node>
      <node id="19004">
        <label>initializer_list</label>
      </node>
      <node id="19068">
        <label>ATen/Formatting.h</label>
        <link refid="_formatting_8h_source"/>
        <childnode refid="19033" relation="include">
        </childnode>
        <childnode refid="19044" relation="include">
        </childnode>
        <childnode refid="19035" relation="include">
        </childnode>
      </node>
    </incdepgraph>
    <innernamespace refid="namespaceat">at</innernamespace>
    <innernamespace refid="namespaceat_1_1native">at::native</innernamespace>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <programlisting>
<codeline lineno="1"><highlight class="preprocessor">#include<sp/>&lt;ATen/ATen.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="2"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/TensorUtils.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="3"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/Config.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="4"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/Error.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="5"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/MatrixRef.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="6"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/NativeFunctions.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="7"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/cuda/CUDAConfig.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="8"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/cuda/Exceptions.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="9"><highlight class="normal"></highlight></codeline>
<codeline lineno="10"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>!AT_CUDNN_ENABLED()</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="11"><highlight class="normal"></highlight></codeline>
<codeline lineno="12"><highlight class="normal"></highlight><highlight class="keyword">namespace<sp/></highlight><highlight class="normal"><ref refid="namespaceat" kindref="compound">at</ref><sp/>{<sp/></highlight><highlight class="keyword">namespace<sp/></highlight><highlight class="normal">native<sp/>{</highlight></codeline>
<codeline lineno="13"><highlight class="normal"></highlight></codeline>
<codeline lineno="14"><highlight class="normal"></highlight><highlight class="comment">//<sp/>See<sp/>Note<sp/>[ATen<sp/>preprocessor<sp/>philosophy]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="15"><highlight class="normal"></highlight></codeline>
<codeline lineno="16"><highlight class="normal">Tensor<sp/>_cudnn_rnn_flatten_weight(</highlight></codeline>
<codeline lineno="17"><highlight class="normal"><sp/><sp/><sp/><sp/>TensorList<sp/>weight_arr,<sp/>int64_t<sp/>weight_stride0,</highlight></codeline>
<codeline lineno="18"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>input_size,</highlight></codeline>
<codeline lineno="19"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>fn_mode,<sp/>int64_t<sp/>fn_hidden_size,</highlight></codeline>
<codeline lineno="20"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>fn_num_layers,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>batch_first,</highlight></codeline>
<codeline lineno="21"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>fn_bidirectional</highlight></codeline>
<codeline lineno="22"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>{</highlight></codeline>
<codeline lineno="23"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;_cudnn_rnn_flatten_weight:<sp/>ATen<sp/>not<sp/>compiled<sp/>with<sp/>cuDNN<sp/>support&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="24"><highlight class="normal">}</highlight></codeline>
<codeline lineno="25"><highlight class="normal"></highlight></codeline>
<codeline lineno="26"><highlight class="normal">std::tuple&lt;Tensor,<sp/>Tensor,<sp/>Tensor,<sp/>Tensor,<sp/>Tensor&gt;<sp/>_cudnn_rnn(</highlight></codeline>
<codeline lineno="27"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>input_r,</highlight></codeline>
<codeline lineno="28"><highlight class="normal"><sp/><sp/><sp/><sp/>TensorList<sp/>weight,<sp/>int64_t<sp/>weight_stride0,</highlight></codeline>
<codeline lineno="29"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>weight_buf_r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>hx,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>cx,</highlight></codeline>
<codeline lineno="30"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>fn_mode,<sp/>int64_t<sp/>fn_hidden_size,</highlight></codeline>
<codeline lineno="31"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>fn_num_layers,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>batch_first,<sp/></highlight><highlight class="keywordtype">double</highlight><highlight class="normal"><sp/>fn_dropout,</highlight></codeline>
<codeline lineno="32"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>fn_train,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>fn_bidirectional,<sp/>IntList<sp/>fn_batch_sizes,</highlight></codeline>
<codeline lineno="33"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>fn_dropout_state</highlight></codeline>
<codeline lineno="34"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>{</highlight></codeline>
<codeline lineno="35"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;_cudnn_rnn:<sp/>ATen<sp/>not<sp/>compiled<sp/>with<sp/>cuDNN<sp/>support&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="36"><highlight class="normal">}</highlight></codeline>
<codeline lineno="37"><highlight class="normal"></highlight></codeline>
<codeline lineno="38"><highlight class="normal">std::tuple&lt;Tensor,<sp/>Tensor,<sp/>Tensor,<sp/>std::vector&lt;Tensor&gt;&gt;<sp/>_cudnn_rnn_backward(</highlight></codeline>
<codeline lineno="39"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>input,<sp/>TensorList<sp/>weight,<sp/>int64_t<sp/>weight_stride0,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>weight_buf,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>hx,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>cx,</highlight></codeline>
<codeline lineno="40"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>output,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_output_r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_hy_r,</highlight></codeline>
<codeline lineno="41"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_cy_r,</highlight></codeline>
<codeline lineno="42"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>mode,<sp/>int64_t<sp/>hidden_size,</highlight></codeline>
<codeline lineno="43"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>num_layers,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>batch_first,<sp/></highlight><highlight class="keywordtype">double</highlight><highlight class="normal"><sp/>dropout,</highlight></codeline>
<codeline lineno="44"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>train,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>bidirectional,<sp/>IntList<sp/>batch_sizes,</highlight></codeline>
<codeline lineno="45"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>dropout_state,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>reserve,</highlight></codeline>
<codeline lineno="46"><highlight class="normal"><sp/><sp/><sp/><sp/>std::array&lt;bool,<sp/>4&gt;<sp/>output_mask</highlight></codeline>
<codeline lineno="47"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>{</highlight></codeline>
<codeline lineno="48"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;_cudnn_rnn_backward:<sp/>ATen<sp/>not<sp/>compiled<sp/>with<sp/>cuDNN<sp/>support&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="49"><highlight class="normal">}</highlight></codeline>
<codeline lineno="50"><highlight class="normal"></highlight></codeline>
<codeline lineno="51"><highlight class="normal">Tensor<sp/>_cudnn_init_dropout_state(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Type&amp;<sp/>ty,<sp/></highlight><highlight class="keywordtype">double</highlight><highlight class="normal"><sp/>dropout,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>train,<sp/>int64_t<sp/>dropout_seed)<sp/>{</highlight></codeline>
<codeline lineno="52"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;_cudnn_init_dropout_state:<sp/>ATen<sp/>not<sp/>compiled<sp/>with<sp/>cuDNN<sp/>support&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="53"><highlight class="normal">}</highlight></codeline>
<codeline lineno="54"><highlight class="normal"></highlight></codeline>
<codeline lineno="55"><highlight class="normal">}}<sp/></highlight><highlight class="comment">//<sp/>namespace<sp/>at::native</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="56"><highlight class="normal"></highlight></codeline>
<codeline lineno="57"><highlight class="normal"></highlight><highlight class="preprocessor">#else<sp/>//<sp/>AT_CUDNN_ENABLED()</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="58"><highlight class="normal"></highlight></codeline>
<codeline lineno="59"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/cudnn/cudnn-wrapper.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="60"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/cudnn/Descriptors.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="61"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/cudnn/Types.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="62"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/cudnn/Utils.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="63"><highlight class="normal"></highlight></codeline>
<codeline lineno="64"><highlight class="normal"></highlight><highlight class="keyword">namespace<sp/></highlight><highlight class="normal"><ref refid="namespaceat" kindref="compound">at</ref><sp/>{<sp/></highlight><highlight class="keyword">namespace<sp/></highlight><highlight class="normal">native<sp/>{</highlight></codeline>
<codeline lineno="65"><highlight class="normal"></highlight></codeline>
<codeline lineno="66"><highlight class="normal"></highlight><highlight class="keyword">namespace<sp/></highlight><highlight class="normal">{</highlight></codeline>
<codeline lineno="67"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>DropoutDescriptor</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="68"><highlight class="normal"></highlight></codeline>
<codeline lineno="69"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">struct<sp/></highlight><highlight class="normal">DropoutDescriptorParams<sp/>{</highlight></codeline>
<codeline lineno="70"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>train;</highlight></codeline>
<codeline lineno="71"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">double</highlight><highlight class="normal"><sp/>dropout;</highlight></codeline>
<codeline lineno="72"><highlight class="normal"><sp/><sp/><sp/><sp/>Tensor<sp/>dropout_state;</highlight></codeline>
<codeline lineno="73"><highlight class="normal"><sp/><sp/><sp/><sp/>DropoutDescriptorParams()<sp/>{}</highlight></codeline>
<codeline lineno="74"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">set</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>train_,<sp/></highlight><highlight class="keywordtype">double</highlight><highlight class="normal"><sp/>dropout_,<sp/>Tensor<sp/>dropout_state_)<sp/>{</highlight></codeline>
<codeline lineno="75"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>train<sp/>=<sp/>train_;</highlight></codeline>
<codeline lineno="76"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>dropout<sp/>=<sp/>dropout_;</highlight></codeline>
<codeline lineno="77"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>dropout_state<sp/>=<sp/>dropout_state_;</highlight></codeline>
<codeline lineno="78"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="79"><highlight class="normal"><sp/><sp/><sp/><sp/>DropoutDescriptor<sp/>descriptor(cudnnHandle_t<sp/>handle)</highlight><highlight class="keyword"><sp/>const<sp/></highlight><highlight class="normal">{</highlight></codeline>
<codeline lineno="80"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dropout_p<sp/>=<sp/>train<sp/>?<sp/>dropout<sp/>:<sp/>0;</highlight></codeline>
<codeline lineno="81"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>DropoutDescriptor<sp/>dropout_desc;</highlight></codeline>
<codeline lineno="82"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(dropout_p<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="83"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dropout_desc.set_no_dropout(handle);</highlight></codeline>
<codeline lineno="84"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="85"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dropout_desc.set(handle,<sp/>dropout_p,<sp/>dropout_state);</highlight></codeline>
<codeline lineno="86"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="87"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>dropout_desc;</highlight></codeline>
<codeline lineno="88"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="89"><highlight class="normal"><sp/><sp/>};</highlight></codeline>
<codeline lineno="90"><highlight class="normal"></highlight></codeline>
<codeline lineno="91"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>RNNDescriptor</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="92"><highlight class="normal"></highlight></codeline>
<codeline lineno="93"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">struct<sp/></highlight><highlight class="normal">RNNDescriptorParams<sp/>{</highlight></codeline>
<codeline lineno="94"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>hidden_size;</highlight></codeline>
<codeline lineno="95"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>num_layers;</highlight></codeline>
<codeline lineno="96"><highlight class="normal"><sp/><sp/><sp/><sp/>cudnnDirectionMode_t<sp/>bidirectional;</highlight></codeline>
<codeline lineno="97"><highlight class="normal"><sp/><sp/><sp/><sp/>cudnnRNNMode_t<sp/>mode;</highlight></codeline>
<codeline lineno="98"><highlight class="normal"><sp/><sp/><sp/><sp/>cudnnDataType_t<sp/>datatype;</highlight></codeline>
<codeline lineno="99"><highlight class="normal"></highlight></codeline>
<codeline lineno="100"><highlight class="normal"><sp/><sp/><sp/><sp/>cudnnRNNInputMode_t<sp/>input_mode<sp/>=<sp/>CUDNN_LINEAR_INPUT;</highlight></codeline>
<codeline lineno="101"><highlight class="normal"></highlight></codeline>
<codeline lineno="102"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>num_directions()</highlight><highlight class="keyword"><sp/>const<sp/></highlight><highlight class="normal">{</highlight></codeline>
<codeline lineno="103"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>bidirectional<sp/>?<sp/>2<sp/>:<sp/>1;</highlight></codeline>
<codeline lineno="104"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="105"><highlight class="normal"></highlight></codeline>
<codeline lineno="106"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>set_mode(int64_t<sp/>fn_mode)<sp/>{</highlight></codeline>
<codeline lineno="107"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">switch</highlight><highlight class="normal"><sp/>(fn_mode)<sp/>{</highlight></codeline>
<codeline lineno="108"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>CUDNN_RNN_RELU:</highlight></codeline>
<codeline lineno="109"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>mode<sp/>=<sp/>CUDNN_RNN_RELU;</highlight></codeline>
<codeline lineno="110"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="111"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>CUDNN_RNN_TANH:</highlight></codeline>
<codeline lineno="112"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>mode<sp/>=<sp/>CUDNN_RNN_TANH;</highlight></codeline>
<codeline lineno="113"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="114"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>CUDNN_LSTM:</highlight></codeline>
<codeline lineno="115"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>mode<sp/>=<sp/>CUDNN_LSTM;</highlight></codeline>
<codeline lineno="116"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="117"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>CUDNN_GRU:</highlight></codeline>
<codeline lineno="118"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>mode<sp/>=<sp/>CUDNN_GRU;</highlight></codeline>
<codeline lineno="119"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="120"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">default</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="121"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>{</highlight></codeline>
<codeline lineno="122"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>std::ostringstream<sp/>oss;</highlight></codeline>
<codeline lineno="123"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>oss<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;unrecognized<sp/>cuDNN<sp/>RNN<sp/>mode<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>fn_mode;</highlight></codeline>
<codeline lineno="124"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(oss.str());</highlight></codeline>
<codeline lineno="125"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="126"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="127"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="128"><highlight class="normal"></highlight></codeline>
<codeline lineno="129"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>set_bidirectional(</highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>fn_bidirectional)<sp/>{</highlight></codeline>
<codeline lineno="130"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>bidirectional<sp/>=<sp/>fn_bidirectional<sp/>?<sp/>CUDNN_BIDIRECTIONAL<sp/>:<sp/>CUDNN_UNIDIRECTIONAL;</highlight></codeline>
<codeline lineno="131"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="132"><highlight class="normal"></highlight></codeline>
<codeline lineno="133"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">set</highlight><highlight class="normal">(int64_t<sp/>mode,<sp/>int64_t<sp/>hidden_size,<sp/>int64_t<sp/>num_layers,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>bidirectional,<sp/>cudnnDataType_t<sp/>datatype)<sp/>{</highlight></codeline>
<codeline lineno="134"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>this-&gt;set_mode(mode);</highlight></codeline>
<codeline lineno="135"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>this-&gt;hidden_size<sp/>=<sp/>hidden_size;</highlight></codeline>
<codeline lineno="136"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>this-&gt;num_layers<sp/>=<sp/>num_layers;</highlight></codeline>
<codeline lineno="137"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>this-&gt;set_bidirectional(bidirectional);</highlight></codeline>
<codeline lineno="138"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>this-&gt;datatype<sp/>=<sp/>datatype;</highlight></codeline>
<codeline lineno="139"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="140"><highlight class="normal"></highlight></codeline>
<codeline lineno="141"><highlight class="normal"></highlight></codeline>
<codeline lineno="142"><highlight class="normal"><sp/><sp/><sp/><sp/>RNNDescriptor<sp/>descriptor(cudnnHandle_t<sp/>handle,<sp/>DropoutDescriptor&amp;&amp;<sp/>dropout_desc)</highlight><highlight class="keyword"><sp/>const<sp/></highlight><highlight class="normal">{</highlight></codeline>
<codeline lineno="143"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>RNNDescriptor<sp/>rnn_desc;</highlight></codeline>
<codeline lineno="144"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>rnn_desc.set(handle,<sp/>hidden_size,<sp/>num_layers,<sp/>std::move(dropout_desc),<sp/>input_mode,<sp/>bidirectional,<sp/>mode,<sp/>datatype);</highlight></codeline>
<codeline lineno="145"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>rnn_desc;</highlight></codeline>
<codeline lineno="146"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="147"><highlight class="normal"></highlight></codeline>
<codeline lineno="148"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>In<sp/>some<sp/>cases,<sp/>a<sp/>use<sp/>of<sp/>RNNDescriptor<sp/>does<sp/>not<sp/>rely<sp/>on<sp/>the</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="149"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>DropoutDescriptor.<sp/><sp/>In<sp/>this<sp/>case,<sp/>we<sp/>fake<sp/>up<sp/>a<sp/>no-dropout</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="150"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>descriptor<sp/>to<sp/>make<sp/>the<sp/>RNN<sp/>descriptor<sp/>initialization<sp/>go<sp/>through.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="151"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>This<sp/>is<sp/>used<sp/>by<sp/>_cudnn_rnn_flatten_weight,<sp/>which<sp/>needs<sp/>an</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="152"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>RNNDescriptor<sp/>for<sp/>get_parameters(),<sp/>but<sp/>does<sp/>not<sp/>actually<sp/>need</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="153"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>a<sp/>fully<sp/>initialized<sp/>dropout<sp/>descriptor.<sp/><sp/>This<sp/>lets<sp/>us<sp/>avoid</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="154"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>having<sp/>to<sp/>pass<sp/>the<sp/>dropout<sp/>state<sp/>to<sp/>flatten,<sp/>which<sp/>has<sp/>no<sp/>business</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="155"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>knowing<sp/>what<sp/>the<sp/>dropout<sp/>state<sp/>is.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="156"><highlight class="normal"><sp/><sp/><sp/><sp/>RNNDescriptor<sp/>descriptor(cudnnHandle_t<sp/>handle)</highlight><highlight class="keyword"><sp/>const<sp/></highlight><highlight class="normal">{</highlight></codeline>
<codeline lineno="157"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>DropoutDescriptor<sp/>dropout_desc;</highlight></codeline>
<codeline lineno="158"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>dropout_desc.set_no_dropout(handle);</highlight></codeline>
<codeline lineno="159"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>descriptor(handle,<sp/>std::move(dropout_desc));</highlight></codeline>
<codeline lineno="160"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="161"><highlight class="normal"><sp/><sp/>};</highlight></codeline>
<codeline lineno="162"><highlight class="normal"></highlight></codeline>
<codeline lineno="163"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>TensorDescriptor<sp/>list</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="164"><highlight class="normal"></highlight></codeline>
<codeline lineno="165"><highlight class="normal"><sp/><sp/>std::vector&lt;TensorDescriptor&gt;<sp/>rnn_descriptor_sequence(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>tensor,<sp/>IntList<sp/>batch_sizes)<sp/>{</highlight></codeline>
<codeline lineno="166"><highlight class="normal"><sp/><sp/><sp/><sp/>std::vector&lt;TensorDescriptor&gt;<sp/>descriptors(batch_sizes.size());</highlight></codeline>
<codeline lineno="167"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="168"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>To<sp/>be<sp/>mutated<sp/>in<sp/>the<sp/>loop</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="169"><highlight class="normal"><sp/><sp/><sp/><sp/>std::vector&lt;int64_t&gt;<sp/>batch_tensor_size(tensor.sizes());</highlight></codeline>
<codeline lineno="170"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>batch_size<sp/>:<sp/>batch_sizes)<sp/>{</highlight></codeline>
<codeline lineno="171"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>batch_tensor_size[0]<sp/>=<sp/>batch_size;</highlight></codeline>
<codeline lineno="172"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>NB:<sp/>cuDNN<sp/>RNN<sp/>API<sp/>does<sp/>not<sp/>support<sp/>2d<sp/>descriptors,<sp/>so<sp/>we</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="173"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>must<sp/>pad<sp/>it<sp/>out<sp/>to<sp/>3d.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="174"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>descriptors[i].set(getCudnnDataType(tensor),<sp/>batch_tensor_size,<sp/>tensor.strides(),<sp/>3);</highlight></codeline>
<codeline lineno="175"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>i++;</highlight></codeline>
<codeline lineno="176"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="177"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>descriptors;</highlight></codeline>
<codeline lineno="178"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="179"><highlight class="normal"></highlight></codeline>
<codeline lineno="180"><highlight class="normal"><sp/><sp/>std::vector&lt;TensorDescriptor&gt;<sp/>rnn_descriptor(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>tensor,<sp/>int64_t<sp/>N)<sp/>{</highlight></codeline>
<codeline lineno="181"><highlight class="normal"><sp/><sp/><sp/><sp/>std::vector&lt;TensorDescriptor&gt;<sp/>descriptors(N);</highlight></codeline>
<codeline lineno="182"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(int64_t<sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>N;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="183"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>descriptors[i].set(tensor,<sp/>5);</highlight></codeline>
<codeline lineno="184"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="185"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>descriptors;</highlight></codeline>
<codeline lineno="186"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="187"><highlight class="normal"></highlight></codeline>
<codeline lineno="188"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>The<sp/>best<sp/>way<sp/>to<sp/>understand<sp/>the<sp/>meaning<sp/>of<sp/>the<sp/>values<sp/>stored<sp/>in</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="189"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>this<sp/>struct<sp/>is<sp/>to<sp/>consider<sp/>each<sp/>of<sp/>the<sp/>possible<sp/>ways<sp/>our</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="190"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>input<sp/>can<sp/>be<sp/>structured.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="191"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="192"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Suppose<sp/>you<sp/>want<sp/>to<sp/>run<sp/>RNN<sp/>on<sp/>the<sp/>following<sp/>variable</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="193"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>length<sp/>inputs:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="194"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="195"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>Sequence<sp/>1:<sp/>ABCD</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="196"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>Sequence<sp/>2:<sp/>EF</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="197"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>Sequence<sp/>3:<sp/>G</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="198"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="199"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>(Let<sp/>_<sp/>be<sp/>padding<sp/>when<sp/>we<sp/>have<sp/>non-packed<sp/>representations.)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="200"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="201"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>#<sp/>Packed<sp/>input<sp/>(batch_sizes<sp/>is<sp/>non-empty)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="202"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="203"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/><sp/>input_size</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="204"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>+------+<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>+</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="205"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>|<sp/>A<sp/><sp/><sp/><sp/>|<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>|</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="206"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>|<sp/>E<sp/><sp/><sp/><sp/>|<sp/>mini_batch<sp/>=<sp/><sp/><sp/><sp/><sp/><sp/><sp/>|</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="207"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>|<sp/>G<sp/><sp/><sp/><sp/>|<sp/>batch_sizes[0]<sp/>=<sp/>3<sp/>|</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="208"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>+------+<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>|</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="209"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>|<sp/>B<sp/><sp/><sp/><sp/>|<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>|<sp/>batch_sizes_sum<sp/>=<sp/>7</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="210"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>|<sp/>F<sp/><sp/><sp/><sp/>|<sp/>batch_sizes[1]<sp/>=<sp/>2<sp/>|</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="211"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>+------+<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>|</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="212"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>|<sp/>C<sp/><sp/><sp/><sp/>|<sp/>batch_sizes[2]<sp/>=<sp/>1<sp/>|</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="213"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>+------+<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>|</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="214"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>|<sp/>D<sp/><sp/><sp/><sp/>|<sp/>batch_sizes[3]<sp/>=<sp/>1<sp/>|</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="215"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>+------+<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>+</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="216"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="217"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>(seq_length<sp/>=<sp/>4)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="218"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="219"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>input.size()<sp/>=<sp/>batch_sizes_sum<sp/>x<sp/>input_size</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="220"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="221"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>#<sp/>Unpacked<sp/>input<sp/>(batch_first<sp/>=<sp/>false)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="222"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="223"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/><sp/>mini_batch<sp/>=<sp/>3</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="224"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>+-------+</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="225"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>|<sp/>A<sp/>E<sp/>G<sp/>|</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="226"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>|<sp/>B<sp/>F<sp/>_<sp/>|<sp/>seq_length<sp/>=<sp/>4</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="227"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>|<sp/>C<sp/>_<sp/>_<sp/>|</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="228"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>|<sp/>D<sp/>_<sp/>_<sp/>|</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="229"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>+-------+</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="230"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>...<sp/><sp/><sp/><sp/>input_size</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="231"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>+-------+</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="232"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="233"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>input.size()<sp/>=<sp/>seq_length<sp/>x<sp/>mini_batch<sp/>x<sp/>input_size</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="234"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="235"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>#<sp/>Unpacked<sp/>input<sp/>(batch_first<sp/>=<sp/>true)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="236"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="237"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/><sp/>seq_length<sp/>=<sp/>4</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="238"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>+---------+</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="239"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>|<sp/>A<sp/>B<sp/>C<sp/>D<sp/>|</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="240"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>|<sp/>E<sp/>F<sp/>_<sp/>_<sp/>|<sp/>mini_batch<sp/>=<sp/>3</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="241"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>|<sp/>G<sp/>_<sp/>_<sp/>_<sp/>|</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="242"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>+---------+</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="243"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/>...<sp/><sp/><sp/><sp/><sp/>input_size</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="244"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>+---------+</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="245"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="246"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>input.size()<sp/>=<sp/>mini_batch<sp/>x<sp/>seq_length<sp/>x<sp/>input_size</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="247"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="248"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">struct<sp/></highlight><highlight class="normal">TensorDescriptorListParams<sp/>{</highlight></codeline>
<codeline lineno="249"><highlight class="normal"><sp/><sp/><sp/><sp/>IntList<sp/>batch_sizes;</highlight></codeline>
<codeline lineno="250"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>seq_length;</highlight></codeline>
<codeline lineno="251"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>mini_batch;</highlight></codeline>
<codeline lineno="252"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>NB:<sp/>this<sp/>is<sp/>not<sp/>input.size(),<sp/>which<sp/>is<sp/>an<sp/>IntList;<sp/>instead,<sp/>this</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="253"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>size<sp/>of<sp/>the<sp/>inner-most<sp/>dimension.<sp/><sp/>In<sp/>NL<sp/>applications,<sp/>this<sp/>is<sp/>usually</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="254"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>the<sp/>size<sp/>of<sp/>the<sp/>embedding.<sp/><sp/>You<sp/>can<sp/>also<sp/>think<sp/>of<sp/>this<sp/>as<sp/>the<sp/>size</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="255"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>of<sp/>the<sp/>&quot;channel&quot;<sp/>dimension<sp/>(at<sp/>risk<sp/>of<sp/>confusing<sp/>vision<sp/>researchers<sp/>:)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="256"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>input_size;</highlight></codeline>
<codeline lineno="257"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Only<sp/>valid<sp/>when<sp/>!is_input_packed</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="258"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>batch_sizes_sum;<sp/></highlight><highlight class="comment">//<sp/>==<sp/>sum(batch_sizes)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="259"><highlight class="normal"></highlight></codeline>
<codeline lineno="260"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>is_input_packed()</highlight><highlight class="keyword"><sp/>const<sp/></highlight><highlight class="normal">{</highlight></codeline>
<codeline lineno="261"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>batch_sizes.size()<sp/>!=<sp/>0;</highlight></codeline>
<codeline lineno="262"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="263"><highlight class="normal"></highlight></codeline>
<codeline lineno="264"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">set</highlight><highlight class="normal">(IntList<sp/>input_sizes,<sp/>IntList<sp/>batch_sizes_,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>batch_first)<sp/>{</highlight></codeline>
<codeline lineno="265"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>batch_sizes<sp/>=<sp/>batch_sizes_;</highlight></codeline>
<codeline lineno="266"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(is_input_packed())<sp/>{</highlight></codeline>
<codeline lineno="267"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>seq_length<sp/>=<sp/>batch_sizes.size();</highlight></codeline>
<codeline lineno="268"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>mini_batch<sp/>=<sp/>batch_sizes[0];</highlight></codeline>
<codeline lineno="269"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>NB:<sp/>When<sp/>input<sp/>is<sp/>packed,<sp/>the<sp/>mini_batch<sp/>size<sp/>is<sp/>NOT<sp/>the<sp/>size</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="270"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>of<sp/>the<sp/>outer<sp/>dimension</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="271"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>batch_sizes_sum<sp/>=<sp/>input_sizes[0];</highlight></codeline>
<codeline lineno="272"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>input_size<sp/>=<sp/>input_sizes[1];</highlight></codeline>
<codeline lineno="273"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="274"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(batch_first)<sp/>{</highlight></codeline>
<codeline lineno="275"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>seq_length<sp/>=<sp/>input_sizes[1];</highlight></codeline>
<codeline lineno="276"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>mini_batch<sp/>=<sp/>input_sizes[0];</highlight></codeline>
<codeline lineno="277"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="278"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>seq_length<sp/>=<sp/>input_sizes[0];</highlight></codeline>
<codeline lineno="279"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>mini_batch<sp/>=<sp/>input_sizes[1];</highlight></codeline>
<codeline lineno="280"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="281"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>input_size<sp/>=<sp/>input_sizes[2];</highlight></codeline>
<codeline lineno="282"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>Actually,<sp/>would<sp/>this<sp/>make<sp/>ASAN&apos;s<sp/>job<sp/>harder<sp/>catching</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="283"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>an<sp/>uninitialized<sp/>access?</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="284"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>batch_sizes_sum<sp/>=<sp/>-1;<sp/></highlight><highlight class="comment">//<sp/>something<sp/>bogus<sp/>in<sp/>case<sp/>we<sp/>access<sp/>it</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="285"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="286"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="287"><highlight class="normal"></highlight></codeline>
<codeline lineno="288"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>check<sp/>x<sp/>for<sp/>consistency<sp/>with<sp/>input_size?</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="289"><highlight class="normal"><sp/><sp/><sp/><sp/>std::vector&lt;TensorDescriptor&gt;<sp/>descriptors(Tensor<sp/>x)</highlight><highlight class="keyword"><sp/>const<sp/></highlight><highlight class="normal">{</highlight></codeline>
<codeline lineno="290"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>is_input_packed<sp/>=<sp/>batch_sizes.size()<sp/>!=<sp/>0;</highlight></codeline>
<codeline lineno="291"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(is_input_packed)<sp/>{</highlight></codeline>
<codeline lineno="292"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>rnn_descriptor_sequence(x,<sp/>batch_sizes);</highlight></codeline>
<codeline lineno="293"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="294"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>rnn_descriptor(x[0],<sp/>seq_length);</highlight></codeline>
<codeline lineno="295"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="296"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="297"><highlight class="normal"><sp/><sp/>};</highlight></codeline>
<codeline lineno="298"><highlight class="normal"></highlight></codeline>
<codeline lineno="299"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Everything<sp/>together</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="300"><highlight class="normal"></highlight></codeline>
<codeline lineno="301"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">struct<sp/></highlight><highlight class="normal">RNNParams<sp/>{</highlight></codeline>
<codeline lineno="302"><highlight class="normal"><sp/><sp/><sp/><sp/>DropoutDescriptorParams<sp/>dropout;</highlight></codeline>
<codeline lineno="303"><highlight class="normal"><sp/><sp/><sp/><sp/>RNNDescriptorParams<sp/>rnn;</highlight></codeline>
<codeline lineno="304"><highlight class="normal"><sp/><sp/><sp/><sp/>TensorDescriptorListParams<sp/>tensors;</highlight></codeline>
<codeline lineno="305"><highlight class="normal"><sp/><sp/>};</highlight></codeline>
<codeline lineno="306"><highlight class="normal"></highlight></codeline>
<codeline lineno="307"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>NB:<sp/>Doesn&apos;t<sp/>include<sp/>the<sp/>weight<sp/>descriptor</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="308"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">struct<sp/></highlight><highlight class="normal">RNNDescriptors<sp/>{</highlight></codeline>
<codeline lineno="309"><highlight class="normal"><sp/><sp/><sp/><sp/>RNNDescriptor<sp/>rnn_desc;</highlight></codeline>
<codeline lineno="310"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>NB:<sp/>this<sp/>won&apos;t<sp/>actually<sp/>lay<sp/>out<sp/>the<sp/>tensor<sp/>descriptor<sp/>pointers</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="311"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>in<sp/>the<sp/>right<sp/>way,<sp/>so<sp/>you&apos;ll<sp/>have<sp/>to<sp/>preprocess<sp/>them</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="312"><highlight class="normal"><sp/><sp/><sp/><sp/>std::vector&lt;TensorDescriptor&gt;<sp/>x_descs;</highlight></codeline>
<codeline lineno="313"><highlight class="normal"><sp/><sp/><sp/><sp/>std::vector&lt;TensorDescriptor&gt;<sp/>y_descs;</highlight></codeline>
<codeline lineno="314"><highlight class="normal"><sp/><sp/><sp/><sp/>TensorDescriptor<sp/>hx_desc;</highlight></codeline>
<codeline lineno="315"><highlight class="normal"><sp/><sp/><sp/><sp/>TensorDescriptor<sp/>hy_desc;</highlight></codeline>
<codeline lineno="316"><highlight class="normal"><sp/><sp/><sp/><sp/>TensorDescriptor<sp/>cx_desc;</highlight></codeline>
<codeline lineno="317"><highlight class="normal"><sp/><sp/><sp/><sp/>TensorDescriptor<sp/>cy_desc;</highlight></codeline>
<codeline lineno="318"><highlight class="normal"></highlight></codeline>
<codeline lineno="319"><highlight class="normal"><sp/><sp/><sp/><sp/>RNNDescriptors(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>RNNParams&amp;<sp/>fn,<sp/>cudnnHandle_t<sp/>handle,<sp/>Tensor<sp/>x,<sp/>Tensor<sp/>y,<sp/>Tensor<sp/>hx,<sp/>Tensor<sp/>cx)<sp/>{</highlight></codeline>
<codeline lineno="320"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>rnn_desc<sp/>=<sp/>fn.rnn.descriptor(handle,<sp/>fn.dropout.descriptor(handle));</highlight></codeline>
<codeline lineno="321"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>x_descs<sp/>=<sp/>fn.tensors.descriptors(x);</highlight></codeline>
<codeline lineno="322"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>y_descs<sp/>=<sp/>fn.tensors.descriptors(y);</highlight></codeline>
<codeline lineno="323"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>hx_desc.set(hx,<sp/>5);</highlight></codeline>
<codeline lineno="324"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>hy_desc.set(hx,<sp/>5);</highlight></codeline>
<codeline lineno="325"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cx.defined())<sp/>{</highlight></codeline>
<codeline lineno="326"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cx_desc.set(cx,<sp/>5);</highlight></codeline>
<codeline lineno="327"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cy_desc.set(cx,<sp/>5);</highlight></codeline>
<codeline lineno="328"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="329"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="330"><highlight class="normal"></highlight></codeline>
<codeline lineno="331"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>This<sp/>is<sp/>annoying,<sp/>having<sp/>to<sp/>put<sp/>the<sp/>cudnnTensorDescriptor_t</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="332"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>in<sp/>a<sp/>contiguous<sp/>array...</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="333"><highlight class="normal"><sp/><sp/><sp/><sp/>std::vector&lt;cudnnTensorDescriptor_t&gt;<sp/>get_descs(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>std::vector&lt;TensorDescriptor&gt;&amp;<sp/>descs)<sp/>{</highlight></codeline>
<codeline lineno="334"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>std::vector&lt;cudnnTensorDescriptor_t&gt;<sp/>r;</highlight></codeline>
<codeline lineno="335"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>r.reserve(descs.size());</highlight></codeline>
<codeline lineno="336"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keyword">auto</highlight><highlight class="normal">&amp;<sp/>desc<sp/>:<sp/>descs)<sp/>{</highlight></codeline>
<codeline lineno="337"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>r.emplace_back(desc.desc());</highlight></codeline>
<codeline lineno="338"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="339"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="340"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="341"><highlight class="normal"></highlight></codeline>
<codeline lineno="342"><highlight class="normal"><sp/><sp/><sp/><sp/>std::vector&lt;cudnnTensorDescriptor_t&gt;<sp/>get_x_descs()<sp/>{</highlight></codeline>
<codeline lineno="343"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>get_descs(x_descs);</highlight></codeline>
<codeline lineno="344"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="345"><highlight class="normal"></highlight></codeline>
<codeline lineno="346"><highlight class="normal"><sp/><sp/><sp/><sp/>std::vector&lt;cudnnTensorDescriptor_t&gt;<sp/>get_y_descs()<sp/>{</highlight></codeline>
<codeline lineno="347"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>get_descs(y_descs);</highlight></codeline>
<codeline lineno="348"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="349"><highlight class="normal"><sp/><sp/>};</highlight></codeline>
<codeline lineno="350"><highlight class="normal"></highlight></codeline>
<codeline lineno="351"><highlight class="normal"><sp/><sp/>int64_t<sp/>get_num_weights(cudnnHandle_t<sp/>handle,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>RNNDescriptor&amp;<sp/>rnn_desc,</highlight></codeline>
<codeline lineno="352"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorDescriptor&amp;<sp/>x_desc,<sp/>cudnnDataType_t<sp/>datatype)<sp/>{</highlight></codeline>
<codeline lineno="353"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>weight_size;</highlight></codeline>
<codeline lineno="354"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_CUDNN_CHECK(cudnnGetRNNParamsSize(handle,<sp/>rnn_desc.desc(),<sp/>x_desc.desc(),<sp/>&amp;weight_size,<sp/>datatype));</highlight></codeline>
<codeline lineno="355"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>elem_size<sp/>=<sp/>dataSize(datatype);</highlight></codeline>
<codeline lineno="356"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_ASSERTM(weight_size<sp/>%<sp/>elem_size<sp/>==<sp/>0,<sp/></highlight><highlight class="stringliteral">&quot;cudnnGetRNNParamsSize<sp/>returned<sp/>nonsensical<sp/>weight_size&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="357"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>weight_size<sp/>/<sp/>elem_size;</highlight></codeline>
<codeline lineno="358"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="359"><highlight class="normal"></highlight></codeline>
<codeline lineno="360"><highlight class="normal"><sp/><sp/>int64_t<sp/>_num_linear_layers(cudnnRNNMode_t<sp/>mode)<sp/>{</highlight></codeline>
<codeline lineno="361"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">switch</highlight><highlight class="normal">(mode)<sp/>{</highlight></codeline>
<codeline lineno="362"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>CUDNN_LSTM:</highlight></codeline>
<codeline lineno="363"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>8;</highlight></codeline>
<codeline lineno="364"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>CUDNN_GRU:</highlight></codeline>
<codeline lineno="365"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>6;</highlight></codeline>
<codeline lineno="366"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>CUDNN_RNN_RELU:</highlight></codeline>
<codeline lineno="367"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>2;</highlight></codeline>
<codeline lineno="368"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>CUDNN_RNN_TANH:</highlight></codeline>
<codeline lineno="369"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>2;</highlight></codeline>
<codeline lineno="370"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">default</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="371"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>AT_ERROR(</highlight><highlight class="stringliteral">&quot;unknown<sp/>cuDNN<sp/>RNN<sp/>mode<sp/>%d&quot;</highlight><highlight class="normal">,<sp/>mode);</highlight></codeline>
<codeline lineno="372"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="373"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="374"><highlight class="normal"></highlight></codeline>
<codeline lineno="375"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">/*</highlight></codeline>
<codeline lineno="376"><highlight class="comment"><sp/><sp/><sp/><sp/>Returns<sp/>weight<sp/>and<sp/>bias<sp/>tensors<sp/>for<sp/>each<sp/>layer<sp/>of<sp/>the<sp/>RNN.<sp/>These<sp/>tensors</highlight></codeline>
<codeline lineno="377"><highlight class="comment"><sp/><sp/><sp/><sp/>are<sp/>views<sp/>on<sp/>the<sp/>underlying<sp/>weight<sp/>buffer<sp/>allocated<sp/>by<sp/>CuDNN.</highlight></codeline>
<codeline lineno="378"><highlight class="comment"></highlight></codeline>
<codeline lineno="379"><highlight class="comment"><sp/><sp/><sp/><sp/>Note:<sp/>for<sp/>LSTM<sp/>and<sp/>GRU,<sp/>which<sp/>have<sp/>multiple<sp/>parameters<sp/>of<sp/>each<sp/>type<sp/>(4<sp/>and<sp/>3,<sp/>respectively),</highlight></codeline>
<codeline lineno="380"><highlight class="comment"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>these<sp/>parameters<sp/>are<sp/>concatenated<sp/>along<sp/>the<sp/>first<sp/>dimension.</highlight></codeline>
<codeline lineno="381"><highlight class="comment"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>These<sp/>parameters<sp/>are<sp/>returned<sp/>in<sp/>a<sp/>consistent<sp/>order<sp/>by<sp/>CuDNN:</highlight></codeline>
<codeline lineno="382"><highlight class="comment"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>(reset,<sp/>forget,<sp/>cell,<sp/>output)<sp/>for<sp/>LSTM</highlight></codeline>
<codeline lineno="383"><highlight class="comment"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>(reset,<sp/>input,<sp/>new)<sp/>for<sp/>GRU</highlight></codeline>
<codeline lineno="384"><highlight class="comment"><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="385"><highlight class="comment"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fn:<sp/>The<sp/>RNN<sp/>function<sp/>object<sp/>holding<sp/>the<sp/>RNN<sp/>state</highlight></codeline>
<codeline lineno="386"><highlight class="comment"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>handle:<sp/>a<sp/>CuDNN<sp/>handle</highlight></codeline>
<codeline lineno="387"><highlight class="comment"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>weight_buf:<sp/>a<sp/>1D<sp/>tensor<sp/>containing<sp/>the<sp/>CuDNN-allocated<sp/>weight<sp/>(or<sp/>grad_weight)<sp/>buffer</highlight></codeline>
<codeline lineno="388"><highlight class="comment"><sp/><sp/><sp/><sp/>Returns:</highlight></codeline>
<codeline lineno="389"><highlight class="comment"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>parameters:<sp/>[(weight_ih,<sp/>weight_hh,<sp/>bias_ih,<sp/>bias_hh)*],<sp/>with<sp/>length<sp/>equal<sp/>to<sp/>the<sp/>num_layers.</highlight></codeline>
<codeline lineno="390"><highlight class="comment"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>This<sp/>is<sp/>represented<sp/>as<sp/>a<sp/>pair<sp/>of<sp/>vector,<sp/>and<sp/>outer-dimension<sp/>stride</highlight></codeline>
<codeline lineno="391"><highlight class="comment"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>(NB:<sp/>Can&apos;t<sp/>return<sp/>MatrixRef<sp/>because<sp/>we<sp/>need<sp/>to<sp/>allocate<sp/>the<sp/>underlying<sp/>tensor)</highlight></codeline>
<codeline lineno="392"><highlight class="comment"><sp/><sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="393"><highlight class="normal"><sp/><sp/>std::pair&lt;std::vector&lt;Tensor&gt;,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">&gt;<sp/></highlight><highlight class="comment">//<sp/>stride0</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="394"><highlight class="normal"><sp/><sp/>get_parameters(</highlight></codeline>
<codeline lineno="395"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>cudnnHandle_t<sp/>handle,</highlight></codeline>
<codeline lineno="396"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>RNNDescriptorParams&amp;<sp/>rnn,</highlight></codeline>
<codeline lineno="397"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>RNNDescriptor&amp;<sp/>rnn_desc,</highlight></codeline>
<codeline lineno="398"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorDescriptor&amp;<sp/>x_desc,</highlight></codeline>
<codeline lineno="399"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>FilterDescriptor&amp;<sp/>w_desc,</highlight></codeline>
<codeline lineno="400"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>weight_buf</highlight></codeline>
<codeline lineno="401"><highlight class="normal"><sp/><sp/>)<sp/>{</highlight></codeline>
<codeline lineno="402"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>cudnn_methods<sp/>=<sp/>{<sp/>cudnnGetRNNLinLayerMatrixParams,<sp/>cudnnGetRNNLinLayerBiasParams<sp/>};</highlight></codeline>
<codeline lineno="403"><highlight class="normal"><sp/><sp/><sp/><sp/>std::vector&lt;Tensor&gt;<sp/>params;</highlight></codeline>
<codeline lineno="404"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>num_linear_layers<sp/>=<sp/>_num_linear_layers(rnn.mode);</highlight></codeline>
<codeline lineno="405"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>num_layers<sp/>=<sp/>rnn.num_directions()<sp/>*<sp/>rnn.num_layers;</highlight></codeline>
<codeline lineno="406"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>cur_offset<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="407"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>global_layer_params_count<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="408"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(int64_t<sp/>layer<sp/>=<sp/>0;<sp/>layer<sp/>&lt;<sp/>num_layers;<sp/>layer++)<sp/>{</highlight></codeline>
<codeline lineno="409"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>layer_params_count<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="410"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>cudnn_method<sp/>:<sp/>cudnn_methods)<sp/>{</highlight></codeline>
<codeline lineno="411"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(int64_t<sp/>linear_id<sp/>=<sp/>0;<sp/>linear_id<sp/>&lt;<sp/>num_linear_layers;<sp/>linear_id++)<sp/>{</highlight></codeline>
<codeline lineno="412"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>FilterDescriptor<sp/>lin_layer_mat_desc;</highlight></codeline>
<codeline lineno="413"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal">*<sp/>matrix_pointer;</highlight></codeline>
<codeline lineno="414"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>AT_CUDNN_CHECK(cudnn_method(</highlight></codeline>
<codeline lineno="415"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>handle,</highlight></codeline>
<codeline lineno="416"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>rnn_desc.desc(),</highlight></codeline>
<codeline lineno="417"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>layer,</highlight></codeline>
<codeline lineno="418"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>x_desc.desc(),</highlight></codeline>
<codeline lineno="419"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>w_desc.desc(),</highlight></codeline>
<codeline lineno="420"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>weight_buf.data_ptr(),</highlight></codeline>
<codeline lineno="421"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>linear_id,</highlight></codeline>
<codeline lineno="422"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>lin_layer_mat_desc.mut_desc(),</highlight></codeline>
<codeline lineno="423"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&amp;matrix_pointer</highlight></codeline>
<codeline lineno="424"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>));</highlight></codeline>
<codeline lineno="425"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cudnnDataType_t<sp/>data_type;</highlight></codeline>
<codeline lineno="426"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cudnnTensorFormat_t<sp/>format;</highlight></codeline>
<codeline lineno="427"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>nb_dims;</highlight></codeline>
<codeline lineno="428"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>constexpr<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>min_dim<sp/>=<sp/>3;</highlight></codeline>
<codeline lineno="429"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>The<sp/>use<sp/>of<sp/>CPU<sp/>tensor<sp/>here<sp/>is<sp/>a<sp/>bit<sp/>goofy<sp/>in<sp/>C++,</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="430"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>some<sp/>sort<sp/>of<sp/>alloca<sp/>would<sp/>be<sp/>good<sp/>enough<sp/>except<sp/>that<sp/>it<sp/>is</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="431"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>kind<sp/>of<sp/>convenient<sp/>to<sp/>be<sp/>able<sp/>to<sp/>prod()<sp/>on<sp/>it.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="432"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Tensor<sp/>filter_dim_a<sp/>=<sp/>at::CPU(kInt).tensor(min_dim);</highlight></codeline>
<codeline lineno="433"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>AT_CUDNN_CHECK(cudnnGetFilterNdDescriptor(</highlight></codeline>
<codeline lineno="434"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>lin_layer_mat_desc.desc(),</highlight></codeline>
<codeline lineno="435"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>min_dim,</highlight></codeline>
<codeline lineno="436"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&amp;data_type,</highlight></codeline>
<codeline lineno="437"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&amp;format,</highlight></codeline>
<codeline lineno="438"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&amp;nb_dims,</highlight></codeline>
<codeline lineno="439"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>filter_dim_a.data&lt;</highlight><highlight class="keywordtype">int</highlight><highlight class="normal">&gt;()</highlight></codeline>
<codeline lineno="440"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>));</highlight></codeline>
<codeline lineno="441"><highlight class="normal"></highlight></codeline>
<codeline lineno="442"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>AT_ASSERTM(nb_dims<sp/>&lt;=<sp/>min_dim,<sp/></highlight><highlight class="stringliteral">&quot;nb_dims<sp/>=<sp/>&quot;</highlight><highlight class="normal">,<sp/>nb_dims,<sp/></highlight><highlight class="stringliteral">&quot;;<sp/>min_dim<sp/><sp/>=<sp/>&quot;</highlight><highlight class="normal">,<sp/>min_dim);</highlight></codeline>
<codeline lineno="443"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>filter_dim_a<sp/>=<sp/>filter_dim_a.slice(0,<sp/>0,<sp/>nb_dims);</highlight></codeline>
<codeline lineno="444"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>elem_size<sp/>=<sp/>dataSize(rnn.datatype);</highlight></codeline>
<codeline lineno="445"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>offset_bytes<sp/>=<sp/>(</highlight><highlight class="keywordtype">char</highlight><highlight class="normal">*)matrix_pointer<sp/>-<sp/>(</highlight><highlight class="keywordtype">char</highlight><highlight class="normal">*)weight_buf.data_ptr();</highlight></codeline>
<codeline lineno="446"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>AT_ASSERTM(offset_bytes<sp/>%<sp/>elem_size<sp/>==<sp/>0,<sp/></highlight><highlight class="stringliteral">&quot;offset_bytes<sp/>=<sp/>&quot;</highlight><highlight class="normal">,<sp/>offset_bytes,<sp/></highlight><highlight class="stringliteral">&quot;;<sp/>elem_size<sp/>=<sp/>&quot;</highlight><highlight class="normal">,<sp/>elem_size);</highlight></codeline>
<codeline lineno="447"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>offset<sp/>=<sp/>offset_bytes<sp/>/<sp/>elem_size;</highlight></codeline>
<codeline lineno="448"><highlight class="normal"></highlight></codeline>
<codeline lineno="449"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>for<sp/>all<sp/>the<sp/>RNN<sp/>types<sp/>provided<sp/>by<sp/>CUDNN,<sp/>all<sp/>the<sp/>ih<sp/>weights</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="450"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>are<sp/>the<sp/>same<sp/>size<sp/>and<sp/>are<sp/>allocated<sp/>in<sp/>a<sp/>contiguous<sp/>chunk</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="451"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>(same<sp/>for<sp/>the<sp/>hh<sp/>weights,<sp/>and<sp/>the<sp/>ih<sp/>and<sp/>hh<sp/>biases).</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="452"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Since<sp/>we&apos;re<sp/>storing<sp/>all<sp/>the<sp/>weights<sp/>in<sp/>a<sp/>single<sp/>tensor<sp/>anyway,</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="453"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>might<sp/>as<sp/>well<sp/>merge<sp/>the<sp/>CUDNN<sp/>ones<sp/>into<sp/>a<sp/>single<sp/>tensor<sp/>as<sp/>well</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="454"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>mat_numel<sp/>=<sp/>*filter_dim_a.prod(at::ScalarType::Int).data&lt;</highlight><highlight class="keywordtype">int</highlight><highlight class="normal">&gt;();</highlight></codeline>
<codeline lineno="455"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(linear_id<sp/>==<sp/>0<sp/>||<sp/>linear_id<sp/>==<sp/>num_linear_layers<sp/>/<sp/>2)<sp/>{</highlight></codeline>
<codeline lineno="456"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>std::initializer_list&lt;int64_t&gt;<sp/>size<sp/>=<sp/>{</highlight></codeline>
<codeline lineno="457"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>mat_numel<sp/>*<sp/>num_linear_layers<sp/>/<sp/>2,<sp/>1};</highlight></codeline>
<codeline lineno="458"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Generate<sp/>a<sp/>new<sp/>parameter<sp/>tensor<sp/>which<sp/>is<sp/>a<sp/>view<sp/>into<sp/>the</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="459"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>weight_buf.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="460"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Tensor<sp/>param<sp/>=<sp/>weight_buf.type().tensor().set_(*weight_buf.storage(),<sp/>offset,<sp/>size);</highlight></codeline>
<codeline lineno="461"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>params.emplace_back(std::move(param));</highlight></codeline>
<codeline lineno="462"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>layer_params_count++;</highlight></codeline>
<codeline lineno="463"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="464"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>AT_ASSERTM(cur_offset<sp/>==<sp/>offset,<sp/></highlight><highlight class="stringliteral">&quot;cur_offset<sp/>=<sp/>&quot;</highlight><highlight class="normal">,<sp/>cur_offset,<sp/></highlight><highlight class="stringliteral">&quot;;<sp/>offset<sp/>=<sp/>&quot;</highlight><highlight class="normal">,<sp/>offset);</highlight></codeline>
<codeline lineno="465"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="466"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cur_offset<sp/>=<sp/>offset<sp/>+<sp/>mat_numel;</highlight></codeline>
<codeline lineno="467"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="468"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="comment">//<sp/>for<sp/>cudnn_method</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="469"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(layer<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="470"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>global_layer_params_count<sp/>=<sp/>layer_params_count;</highlight></codeline>
<codeline lineno="471"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="472"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>AT_ASSERTM(global_layer_params_count<sp/>==<sp/>layer_params_count,</highlight></codeline>
<codeline lineno="473"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;global_layer_params_count<sp/>=<sp/>&quot;</highlight><highlight class="normal">,<sp/>global_layer_params_count,</highlight></codeline>
<codeline lineno="474"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;;<sp/>layer_params_count<sp/>=<sp/>&quot;</highlight><highlight class="normal">,<sp/>layer_params_count);</highlight></codeline>
<codeline lineno="475"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="476"><highlight class="normal"><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="comment">//<sp/>for<sp/>layer</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="477"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>std::make_pair(params,<sp/>global_layer_params_count);</highlight></codeline>
<codeline lineno="478"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="479"><highlight class="normal"></highlight></codeline>
<codeline lineno="480"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>_copyParams(MatrixRef&lt;Tensor&gt;<sp/>params_from,<sp/>MatrixRef&lt;Tensor&gt;<sp/>params_to)<sp/>{</highlight></codeline>
<codeline lineno="481"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_ASSERTM(params_from.size(0)<sp/>==<sp/>params_to.size(0),<sp/></highlight><highlight class="stringliteral">&quot;number<sp/>of<sp/>layers<sp/>mismatch&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="482"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>params_from.size(0);<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="483"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>layer_params_from<sp/>=<sp/>params_from[i];</highlight></codeline>
<codeline lineno="484"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>layer_params_to<sp/>=<sp/>params_to[i];</highlight></codeline>
<codeline lineno="485"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>NOTE:<sp/>these<sp/>lists<sp/>have<sp/>all<sp/>weights<sp/>before<sp/>all<sp/>biases,<sp/>so<sp/>if<sp/>the<sp/>layer</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="486"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>doesn&apos;t<sp/>use<sp/>biases,<sp/>iteration<sp/>will<sp/>terminate<sp/>once<sp/>layer_params_from<sp/>ends</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="487"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>and<sp/>ignore<sp/>them.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="488"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>a<sp/>=<sp/>layer_params_from.begin(),<sp/>b<sp/>=<sp/>layer_params_to.begin();</highlight></codeline>
<codeline lineno="489"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>a<sp/>!=<sp/>layer_params_from.end()<sp/>&amp;&amp;<sp/>b<sp/>!=<sp/>layer_params_to.end();</highlight></codeline>
<codeline lineno="490"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>++a,<sp/>++b)<sp/>{</highlight></codeline>
<codeline lineno="491"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>param_from<sp/>=<sp/>*a,<sp/>param_to<sp/>=<sp/>*b;</highlight></codeline>
<codeline lineno="492"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>AT_ASSERTM(param_from.type()<sp/>==<sp/>param_to.type(),<sp/></highlight><highlight class="stringliteral">&quot;parameter<sp/>types<sp/>mismatch&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="493"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>param_to.copy_(param_from.view_as(param_to));</highlight></codeline>
<codeline lineno="494"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="495"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="496"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="497"><highlight class="normal"></highlight></codeline>
<codeline lineno="498"><highlight class="normal"><sp/><sp/>std::vector&lt;int64_t&gt;<sp/>_input_size(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorDescriptorListParams&amp;<sp/>tensors)<sp/>{</highlight></codeline>
<codeline lineno="499"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(tensors.is_input_packed())<sp/>{</highlight></codeline>
<codeline lineno="500"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>{tensors.batch_sizes_sum,<sp/>tensors.input_size};</highlight></codeline>
<codeline lineno="501"><highlight class="normal"><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="502"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>{tensors.seq_length,<sp/>tensors.mini_batch,<sp/>tensors.input_size};</highlight></codeline>
<codeline lineno="503"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="504"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="505"><highlight class="normal"></highlight></codeline>
<codeline lineno="506"><highlight class="normal"><sp/><sp/>std::vector&lt;int64_t&gt;<sp/>_hidden_size(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>RNNDescriptorParams&amp;<sp/>rnn,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorDescriptorListParams&amp;<sp/>tensors)<sp/>{</highlight></codeline>
<codeline lineno="507"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>{rnn.num_layers<sp/>*<sp/>rnn.num_directions(),<sp/>tensors.mini_batch,<sp/>rnn.hidden_size};</highlight></codeline>
<codeline lineno="508"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="509"><highlight class="normal"></highlight></codeline>
<codeline lineno="510"><highlight class="normal"><sp/><sp/>std::vector&lt;int64_t&gt;<sp/>_output_size(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>RNNDescriptorParams&amp;<sp/>rnn,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>TensorDescriptorListParams&amp;<sp/>tensors)<sp/>{</highlight></codeline>
<codeline lineno="511"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(tensors.is_input_packed())<sp/>{</highlight></codeline>
<codeline lineno="512"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>{tensors.batch_sizes_sum,<sp/>rnn.hidden_size<sp/>*<sp/>rnn.num_directions()};</highlight></codeline>
<codeline lineno="513"><highlight class="normal"><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="514"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>{tensors.seq_length,<sp/>tensors.mini_batch,<sp/>rnn.hidden_size<sp/>*<sp/>rnn.num_directions()};</highlight></codeline>
<codeline lineno="515"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="516"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="517"><highlight class="normal"></highlight></codeline>
<codeline lineno="518"><highlight class="normal">}<sp/></highlight><highlight class="comment">//<sp/>anonymous<sp/>namespace</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="519"><highlight class="normal"></highlight></codeline>
<codeline lineno="520"><highlight class="normal"></highlight><highlight class="comment">//<sp/>NB:<sp/>does<sp/>inplace<sp/>update<sp/>into<sp/>TensorList</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="521"><highlight class="normal"></highlight><highlight class="comment">//<sp/>It<sp/>would<sp/>be<sp/>a<sp/>relatively<sp/>simple<sp/>matter<sp/>to<sp/>refactor<sp/>this<sp/>into<sp/>multiple</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="522"><highlight class="normal"></highlight><highlight class="comment">//<sp/>functions,<sp/>only<sp/>one<sp/>of<sp/>which<sp/>does<sp/>an<sp/>inplace<sp/>update,<sp/>but<sp/>we<sp/>leave<sp/>this</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="523"><highlight class="normal"></highlight><highlight class="comment">//<sp/>for<sp/>future<sp/>work</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="524"><highlight class="normal">Tensor<sp/>_cudnn_rnn_flatten_weight(</highlight></codeline>
<codeline lineno="525"><highlight class="normal"><sp/><sp/><sp/><sp/>TensorList<sp/>weight_arr,<sp/>int64_t<sp/>weight_stride0,</highlight></codeline>
<codeline lineno="526"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>input_size,</highlight></codeline>
<codeline lineno="527"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>fn_mode,<sp/>int64_t<sp/>fn_hidden_size,</highlight></codeline>
<codeline lineno="528"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>fn_num_layers,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>batch_first,</highlight></codeline>
<codeline lineno="529"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>fn_bidirectional</highlight></codeline>
<codeline lineno="530"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>{</highlight></codeline>
<codeline lineno="531"><highlight class="normal"></highlight></codeline>
<codeline lineno="532"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(weight_arr.size()<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="533"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;_cudnn_rnn_flatten_weight_:<sp/>cannot<sp/>flatten<sp/>empty<sp/>weight<sp/>list&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="534"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="535"><highlight class="normal"></highlight></codeline>
<codeline lineno="536"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>any_param<sp/>=<sp/>weight_arr[0];</highlight></codeline>
<codeline lineno="537"><highlight class="normal"></highlight></codeline>
<codeline lineno="538"><highlight class="normal"><sp/><sp/>RNNDescriptorParams<sp/>rnn;</highlight></codeline>
<codeline lineno="539"><highlight class="normal"><sp/><sp/>rnn.set(fn_mode,<sp/>fn_hidden_size,<sp/>fn_num_layers,<sp/>fn_bidirectional,<sp/>getCudnnDataType(any_param));</highlight></codeline>
<codeline lineno="540"><highlight class="normal"></highlight></codeline>
<codeline lineno="541"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>handle<sp/>=<sp/>getCudnnHandle();</highlight></codeline>
<codeline lineno="542"><highlight class="normal"><sp/><sp/>RNNDescriptor<sp/>rnn_desc<sp/>=<sp/>rnn.descriptor(handle);</highlight></codeline>
<codeline lineno="543"><highlight class="normal"></highlight></codeline>
<codeline lineno="544"><highlight class="normal"><sp/><sp/>TensorGeometry<sp/>x_geom({1,<sp/>input_size});</highlight></codeline>
<codeline lineno="545"><highlight class="normal"><sp/><sp/>TensorDescriptor<sp/>x_desc;</highlight></codeline>
<codeline lineno="546"><highlight class="normal"><sp/><sp/>x_desc.set(getCudnnDataType(any_param),<sp/>x_geom.sizes(),<sp/>x_geom.strides(),<sp/>5);</highlight></codeline>
<codeline lineno="547"><highlight class="normal"></highlight></codeline>
<codeline lineno="548"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>num_weights<sp/>=<sp/>get_num_weights(handle,<sp/>rnn_desc,<sp/>x_desc,<sp/>rnn.datatype);</highlight></codeline>
<codeline lineno="549"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>weight_buf<sp/>=<sp/>any_param.type().tensor(num_weights).zero_();</highlight></codeline>
<codeline lineno="550"><highlight class="normal"></highlight></codeline>
<codeline lineno="551"><highlight class="normal"><sp/><sp/>FilterDescriptor<sp/>w_desc;</highlight></codeline>
<codeline lineno="552"><highlight class="normal"><sp/><sp/>w_desc.set(weight_buf,<sp/>3);</highlight></codeline>
<codeline lineno="553"><highlight class="normal"></highlight></codeline>
<codeline lineno="554"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Slice<sp/>off<sp/>views<sp/>into<sp/>weight_buf</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="555"><highlight class="normal"><sp/><sp/>std::vector&lt;Tensor&gt;<sp/>params_arr;</highlight></codeline>
<codeline lineno="556"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>params_stride0;</highlight></codeline>
<codeline lineno="557"><highlight class="normal"><sp/><sp/>std::tie(params_arr,<sp/>params_stride0)<sp/>=<sp/>get_parameters(handle,<sp/>rnn,<sp/>rnn_desc,<sp/>x_desc,<sp/>w_desc,<sp/>weight_buf);</highlight></codeline>
<codeline lineno="558"><highlight class="normal"></highlight></codeline>
<codeline lineno="559"><highlight class="normal"><sp/><sp/>MatrixRef&lt;Tensor&gt;<sp/>weight{weight_arr,<sp/></highlight><highlight class="keyword">static_cast&lt;</highlight><highlight class="keywordtype">size_t</highlight><highlight class="keyword">&gt;</highlight><highlight class="normal">(weight_stride0)},</highlight></codeline>
<codeline lineno="560"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>params{params_arr,<sp/>params_stride0};</highlight></codeline>
<codeline lineno="561"><highlight class="normal"></highlight></codeline>
<codeline lineno="562"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Copy<sp/>weights</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="563"><highlight class="normal"><sp/><sp/>_copyParams(weight,<sp/>params);</highlight></codeline>
<codeline lineno="564"><highlight class="normal"></highlight></codeline>
<codeline lineno="565"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Update<sp/>the<sp/>storage</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="566"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>weight.size(0);<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="567"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>orig_param_it<sp/>=<sp/>weight[i].begin(),<sp/>new_param_it<sp/>=<sp/>params[i].begin();</highlight></codeline>
<codeline lineno="568"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>orig_param_it<sp/>!=<sp/>weight[i].end()<sp/>&amp;&amp;<sp/>new_param_it<sp/>!=<sp/>params[i].end();</highlight></codeline>
<codeline lineno="569"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>orig_param_it++,<sp/>new_param_it++)<sp/>{</highlight></codeline>
<codeline lineno="570"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>orig_param<sp/>=<sp/>*orig_param_it,<sp/>new_param<sp/>=<sp/>*new_param_it;</highlight></codeline>
<codeline lineno="571"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>orig_param.set_(new_param.view_as(orig_param));</highlight></codeline>
<codeline lineno="572"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="573"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="574"><highlight class="normal"></highlight></codeline>
<codeline lineno="575"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>weight_buf;</highlight></codeline>
<codeline lineno="576"><highlight class="normal">}</highlight></codeline>
<codeline lineno="577"><highlight class="normal"></highlight></codeline>
<codeline lineno="578"><highlight class="normal"></highlight><highlight class="comment">//<sp/>NB:<sp/>when<sp/>fn_batch_sizes<sp/>is<sp/>empty,<sp/>that<sp/>means<sp/>no<sp/>batch<sp/>sizes<sp/>was<sp/>specified</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="579"><highlight class="normal">std::tuple&lt;Tensor,<sp/>Tensor,<sp/>Tensor,<sp/>Tensor,<sp/>Tensor&gt;<sp/>_cudnn_rnn(</highlight></codeline>
<codeline lineno="580"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>input_r,</highlight></codeline>
<codeline lineno="581"><highlight class="normal"><sp/><sp/><sp/><sp/>TensorList<sp/>weight,<sp/>int64_t<sp/>weight_stride0,</highlight></codeline>
<codeline lineno="582"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>weight_buf_r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>hx,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>cx,</highlight></codeline>
<codeline lineno="583"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>fn_mode,<sp/>int64_t<sp/>fn_hidden_size,</highlight></codeline>
<codeline lineno="584"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>fn_num_layers,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>batch_first,<sp/></highlight><highlight class="keywordtype">double</highlight><highlight class="normal"><sp/>fn_dropout,</highlight></codeline>
<codeline lineno="585"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>fn_train,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>fn_bidirectional,<sp/>IntList<sp/>fn_batch_sizes,</highlight></codeline>
<codeline lineno="586"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>fn_dropout_state</highlight></codeline>
<codeline lineno="587"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>{</highlight></codeline>
<codeline lineno="588"><highlight class="normal"></highlight></codeline>
<codeline lineno="589"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>input<sp/>=<sp/>input_r;</highlight></codeline>
<codeline lineno="590"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>weight_buf<sp/>=<sp/>weight_buf_r;</highlight></codeline>
<codeline lineno="591"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(fn_dropout_state.defined())<sp/>{</highlight></codeline>
<codeline lineno="592"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>input_arg<sp/>=<sp/>TensorArg(input,<sp/></highlight><highlight class="stringliteral">&quot;input&quot;</highlight><highlight class="normal">,<sp/>1);</highlight></codeline>
<codeline lineno="593"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dropout_state_arg<sp/>=<sp/>TensorArg(fn_dropout_state,<sp/></highlight><highlight class="stringliteral">&quot;dropout_states&quot;</highlight><highlight class="normal">,<sp/>15);</highlight></codeline>
<codeline lineno="594"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>checkSameGPU(</highlight><highlight class="stringliteral">&quot;cudnn_rnn&quot;</highlight><highlight class="normal">,<sp/>input_arg,<sp/>dropout_state_arg);</highlight></codeline>
<codeline lineno="595"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="596"><highlight class="normal"><sp/><sp/>RNNParams<sp/>fn;</highlight></codeline>
<codeline lineno="597"><highlight class="normal"><sp/><sp/>fn.rnn.set(fn_mode,<sp/>fn_hidden_size,<sp/>fn_num_layers,<sp/>fn_bidirectional,<sp/>getCudnnDataType(input));</highlight></codeline>
<codeline lineno="598"><highlight class="normal"><sp/><sp/>fn.dropout.set(fn_train,<sp/>fn_dropout,<sp/>fn_dropout_state);</highlight></codeline>
<codeline lineno="599"><highlight class="normal"><sp/><sp/>fn.tensors.set(input.sizes(),<sp/>fn_batch_sizes,<sp/>batch_first);</highlight></codeline>
<codeline lineno="600"><highlight class="normal"></highlight></codeline>
<codeline lineno="601"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>Set<sp/>device<sp/>to<sp/>input</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="602"><highlight class="normal"></highlight></codeline>
<codeline lineno="603"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(fn.rnn.mode<sp/>!=<sp/>CUDNN_LSTM)<sp/>{</highlight></codeline>
<codeline lineno="604"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cx.defined())<sp/>{</highlight></codeline>
<codeline lineno="605"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;rnn:<sp/>illegal<sp/>defined<sp/>cx<sp/>for<sp/>non-LSTM<sp/>RNN&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="606"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="607"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="608"><highlight class="normal"></highlight></codeline>
<codeline lineno="609"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>can<sp/>batch_first<sp/>be<sp/>a<sp/>wrapper<sp/>around<sp/>this<sp/>function?</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="610"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>is_input_packed<sp/>=<sp/>fn.tensors.batch_sizes.size()<sp/>!=<sp/>0;</highlight></codeline>
<codeline lineno="611"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(batch_first<sp/>&amp;&amp;<sp/>!is_input_packed)<sp/>{</highlight></codeline>
<codeline lineno="612"><highlight class="normal"><sp/><sp/><sp/><sp/>input<sp/>=<sp/>input.transpose(0,<sp/>1);</highlight></codeline>
<codeline lineno="613"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="614"><highlight class="normal"></highlight></codeline>
<codeline lineno="615"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>hidden_size<sp/>=<sp/>_hidden_size(fn.rnn,<sp/>fn.tensors);</highlight></codeline>
<codeline lineno="616"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>output_size<sp/>=<sp/>_output_size(fn.rnn,<sp/>fn.tensors);</highlight></codeline>
<codeline lineno="617"><highlight class="normal"></highlight></codeline>
<codeline lineno="618"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!hx.is_contiguous())<sp/>{</highlight></codeline>
<codeline lineno="619"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;rnn:<sp/>hx<sp/>is<sp/>not<sp/>contiguous&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="620"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="621"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cx.defined()<sp/>&amp;&amp;<sp/>!cx.is_contiguous())<sp/>{</highlight></codeline>
<codeline lineno="622"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;rnn:<sp/>cx<sp/>is<sp/>not<sp/>contiguous&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="623"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="624"><highlight class="normal"></highlight></codeline>
<codeline lineno="625"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>x<sp/>=<sp/>input.contiguous();</highlight></codeline>
<codeline lineno="626"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>output<sp/>=<sp/>input.type().tensor(output_size);</highlight></codeline>
<codeline lineno="627"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>hy<sp/>=<sp/>hx.type().tensor(hidden_size);</highlight></codeline>
<codeline lineno="628"><highlight class="normal"><sp/><sp/>Tensor<sp/>cy;</highlight></codeline>
<codeline lineno="629"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cx.defined())<sp/>{</highlight></codeline>
<codeline lineno="630"><highlight class="normal"><sp/><sp/><sp/><sp/>cy<sp/>=<sp/>cx.type().tensor(hidden_size);</highlight></codeline>
<codeline lineno="631"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="632"><highlight class="normal"><sp/><sp/><sp/><sp/>cy<sp/>=<sp/>hx.type().tensor();<sp/></highlight><highlight class="comment">//<sp/>NB:<sp/>Not<sp/>allowed<sp/>to<sp/>return<sp/>undefined<sp/>tensors</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="633"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="634"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>y<sp/>=<sp/>output;</highlight></codeline>
<codeline lineno="635"><highlight class="normal"></highlight></codeline>
<codeline lineno="636"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>handle<sp/>=<sp/>getCudnnHandle();</highlight></codeline>
<codeline lineno="637"><highlight class="normal"><sp/><sp/>RNNDescriptors<sp/>descs(fn,<sp/>handle,<sp/>x,<sp/>y,<sp/>hx,<sp/>cx);</highlight></codeline>
<codeline lineno="638"><highlight class="normal"></highlight></codeline>
<codeline lineno="639"><highlight class="normal"><sp/><sp/>FilterDescriptor<sp/>w_desc;</highlight></codeline>
<codeline lineno="640"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!weight_buf.defined())<sp/>{</highlight></codeline>
<codeline lineno="641"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>num_weights<sp/>=<sp/>get_num_weights(handle,<sp/>descs.rnn_desc,<sp/>descs.x_descs[0],<sp/>fn.rnn.datatype);</highlight></codeline>
<codeline lineno="642"><highlight class="normal"><sp/><sp/><sp/><sp/>weight_buf<sp/>=<sp/>x.type().tensor(num_weights);</highlight></codeline>
<codeline lineno="643"><highlight class="normal"><sp/><sp/><sp/><sp/>w_desc.set(weight_buf,<sp/>3);</highlight></codeline>
<codeline lineno="644"><highlight class="normal"><sp/><sp/><sp/><sp/>weight_buf.zero_();</highlight></codeline>
<codeline lineno="645"><highlight class="normal"><sp/><sp/><sp/><sp/>std::vector&lt;Tensor&gt;<sp/>params;</highlight></codeline>
<codeline lineno="646"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>params_stride0;</highlight></codeline>
<codeline lineno="647"><highlight class="normal"><sp/><sp/><sp/><sp/>std::tie(params,<sp/>params_stride0)<sp/>=<sp/>get_parameters(handle,<sp/>fn.rnn,<sp/>descs.rnn_desc,<sp/>descs.x_descs[0],<sp/>w_desc,<sp/>weight_buf);</highlight></codeline>
<codeline lineno="648"><highlight class="normal"><sp/><sp/><sp/><sp/>_copyParams(MatrixRef&lt;Tensor&gt;{weight,<sp/></highlight><highlight class="keyword">static_cast&lt;</highlight><highlight class="keywordtype">size_t</highlight><highlight class="keyword">&gt;</highlight><highlight class="normal">(weight_stride0)},</highlight></codeline>
<codeline lineno="649"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>MatrixRef&lt;Tensor&gt;{params,<sp/>params_stride0});</highlight></codeline>
<codeline lineno="650"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="651"><highlight class="normal"><sp/><sp/><sp/><sp/>w_desc.set(weight_buf,<sp/>3);</highlight></codeline>
<codeline lineno="652"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="653"><highlight class="normal"></highlight></codeline>
<codeline lineno="654"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cx.defined()<sp/>&amp;&amp;<sp/>!cx.sizes().equals(hidden_size))<sp/>{</highlight></codeline>
<codeline lineno="655"><highlight class="normal"><sp/><sp/><sp/><sp/>std::ostringstream<sp/>oss;</highlight></codeline>
<codeline lineno="656"><highlight class="normal"><sp/><sp/><sp/><sp/>oss<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;Expected<sp/>cell<sp/>size<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>IntList{hidden_size}<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>cx.sizes();</highlight></codeline>
<codeline lineno="657"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(oss.str());</highlight></codeline>
<codeline lineno="658"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="659"><highlight class="normal"></highlight></codeline>
<codeline lineno="660"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>workspace_size;</highlight></codeline>
<codeline lineno="661"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>x_descs_arr<sp/>=<sp/>descs.get_x_descs();</highlight></codeline>
<codeline lineno="662"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>y_descs_arr<sp/>=<sp/>descs.get_y_descs();</highlight></codeline>
<codeline lineno="663"><highlight class="normal"><sp/><sp/>AT_CUDNN_CHECK(cudnnGetRNNWorkspaceSize(</highlight></codeline>
<codeline lineno="664"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>handle,</highlight></codeline>
<codeline lineno="665"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.rnn_desc.desc(),</highlight></codeline>
<codeline lineno="666"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fn.tensors.seq_length,</highlight></codeline>
<codeline lineno="667"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>x_descs_arr.data(),</highlight></codeline>
<codeline lineno="668"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&amp;workspace_size</highlight></codeline>
<codeline lineno="669"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>));</highlight></codeline>
<codeline lineno="670"><highlight class="normal"><sp/><sp/>Tensor<sp/>workspace<sp/>=<sp/>input.type().toScalarType(kByte).tensor(workspace_size);</highlight></codeline>
<codeline lineno="671"><highlight class="normal"></highlight></codeline>
<codeline lineno="672"><highlight class="normal"><sp/><sp/>Tensor<sp/>reserve;</highlight></codeline>
<codeline lineno="673"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>NB:<sp/>Previously,<sp/>the<sp/>test<sp/>was<sp/>for<sp/>fn.requires_grad,<sp/>but<sp/>we<sp/>don&apos;t<sp/>have</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="674"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>this<sp/>information.<sp/><sp/>Use<sp/>&apos;train&apos;<sp/>as<sp/>a<sp/>proxy.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="675"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(fn_train)<sp/>{</highlight></codeline>
<codeline lineno="676"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>reserve_size;</highlight></codeline>
<codeline lineno="677"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_CUDNN_CHECK(cudnnGetRNNTrainingReserveSize(</highlight></codeline>
<codeline lineno="678"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>handle,</highlight></codeline>
<codeline lineno="679"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.rnn_desc.desc(),</highlight></codeline>
<codeline lineno="680"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fn.tensors.seq_length,</highlight></codeline>
<codeline lineno="681"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>x_descs_arr.data(),</highlight></codeline>
<codeline lineno="682"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&amp;reserve_size</highlight></codeline>
<codeline lineno="683"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>));</highlight></codeline>
<codeline lineno="684"><highlight class="normal"><sp/><sp/><sp/><sp/>reserve<sp/>=<sp/>input.type().toScalarType(kByte).tensor(reserve_size);</highlight></codeline>
<codeline lineno="685"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_CUDNN_CHECK(cudnnRNNForwardTraining(</highlight></codeline>
<codeline lineno="686"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>handle,</highlight></codeline>
<codeline lineno="687"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.rnn_desc.desc(),</highlight></codeline>
<codeline lineno="688"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fn.tensors.seq_length,</highlight></codeline>
<codeline lineno="689"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>x_descs_arr.data(),<sp/>x.data_ptr(),</highlight></codeline>
<codeline lineno="690"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.hx_desc.desc(),<sp/>hx.data_ptr(),</highlight></codeline>
<codeline lineno="691"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.cx_desc.desc(),<sp/>cx.defined()<sp/>?<sp/>cx.data_ptr()<sp/>:<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="692"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>w_desc.desc(),<sp/>weight_buf.data_ptr(),</highlight></codeline>
<codeline lineno="693"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>y_descs_arr.data(),<sp/>y.data_ptr(),</highlight></codeline>
<codeline lineno="694"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.hy_desc.desc(),<sp/>hy.data_ptr(),</highlight></codeline>
<codeline lineno="695"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.cy_desc.desc(),<sp/>cy.defined()<sp/>?<sp/>cy.data_ptr()<sp/>:<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="696"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>workspace.data_ptr(),<sp/>workspace.size(0),</highlight></codeline>
<codeline lineno="697"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>reserve.data_ptr(),<sp/>reserve.size(0)</highlight></codeline>
<codeline lineno="698"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>));</highlight></codeline>
<codeline lineno="699"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{<sp/></highlight><highlight class="comment">//<sp/>inference</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="700"><highlight class="normal"><sp/><sp/><sp/><sp/>reserve<sp/>=<sp/>input.type().toScalarType(kByte).tensor();</highlight></codeline>
<codeline lineno="701"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_CUDNN_CHECK(cudnnRNNForwardInference(</highlight></codeline>
<codeline lineno="702"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>handle,</highlight></codeline>
<codeline lineno="703"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.rnn_desc.desc(),</highlight></codeline>
<codeline lineno="704"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fn.tensors.seq_length,</highlight></codeline>
<codeline lineno="705"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>x_descs_arr.data(),<sp/>x.data_ptr(),</highlight></codeline>
<codeline lineno="706"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.hx_desc.desc(),<sp/>hx.data_ptr(),</highlight></codeline>
<codeline lineno="707"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.cx_desc.desc(),<sp/>cx.defined()<sp/>?<sp/>cx.data_ptr()<sp/>:<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="708"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>w_desc.desc(),<sp/>weight_buf.data_ptr(),</highlight></codeline>
<codeline lineno="709"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>y_descs_arr.data(),<sp/>y.data_ptr(),</highlight></codeline>
<codeline lineno="710"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.hy_desc.desc(),<sp/>hy.data_ptr(),</highlight></codeline>
<codeline lineno="711"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.cy_desc.desc(),<sp/>cy.defined()<sp/>?<sp/>cy.data_ptr()<sp/>:<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="712"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>workspace.data_ptr(),<sp/>workspace.size(0)</highlight></codeline>
<codeline lineno="713"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>));</highlight></codeline>
<codeline lineno="714"><highlight class="normal"></highlight></codeline>
<codeline lineno="715"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="716"><highlight class="normal"></highlight></codeline>
<codeline lineno="717"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(batch_first<sp/>&amp;&amp;<sp/>!is_input_packed)<sp/>{</highlight></codeline>
<codeline lineno="718"><highlight class="normal"><sp/><sp/><sp/><sp/>output.transpose_(0,<sp/>1);</highlight></codeline>
<codeline lineno="719"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="720"><highlight class="normal"></highlight></codeline>
<codeline lineno="721"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>std::make_tuple(output,<sp/>hy,<sp/>cy,<sp/>reserve,<sp/>weight_buf);</highlight></codeline>
<codeline lineno="722"><highlight class="normal">}</highlight></codeline>
<codeline lineno="723"><highlight class="normal"></highlight></codeline>
<codeline lineno="724"><highlight class="normal">std::tuple&lt;Tensor,<sp/>Tensor,<sp/>Tensor&gt;<sp/>_cudnn_rnn_backward_input(</highlight></codeline>
<codeline lineno="725"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>input_r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>weight_buf,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>hx,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>cx,</highlight></codeline>
<codeline lineno="726"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>output_r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_output_r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_hy,</highlight></codeline>
<codeline lineno="727"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_cy,</highlight></codeline>
<codeline lineno="728"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>fn_mode,<sp/>int64_t<sp/>fn_hidden_size,</highlight></codeline>
<codeline lineno="729"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>fn_num_layers,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>batch_first,<sp/></highlight><highlight class="keywordtype">double</highlight><highlight class="normal"><sp/>fn_dropout,</highlight></codeline>
<codeline lineno="730"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>fn_train,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>fn_bidirectional,<sp/>IntList<sp/>fn_batch_sizes,</highlight></codeline>
<codeline lineno="731"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>fn_dropout_state,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>fn_reserve,</highlight></codeline>
<codeline lineno="732"><highlight class="normal"><sp/><sp/><sp/><sp/>std::array&lt;bool,<sp/>3&gt;<sp/>output_mask</highlight></codeline>
<codeline lineno="733"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>{</highlight></codeline>
<codeline lineno="734"><highlight class="normal"></highlight></codeline>
<codeline lineno="735"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>input<sp/>=<sp/>input_r;</highlight></codeline>
<codeline lineno="736"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>grad_output<sp/>=<sp/>grad_output_r;</highlight></codeline>
<codeline lineno="737"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>output<sp/>=<sp/>output_r;</highlight></codeline>
<codeline lineno="738"><highlight class="normal"></highlight></codeline>
<codeline lineno="739"><highlight class="normal"><sp/><sp/>RNNParams<sp/>fn;</highlight></codeline>
<codeline lineno="740"><highlight class="normal"><sp/><sp/>fn.rnn.set(fn_mode,<sp/>fn_hidden_size,<sp/>fn_num_layers,<sp/>fn_bidirectional,<sp/>getCudnnDataType(input));</highlight></codeline>
<codeline lineno="741"><highlight class="normal"><sp/><sp/>fn.dropout.set(fn_train,<sp/>fn_dropout,<sp/>fn_dropout_state);</highlight></codeline>
<codeline lineno="742"><highlight class="normal"><sp/><sp/>fn.tensors.set(input.sizes(),<sp/>fn_batch_sizes,<sp/>batch_first);</highlight></codeline>
<codeline lineno="743"><highlight class="normal"></highlight></codeline>
<codeline lineno="744"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>Set<sp/>device<sp/>to<sp/>input</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="745"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>handle<sp/>=<sp/>getCudnnHandle();</highlight></codeline>
<codeline lineno="746"><highlight class="normal"></highlight></codeline>
<codeline lineno="747"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(fn.rnn.mode<sp/>!=<sp/>CUDNN_LSTM)<sp/>{</highlight></codeline>
<codeline lineno="748"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cx.defined())<sp/>{</highlight></codeline>
<codeline lineno="749"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;rnn:<sp/>illegal<sp/>defined<sp/>cx<sp/>for<sp/>non-LSTM<sp/>RNN&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="750"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="751"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="752"><highlight class="normal"></highlight></codeline>
<codeline lineno="753"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>is_input_packed<sp/>=<sp/>fn_batch_sizes.size()<sp/>!=<sp/>0;</highlight></codeline>
<codeline lineno="754"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(batch_first<sp/>&amp;&amp;<sp/>!is_input_packed)<sp/>{</highlight></codeline>
<codeline lineno="755"><highlight class="normal"><sp/><sp/><sp/><sp/>input<sp/>=<sp/>input.transpose(0,<sp/>1);</highlight></codeline>
<codeline lineno="756"><highlight class="normal"><sp/><sp/><sp/><sp/>grad_output<sp/>=<sp/>grad_output.transpose(0,<sp/>1);</highlight></codeline>
<codeline lineno="757"><highlight class="normal"><sp/><sp/><sp/><sp/>output<sp/>=<sp/>output.transpose(0,<sp/>1);</highlight></codeline>
<codeline lineno="758"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="759"><highlight class="normal"></highlight></codeline>
<codeline lineno="760"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>input_size<sp/>=<sp/>_input_size(fn.tensors);</highlight></codeline>
<codeline lineno="761"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>hidden_size<sp/>=<sp/>_hidden_size(fn.rnn,<sp/>fn.tensors);</highlight></codeline>
<codeline lineno="762"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>output_size<sp/>=<sp/>_output_size(fn.rnn,<sp/>fn.tensors);</highlight></codeline>
<codeline lineno="763"><highlight class="normal"></highlight></codeline>
<codeline lineno="764"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!hx.is_contiguous())<sp/>{</highlight></codeline>
<codeline lineno="765"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;rnn:<sp/>hx<sp/>is<sp/>not<sp/>contiguous&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="766"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="767"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cx.defined()<sp/>&amp;&amp;<sp/>!cx.is_contiguous())<sp/>{</highlight></codeline>
<codeline lineno="768"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;rnn:<sp/>cx<sp/>is<sp/>not<sp/>contiguous&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="769"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="770"><highlight class="normal"></highlight></codeline>
<codeline lineno="771"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>x<sp/>=<sp/>input.contiguous();</highlight></codeline>
<codeline lineno="772"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dy<sp/>=<sp/>grad_output.contiguous();</highlight></codeline>
<codeline lineno="773"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>y<sp/>=<sp/>output;</highlight></codeline>
<codeline lineno="774"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>w<sp/>=<sp/>weight_buf;</highlight></codeline>
<codeline lineno="775"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dx<sp/>=<sp/>input.type().tensor(input.sizes());<sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>more<sp/>compact<sp/>way<sp/>of<sp/>saying<sp/>this</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="776"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dhy<sp/>=<sp/>grad_hy.contiguous().view(hidden_size);</highlight></codeline>
<codeline lineno="777"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dcy<sp/>=<sp/>grad_cy.defined()<sp/>?<sp/>grad_cy.contiguous().view(hidden_size)<sp/>:<sp/>Tensor();</highlight></codeline>
<codeline lineno="778"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dhx<sp/>=<sp/>hx.type().tensor(hidden_size);</highlight></codeline>
<codeline lineno="779"><highlight class="normal"><sp/><sp/>AT_ASSERTM(cx.defined()<sp/>||<sp/>!output_mask[2],<sp/></highlight><highlight class="stringliteral">&quot;illegally<sp/>required<sp/>grad<sp/>of<sp/>cx<sp/>for<sp/>non-LSTM<sp/>RNN&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="780"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dcx<sp/>=<sp/>cx.defined()<sp/>?<sp/>cx.type().tensor(hidden_size)<sp/>:<sp/>Tensor();</highlight></codeline>
<codeline lineno="781"><highlight class="normal"></highlight></codeline>
<codeline lineno="782"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!fn_train)<sp/>{</highlight></codeline>
<codeline lineno="783"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;cudnn<sp/>RNN<sp/>backward<sp/>can<sp/>only<sp/>be<sp/>called<sp/>in<sp/>training<sp/>mode&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="784"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="785"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!input.sizes().equals(input_size))<sp/>{</highlight></codeline>
<codeline lineno="786"><highlight class="normal"><sp/><sp/><sp/><sp/>std::ostringstream<sp/>oss;</highlight></codeline>
<codeline lineno="787"><highlight class="normal"><sp/><sp/><sp/><sp/>oss<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;Expected<sp/>input<sp/>size<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>IntList{input_size}<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>input.sizes();</highlight></codeline>
<codeline lineno="788"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(oss.str());</highlight></codeline>
<codeline lineno="789"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="790"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!output.sizes().equals(output_size))<sp/>{</highlight></codeline>
<codeline lineno="791"><highlight class="normal"><sp/><sp/><sp/><sp/>std::ostringstream<sp/>oss;</highlight></codeline>
<codeline lineno="792"><highlight class="normal"><sp/><sp/><sp/><sp/>oss<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;Expected<sp/>output<sp/>size<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>IntList{output_size}<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>output.sizes();</highlight></codeline>
<codeline lineno="793"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(oss.str());</highlight></codeline>
<codeline lineno="794"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="795"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(hx.defined()<sp/>&amp;&amp;<sp/>!hx.sizes().equals(hidden_size))<sp/>{</highlight></codeline>
<codeline lineno="796"><highlight class="normal"><sp/><sp/><sp/><sp/>std::ostringstream<sp/>oss;</highlight></codeline>
<codeline lineno="797"><highlight class="normal"><sp/><sp/><sp/><sp/>oss<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;Expected<sp/>hidden<sp/>size<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>IntList{hidden_size}<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>hx.sizes();</highlight></codeline>
<codeline lineno="798"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(oss.str());</highlight></codeline>
<codeline lineno="799"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="800"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cx.defined()<sp/>&amp;&amp;<sp/>!cx.sizes().equals(hidden_size))<sp/>{</highlight></codeline>
<codeline lineno="801"><highlight class="normal"><sp/><sp/><sp/><sp/>std::ostringstream<sp/>oss;</highlight></codeline>
<codeline lineno="802"><highlight class="normal"><sp/><sp/><sp/><sp/>oss<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;Expected<sp/>cell<sp/>size<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>IntList{hidden_size}<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>cx.sizes();</highlight></codeline>
<codeline lineno="803"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(oss.str());</highlight></codeline>
<codeline lineno="804"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="805"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(dhy.defined()<sp/>&amp;&amp;<sp/>!dhy.sizes().equals(hidden_size))<sp/>{</highlight></codeline>
<codeline lineno="806"><highlight class="normal"><sp/><sp/><sp/><sp/>std::ostringstream<sp/>oss;</highlight></codeline>
<codeline lineno="807"><highlight class="normal"><sp/><sp/><sp/><sp/>oss<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;Expected<sp/>d_hidden<sp/>size<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>IntList{hidden_size}<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>dhy.sizes();</highlight></codeline>
<codeline lineno="808"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(oss.str());</highlight></codeline>
<codeline lineno="809"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="810"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(dcy.defined()<sp/>&amp;&amp;<sp/>!dcy.sizes().equals(hidden_size))<sp/>{</highlight></codeline>
<codeline lineno="811"><highlight class="normal"><sp/><sp/><sp/><sp/>std::ostringstream<sp/>oss;</highlight></codeline>
<codeline lineno="812"><highlight class="normal"><sp/><sp/><sp/><sp/>oss<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;Expected<sp/>d_cell<sp/>size<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>IntList{hidden_size}<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>dcy.sizes();</highlight></codeline>
<codeline lineno="813"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(oss.str());</highlight></codeline>
<codeline lineno="814"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="815"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!dhy.is_cuda()<sp/>||<sp/>!dy.is_cuda()<sp/>||<sp/>(dcy.defined()<sp/>&amp;&amp;<sp/>!dcy.is_cuda()))<sp/>{</highlight></codeline>
<codeline lineno="816"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;Gradients<sp/>aren&apos;t<sp/>CUDA<sp/>tensors&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="817"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="818"><highlight class="normal"></highlight></codeline>
<codeline lineno="819"><highlight class="normal"><sp/><sp/>RNNDescriptors<sp/>descs(fn,<sp/>handle,<sp/>x,<sp/>y,<sp/>hx,<sp/>cx);</highlight></codeline>
<codeline lineno="820"><highlight class="normal"></highlight></codeline>
<codeline lineno="821"><highlight class="normal"><sp/><sp/>FilterDescriptor<sp/>w_desc;</highlight></codeline>
<codeline lineno="822"><highlight class="normal"><sp/><sp/>w_desc.set(weight_buf,<sp/>3);</highlight></codeline>
<codeline lineno="823"><highlight class="normal"></highlight></codeline>
<codeline lineno="824"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>workspace_size;</highlight></codeline>
<codeline lineno="825"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>x_descs_arr<sp/>=<sp/>descs.get_x_descs();</highlight></codeline>
<codeline lineno="826"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>y_descs_arr<sp/>=<sp/>descs.get_y_descs();</highlight></codeline>
<codeline lineno="827"><highlight class="normal"><sp/><sp/>AT_CUDNN_CHECK(cudnnGetRNNWorkspaceSize(</highlight></codeline>
<codeline lineno="828"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>handle,</highlight></codeline>
<codeline lineno="829"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.rnn_desc.desc(),</highlight></codeline>
<codeline lineno="830"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fn.tensors.seq_length,</highlight></codeline>
<codeline lineno="831"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>x_descs_arr.data(),</highlight></codeline>
<codeline lineno="832"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&amp;workspace_size</highlight></codeline>
<codeline lineno="833"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>));</highlight></codeline>
<codeline lineno="834"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>put<sp/>this<sp/>in<sp/>the<sp/>correct<sp/>device???</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="835"><highlight class="normal"><sp/><sp/>Tensor<sp/>workspace<sp/>=<sp/>input.type().toScalarType(kByte).tensor(workspace_size);</highlight></codeline>
<codeline lineno="836"><highlight class="normal"></highlight></codeline>
<codeline lineno="837"><highlight class="normal"><sp/><sp/>AT_CUDNN_CHECK(cudnnRNNBackwardData(</highlight></codeline>
<codeline lineno="838"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>handle,</highlight></codeline>
<codeline lineno="839"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.rnn_desc.desc(),</highlight></codeline>
<codeline lineno="840"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fn.tensors.seq_length,</highlight></codeline>
<codeline lineno="841"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>y_descs_arr.data(),<sp/>y.data_ptr(),</highlight></codeline>
<codeline lineno="842"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>y_descs_arr.data(),<sp/>dy.data_ptr(),</highlight></codeline>
<codeline lineno="843"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.hy_desc.desc(),<sp/>dhy.data_ptr(),</highlight></codeline>
<codeline lineno="844"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.cy_desc.desc(),<sp/>cx.defined()<sp/>?<sp/>dcy.data_ptr()<sp/>:<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="845"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>w_desc.desc(),<sp/>w.data_ptr(),</highlight></codeline>
<codeline lineno="846"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.hx_desc.desc(),<sp/>hx.data_ptr(),</highlight></codeline>
<codeline lineno="847"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.cx_desc.desc(),<sp/>cx.defined()<sp/>?<sp/>cx.data_ptr()<sp/>:<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="848"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>x_descs_arr.data(),<sp/>dx.data_ptr(),</highlight></codeline>
<codeline lineno="849"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.hx_desc.desc(),<sp/>dhx.data_ptr(),</highlight></codeline>
<codeline lineno="850"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.cx_desc.desc(),<sp/>cx.defined()<sp/>?<sp/>dcx.data_ptr()<sp/>:<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="851"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>workspace.data_ptr(),<sp/>workspace.size(0),</highlight></codeline>
<codeline lineno="852"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fn_reserve.data_ptr(),<sp/>fn_reserve.size(0)</highlight></codeline>
<codeline lineno="853"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>));</highlight></codeline>
<codeline lineno="854"><highlight class="normal"></highlight></codeline>
<codeline lineno="855"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(batch_first<sp/>&amp;&amp;<sp/>!is_input_packed)<sp/>{</highlight></codeline>
<codeline lineno="856"><highlight class="normal"><sp/><sp/><sp/><sp/>dx<sp/>=<sp/>dx.transpose_(0,<sp/>1);</highlight></codeline>
<codeline lineno="857"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="858"><highlight class="normal"></highlight></codeline>
<codeline lineno="859"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>std::make_tuple(dx,<sp/>dhx,<sp/>dcx);</highlight></codeline>
<codeline lineno="860"><highlight class="normal">}</highlight></codeline>
<codeline lineno="861"><highlight class="normal"></highlight></codeline>
<codeline lineno="862"><highlight class="normal"></highlight><highlight class="comment">//<sp/>NB:<sp/>This<sp/>MUST<sp/>BE<sp/>CALLED<sp/>AFTER<sp/>_cudnn_rnn_backward_input.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="863"><highlight class="normal"></highlight><highlight class="comment">//<sp/>We&apos;ll<sp/>give<sp/>a<sp/>user<sp/>friendly<sp/>combined<sp/>function...</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="864"><highlight class="normal">std::vector&lt;Tensor&gt;<sp/>_cudnn_rnn_backward_weight(</highlight></codeline>
<codeline lineno="865"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>I<sp/>think<sp/>tensor<sp/>geometry<sp/>sufficient<sp/>for<sp/>weight_buf/weight</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="866"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>input_r,<sp/>TensorList<sp/>weight_arr,<sp/>int64_t<sp/>weight_stride0,</highlight></codeline>
<codeline lineno="867"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>weight_buf,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>hx,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>cx,</highlight></codeline>
<codeline lineno="868"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>output_r,</highlight></codeline>
<codeline lineno="869"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>fn_mode,<sp/>int64_t<sp/>fn_hidden_size,</highlight></codeline>
<codeline lineno="870"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>fn_num_layers,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>batch_first,<sp/></highlight><highlight class="keywordtype">double</highlight><highlight class="normal"><sp/>fn_dropout,</highlight></codeline>
<codeline lineno="871"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>fn_train,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>fn_bidirectional,<sp/>IntList<sp/>fn_batch_sizes,</highlight></codeline>
<codeline lineno="872"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>fn_dropout_state,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>fn_reserve</highlight></codeline>
<codeline lineno="873"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>{</highlight></codeline>
<codeline lineno="874"><highlight class="normal"></highlight></codeline>
<codeline lineno="875"><highlight class="normal"><sp/><sp/>MatrixRef&lt;Tensor&gt;<sp/>weight{<sp/>weight_arr,<sp/></highlight><highlight class="keyword">static_cast&lt;</highlight><highlight class="keywordtype">size_t</highlight><highlight class="keyword">&gt;</highlight><highlight class="normal">(weight_stride0)<sp/>};</highlight></codeline>
<codeline lineno="876"><highlight class="normal"></highlight></codeline>
<codeline lineno="877"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>input<sp/>=<sp/>input_r;</highlight></codeline>
<codeline lineno="878"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>output<sp/>=<sp/>output_r;</highlight></codeline>
<codeline lineno="879"><highlight class="normal"></highlight></codeline>
<codeline lineno="880"><highlight class="normal"><sp/><sp/>RNNParams<sp/>fn;</highlight></codeline>
<codeline lineno="881"><highlight class="normal"><sp/><sp/>fn.rnn.set(fn_mode,<sp/>fn_hidden_size,<sp/>fn_num_layers,<sp/>fn_bidirectional,<sp/>getCudnnDataType(input));</highlight></codeline>
<codeline lineno="882"><highlight class="normal"><sp/><sp/>fn.dropout.set(fn_train,<sp/>fn_dropout,<sp/>fn_dropout_state);</highlight></codeline>
<codeline lineno="883"><highlight class="normal"><sp/><sp/>fn.tensors.set(input.sizes(),<sp/>fn_batch_sizes,<sp/>batch_first);</highlight></codeline>
<codeline lineno="884"><highlight class="normal"></highlight></codeline>
<codeline lineno="885"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>handle<sp/>=<sp/>getCudnnHandle();</highlight></codeline>
<codeline lineno="886"><highlight class="normal"></highlight></codeline>
<codeline lineno="887"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(fn.rnn.mode<sp/>!=<sp/>CUDNN_LSTM)<sp/>{</highlight></codeline>
<codeline lineno="888"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cx.defined())<sp/>{</highlight></codeline>
<codeline lineno="889"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;rnn:<sp/>illegal<sp/>defined<sp/>cx<sp/>for<sp/>non-LSTM<sp/>RNN&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="890"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="891"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="892"><highlight class="normal"></highlight></codeline>
<codeline lineno="893"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>is_input_packed<sp/>=<sp/>fn_batch_sizes.size()<sp/>!=<sp/>0;</highlight></codeline>
<codeline lineno="894"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(batch_first<sp/>&amp;&amp;<sp/>!is_input_packed)<sp/>{</highlight></codeline>
<codeline lineno="895"><highlight class="normal"><sp/><sp/><sp/><sp/>input<sp/>=<sp/>input.transpose(0,<sp/>1);</highlight></codeline>
<codeline lineno="896"><highlight class="normal"><sp/><sp/><sp/><sp/>output<sp/>=<sp/>output.transpose(0,<sp/>1);</highlight></codeline>
<codeline lineno="897"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="898"><highlight class="normal"></highlight></codeline>
<codeline lineno="899"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>input_size<sp/>=<sp/>_input_size(fn.tensors);</highlight></codeline>
<codeline lineno="900"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>hidden_size<sp/>=<sp/>_hidden_size(fn.rnn,<sp/>fn.tensors);</highlight></codeline>
<codeline lineno="901"><highlight class="normal"></highlight></codeline>
<codeline lineno="902"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!fn_train)<sp/>{</highlight></codeline>
<codeline lineno="903"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;cudnn<sp/>RNN<sp/>backward<sp/>can<sp/>only<sp/>be<sp/>called<sp/>in<sp/>training<sp/>mode&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="904"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="905"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!input.sizes().equals(input_size))<sp/>{</highlight></codeline>
<codeline lineno="906"><highlight class="normal"><sp/><sp/><sp/><sp/>std::ostringstream<sp/>oss;</highlight></codeline>
<codeline lineno="907"><highlight class="normal"><sp/><sp/><sp/><sp/>oss<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;Expected<sp/>input<sp/>size<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>IntList{input_size}<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>input.sizes();</highlight></codeline>
<codeline lineno="908"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(oss.str());</highlight></codeline>
<codeline lineno="909"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="910"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(hx.defined()<sp/>&amp;&amp;<sp/>!hx.sizes().equals(hidden_size))<sp/>{</highlight></codeline>
<codeline lineno="911"><highlight class="normal"><sp/><sp/><sp/><sp/>std::ostringstream<sp/>oss;</highlight></codeline>
<codeline lineno="912"><highlight class="normal"><sp/><sp/><sp/><sp/>oss<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;Expected<sp/>hidden<sp/>size<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>IntList{hidden_size}<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>hx.sizes();</highlight></codeline>
<codeline lineno="913"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(oss.str());</highlight></codeline>
<codeline lineno="914"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="915"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>the<sp/>above<sp/>were<sp/>the<sp/>only<sp/>checks<sp/>in<sp/>rnn.py,<sp/>but<sp/>it<sp/>doesn&apos;t<sp/>seem</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="916"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>like<sp/>these<sp/>checks<sp/>are<sp/>enough</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="917"><highlight class="normal"></highlight></codeline>
<codeline lineno="918"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!hx.is_contiguous())<sp/>{</highlight></codeline>
<codeline lineno="919"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;rnn:<sp/>hx<sp/>is<sp/>not<sp/>contiguous&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="920"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="921"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cx.defined()<sp/>&amp;&amp;<sp/>!cx.is_contiguous())<sp/>{</highlight></codeline>
<codeline lineno="922"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">throw</highlight><highlight class="normal"><sp/>std::runtime_error(</highlight><highlight class="stringliteral">&quot;rnn:<sp/>cx<sp/>is<sp/>not<sp/>contiguous&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="923"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="924"><highlight class="normal"></highlight></codeline>
<codeline lineno="925"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>x<sp/>=<sp/>input.contiguous();</highlight></codeline>
<codeline lineno="926"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal">&amp;<sp/>y<sp/>=<sp/>output;</highlight></codeline>
<codeline lineno="927"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dw<sp/>=<sp/>weight_buf.type().tensor(weight_buf.sizes()).zero_();</highlight></codeline>
<codeline lineno="928"><highlight class="normal"></highlight></codeline>
<codeline lineno="929"><highlight class="normal"><sp/><sp/>RNNDescriptors<sp/>descs(fn,<sp/>handle,<sp/>x,<sp/>y,<sp/>hx,<sp/>cx);</highlight></codeline>
<codeline lineno="930"><highlight class="normal"></highlight></codeline>
<codeline lineno="931"><highlight class="normal"><sp/><sp/>FilterDescriptor<sp/>w_desc;</highlight></codeline>
<codeline lineno="932"><highlight class="normal"><sp/><sp/>w_desc.set(weight_buf,<sp/>3);</highlight></codeline>
<codeline lineno="933"><highlight class="normal"></highlight></codeline>
<codeline lineno="934"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>workspace_size;</highlight></codeline>
<codeline lineno="935"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>x_descs_arr<sp/>=<sp/>descs.get_x_descs();</highlight></codeline>
<codeline lineno="936"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>y_descs_arr<sp/>=<sp/>descs.get_y_descs();</highlight></codeline>
<codeline lineno="937"><highlight class="normal"><sp/><sp/>AT_CUDNN_CHECK(cudnnGetRNNWorkspaceSize(</highlight></codeline>
<codeline lineno="938"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>handle,</highlight></codeline>
<codeline lineno="939"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.rnn_desc.desc(),</highlight></codeline>
<codeline lineno="940"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fn.tensors.seq_length,</highlight></codeline>
<codeline lineno="941"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>x_descs_arr.data(),</highlight></codeline>
<codeline lineno="942"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&amp;workspace_size</highlight></codeline>
<codeline lineno="943"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>));</highlight></codeline>
<codeline lineno="944"><highlight class="normal"><sp/><sp/>Tensor<sp/>workspace<sp/>=<sp/>input.type().toScalarType(kByte).tensor(workspace_size);</highlight></codeline>
<codeline lineno="945"><highlight class="normal"></highlight></codeline>
<codeline lineno="946"><highlight class="normal"><sp/><sp/>AT_CUDNN_CHECK(cudnnRNNBackwardWeights(</highlight></codeline>
<codeline lineno="947"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>handle,</highlight></codeline>
<codeline lineno="948"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.rnn_desc.desc(),</highlight></codeline>
<codeline lineno="949"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fn.tensors.seq_length,</highlight></codeline>
<codeline lineno="950"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>x_descs_arr.data(),<sp/>x.data_ptr(),</highlight></codeline>
<codeline lineno="951"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>descs.hx_desc.desc(),<sp/>hx.data_ptr(),</highlight></codeline>
<codeline lineno="952"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>y_descs_arr.data(),<sp/>y.data_ptr(),</highlight></codeline>
<codeline lineno="953"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>workspace.data_ptr(),<sp/>workspace.size(0),</highlight></codeline>
<codeline lineno="954"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>w_desc.desc(),<sp/>dw.data_ptr(),</highlight></codeline>
<codeline lineno="955"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fn_reserve.data_ptr(),<sp/>fn_reserve.size(0)</highlight></codeline>
<codeline lineno="956"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>));</highlight></codeline>
<codeline lineno="957"><highlight class="normal"></highlight></codeline>
<codeline lineno="958"><highlight class="normal"><sp/><sp/>std::vector&lt;Tensor&gt;<sp/>grad_weight_arr;</highlight></codeline>
<codeline lineno="959"><highlight class="normal"><sp/><sp/>grad_weight_arr.reserve(<sp/>weight.numel()<sp/>);</highlight></codeline>
<codeline lineno="960"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal">&amp;<sp/>w<sp/>:<sp/>weight_arr)<sp/>{</highlight></codeline>
<codeline lineno="961"><highlight class="normal"><sp/><sp/><sp/><sp/>grad_weight_arr.emplace_back(w.type().tensor(w.sizes()).zero_());</highlight></codeline>
<codeline lineno="962"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="963"><highlight class="normal"></highlight></codeline>
<codeline lineno="964"><highlight class="normal"><sp/><sp/>std::vector&lt;Tensor&gt;<sp/>grad_params_arr;</highlight></codeline>
<codeline lineno="965"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>grad_params_stride0;</highlight></codeline>
<codeline lineno="966"><highlight class="normal"><sp/><sp/>std::tie(grad_params_arr,<sp/>grad_params_stride0)<sp/>=<sp/>get_parameters(handle,<sp/>fn.rnn,<sp/>descs.rnn_desc,<sp/>descs.x_descs[0],<sp/>w_desc,<sp/>dw);</highlight></codeline>
<codeline lineno="967"><highlight class="normal"><sp/><sp/>_copyParams(MatrixRef&lt;Tensor&gt;{grad_params_arr,<sp/>grad_params_stride0},</highlight></codeline>
<codeline lineno="968"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>MatrixRef&lt;Tensor&gt;{grad_weight_arr,<sp/></highlight><highlight class="keyword">static_cast&lt;</highlight><highlight class="keywordtype">size_t</highlight><highlight class="keyword">&gt;</highlight><highlight class="normal">(weight_stride0)});</highlight></codeline>
<codeline lineno="969"><highlight class="normal"></highlight></codeline>
<codeline lineno="970"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>grad_weight_arr;<sp/></highlight><highlight class="comment">//<sp/>stride<sp/>is<sp/>known<sp/>from<sp/>call<sp/>site<sp/>(and<sp/>also<sp/>inconvenient<sp/>to<sp/>return)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="971"><highlight class="normal">}</highlight></codeline>
<codeline lineno="972"><highlight class="normal"></highlight></codeline>
<codeline lineno="973"><highlight class="normal"></highlight><highlight class="comment">//<sp/>We<sp/>need<sp/>this<sp/>dispatcher<sp/>because<sp/>_cudnn_rnn_backward_weight<sp/>has<sp/>a<sp/>stringent</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="974"><highlight class="normal"></highlight><highlight class="comment">//<sp/>ordering<sp/>requirement<sp/>with<sp/>_cudnn_rnn_backward_input</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="975"><highlight class="normal">std::tuple&lt;Tensor,<sp/>Tensor,<sp/>Tensor,<sp/>std::vector&lt;Tensor&gt;&gt;<sp/>_cudnn_rnn_backward(</highlight></codeline>
<codeline lineno="976"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>input,<sp/>TensorList<sp/>weight,<sp/>int64_t<sp/>weight_stride0,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>weight_buf,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>hx,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>cx,</highlight></codeline>
<codeline lineno="977"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>output,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_output_r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_hy_r,</highlight></codeline>
<codeline lineno="978"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>grad_cy_r,</highlight></codeline>
<codeline lineno="979"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>mode,<sp/>int64_t<sp/>hidden_size,</highlight></codeline>
<codeline lineno="980"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>num_layers,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>batch_first,<sp/></highlight><highlight class="keywordtype">double</highlight><highlight class="normal"><sp/>dropout,</highlight></codeline>
<codeline lineno="981"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>train,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>bidirectional,<sp/>IntList<sp/>batch_sizes,</highlight></codeline>
<codeline lineno="982"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>dropout_state,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>reserve,</highlight></codeline>
<codeline lineno="983"><highlight class="normal"><sp/><sp/><sp/><sp/>std::array&lt;bool,<sp/>4&gt;<sp/>output_mask</highlight></codeline>
<codeline lineno="984"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>{</highlight></codeline>
<codeline lineno="985"><highlight class="normal"></highlight></codeline>
<codeline lineno="986"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>grad_output<sp/>=<sp/>grad_output_r.defined()<sp/>?<sp/>grad_output_r<sp/>:<sp/>output.type().zeros_like(output);</highlight></codeline>
<codeline lineno="987"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>grad_hy<sp/>=<sp/>grad_hy_r.defined()<sp/>?<sp/>grad_hy_r<sp/>:<sp/>hx.type().zeros_like(hx);</highlight></codeline>
<codeline lineno="988"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>grad_cy<sp/>=<sp/>cx.defined()<sp/>?<sp/>(grad_cy_r.defined()<sp/>?<sp/>grad_cy_r<sp/>:<sp/>cx.type().zeros_like(cx))<sp/>:<sp/>grad_cy_r;</highlight></codeline>
<codeline lineno="989"><highlight class="normal"></highlight></codeline>
<codeline lineno="990"><highlight class="normal"><sp/><sp/>Tensor<sp/>dx,<sp/>dhx,<sp/>dcx;</highlight></codeline>
<codeline lineno="991"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>NB:<sp/>unconditionally<sp/>compute<sp/>this<sp/>gradient,<sp/>because<sp/>it<sp/>mutates<sp/>reserve</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="992"><highlight class="normal"><sp/><sp/>std::tie(dx,<sp/>dhx,<sp/>dcx)<sp/>=<sp/>at::native::_cudnn_rnn_backward_input(input,<sp/>weight_buf,<sp/>hx,<sp/>cx,<sp/>output,<sp/>grad_output,<sp/>grad_hy,<sp/>grad_cy,<sp/>mode,<sp/>hidden_size,<sp/>num_layers,<sp/>batch_first,<sp/>dropout,<sp/>train,<sp/>bidirectional,<sp/>batch_sizes,<sp/>dropout_state,<sp/>reserve,<sp/>{output_mask[0],<sp/>output_mask[1],<sp/>output_mask[2]});</highlight></codeline>
<codeline lineno="993"><highlight class="normal"><sp/><sp/>std::vector&lt;Tensor&gt;<sp/>dw;</highlight></codeline>
<codeline lineno="994"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(output_mask[3])<sp/>{</highlight></codeline>
<codeline lineno="995"><highlight class="normal"><sp/><sp/><sp/><sp/>dw<sp/>=<sp/>at::native::_cudnn_rnn_backward_weight(input,<sp/>weight,<sp/>weight_stride0,<sp/>weight_buf,<sp/>hx,<sp/>cx,<sp/>output,<sp/>mode,<sp/>hidden_size,<sp/>num_layers,<sp/>batch_first,<sp/>dropout,<sp/>train,<sp/>bidirectional,<sp/>batch_sizes,<sp/>dropout_state,<sp/>reserve);</highlight></codeline>
<codeline lineno="996"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="997"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>std::tuple&lt;Tensor,<sp/>Tensor,<sp/>Tensor,<sp/>TensorList&gt;{dx,<sp/>dhx,<sp/>dcx,<sp/>dw};</highlight></codeline>
<codeline lineno="998"><highlight class="normal">}</highlight></codeline>
<codeline lineno="999"><highlight class="normal"></highlight></codeline>
<codeline lineno="1000"><highlight class="normal"></highlight><highlight class="comment">//<sp/>TODO:<sp/>I<sp/>am<sp/>not<sp/>sure<sp/>if<sp/>we<sp/>actually<sp/>need<sp/>the<sp/>&apos;dropout&apos;<sp/>and<sp/>&apos;train&apos;<sp/>parameters</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1001"><highlight class="normal"></highlight><highlight class="comment">//<sp/>to<sp/>initialize<sp/>just<sp/>the<sp/>state<sp/>tensor</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1002"><highlight class="normal">Tensor<sp/>_cudnn_init_dropout_state(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Type&amp;<sp/>ty,<sp/></highlight><highlight class="keywordtype">double</highlight><highlight class="normal"><sp/>dropout,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>train,<sp/>int64_t<sp/>dropout_seed)<sp/>{</highlight></codeline>
<codeline lineno="1003"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>handle<sp/>=<sp/>getCudnnHandle();</highlight></codeline>
<codeline lineno="1004"><highlight class="normal"><sp/><sp/>DropoutDescriptor<sp/>dropout_desc;</highlight></codeline>
<codeline lineno="1005"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>dropout_p<sp/>=<sp/>train<sp/>?<sp/>dropout<sp/>:<sp/>0;</highlight></codeline>
<codeline lineno="1006"><highlight class="normal"><sp/><sp/>dropout_desc.initialize_rng(ty,<sp/>handle,<sp/>dropout_p,<sp/>dropout_seed);</highlight></codeline>
<codeline lineno="1007"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>dropout_desc.state;</highlight></codeline>
<codeline lineno="1008"><highlight class="normal">}</highlight></codeline>
<codeline lineno="1009"><highlight class="normal"></highlight></codeline>
<codeline lineno="1010"><highlight class="normal">}}<sp/></highlight><highlight class="comment">//<sp/>namespace<sp/>at::native</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1011"><highlight class="normal"></highlight></codeline>
<codeline lineno="1012"><highlight class="normal"></highlight><highlight class="preprocessor">#endif<sp/>//<sp/>AT_CUDNN_ENABLED()</highlight></codeline>
    </programlisting>
    <location file="/Users/robkunkle/fork/goodlux/pytorch/aten/src/ATen/native/cudnn/RNN.cpp"/>
  </compounddef>
</doxygen>
