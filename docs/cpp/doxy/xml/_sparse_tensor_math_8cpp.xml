<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.14">
  <compounddef id="_sparse_tensor_math_8cpp" kind="file" language="C++">
    <compoundname>SparseTensorMath.cpp</compoundname>
    <includes refid="_a_ten_8h" local="no">ATen/ATen.h</includes>
    <includes refid="_sparse_tensor_impl_8h" local="no">ATen/SparseTensorImpl.h</includes>
    <includes refid="_expand_utils_8h" local="no">ATen/ExpandUtils.h</includes>
    <includes local="no">ATen/NativeFunctions.h</includes>
    <includes refid="_sparse_utils_8h" local="no">ATen/native/sparse/SparseUtils.h</includes>
    <includes local="no">TH/THBlasUtils.h</includes>
    <incdepgraph>
      <node id="7591">
        <label>ATen/optional.h</label>
        <link refid="optional_8h_source"/>
        <childnode refid="7592" relation="include">
        </childnode>
        <childnode refid="7593" relation="include">
        </childnode>
        <childnode refid="7594" relation="include">
        </childnode>
        <childnode refid="7595" relation="include">
        </childnode>
        <childnode refid="7596" relation="include">
        </childnode>
        <childnode refid="7597" relation="include">
        </childnode>
        <childnode refid="7598" relation="include">
        </childnode>
      </node>
      <node id="7637">
        <label>ATen/detail/CUDAHooksInterface.h</label>
        <link refid="_c_u_d_a_hooks_interface_8h_source"/>
        <childnode refid="7587" relation="include">
        </childnode>
        <childnode refid="7590" relation="include">
        </childnode>
        <childnode refid="7635" relation="include">
        </childnode>
        <childnode refid="7638" relation="include">
        </childnode>
        <childnode refid="7599" relation="include">
        </childnode>
        <childnode refid="7596" relation="include">
        </childnode>
        <childnode refid="7588" relation="include">
        </childnode>
      </node>
      <node id="7605">
        <label>ATen/Device.h</label>
        <link refid="_device_8h_source"/>
        <childnode refid="7590" relation="include">
        </childnode>
        <childnode refid="7606" relation="include">
        </childnode>
        <childnode refid="7599" relation="include">
        </childnode>
        <childnode refid="7621" relation="include">
        </childnode>
        <childnode refid="7597" relation="include">
        </childnode>
        <childnode refid="7596" relation="include">
        </childnode>
      </node>
      <node id="7604">
        <label>atomic</label>
      </node>
      <node id="7596">
        <label>functional</label>
      </node>
      <node id="7642">
        <label>ATen/Backtrace.h</label>
        <link refid="_backtrace_8h_source"/>
        <childnode refid="7599" relation="include">
        </childnode>
        <childnode refid="7597" relation="include">
        </childnode>
        <childnode refid="7632" relation="include">
        </childnode>
        <childnode refid="7585" relation="include">
        </childnode>
      </node>
      <node id="7606">
        <label>ATen/ScalarType.h</label>
        <link refid="_scalar_type_8h_source"/>
        <childnode refid="7607" relation="include">
        </childnode>
        <childnode refid="7585" relation="include">
        </childnode>
        <childnode refid="7617" relation="include">
        </childnode>
        <childnode refid="7619" relation="include">
        </childnode>
        <childnode refid="7623" relation="include">
        </childnode>
      </node>
      <node id="7618">
        <label>limits</label>
      </node>
      <node id="7665">
        <label>ATen/SparseTensorImpl.h</label>
        <link refid="_sparse_tensor_impl_8h_source"/>
        <childnode refid="7646" relation="include">
        </childnode>
        <childnode refid="7629" relation="include">
        </childnode>
        <childnode refid="7590" relation="include">
        </childnode>
      </node>
      <node id="7626">
        <label>assert.h</label>
      </node>
      <node id="7631">
        <label>ATen/Utils.h</label>
        <link refid="aten_2src_2_a_ten_2utils_8h_source"/>
        <childnode refid="7585" relation="include">
        </childnode>
        <childnode refid="7607" relation="include">
        </childnode>
        <childnode refid="7590" relation="include">
        </childnode>
        <childnode refid="7630" relation="include">
        </childnode>
        <childnode refid="7610" relation="include">
        </childnode>
        <childnode refid="7602" relation="include">
        </childnode>
        <childnode refid="7632" relation="include">
        </childnode>
        <childnode refid="7633" relation="include">
        </childnode>
      </node>
      <node id="7613">
        <label>iterator</label>
      </node>
      <node id="7625">
        <label>ATen/Scalar.h</label>
        <link refid="_scalar_8h_source"/>
        <childnode refid="7626" relation="include">
        </childnode>
        <childnode refid="7627" relation="include">
        </childnode>
        <childnode refid="7598" relation="include">
        </childnode>
        <childnode refid="7597" relation="include">
        </childnode>
        <childnode refid="7592" relation="include">
        </childnode>
        <childnode refid="7585" relation="include">
        </childnode>
        <childnode refid="7617" relation="include">
        </childnode>
        <childnode refid="7606" relation="include">
        </childnode>
        <childnode refid="7628" relation="include">
        </childnode>
        <childnode refid="7631" relation="include">
        </childnode>
      </node>
      <node id="7645">
        <label>TH/THStorageFunctions.hpp</label>
      </node>
      <node id="7619">
        <label>cstdint</label>
      </node>
      <node id="7653">
        <label>ATen/Deprecated.h</label>
        <link refid="_deprecated_8h_source"/>
      </node>
      <node id="7627">
        <label>stdint.h</label>
      </node>
      <node id="7664">
        <label>ATen/CUDAGuard.h</label>
        <link refid="_c_u_d_a_guard_8h_source"/>
      </node>
      <node id="7620">
        <label>cmath</label>
      </node>
      <node id="7595">
        <label>cassert</label>
      </node>
      <node id="7636">
        <label>ATen/Context.h</label>
        <link refid="_context_8h_source"/>
        <childnode refid="7585" relation="include">
        </childnode>
        <childnode refid="7586" relation="include">
        </childnode>
        <childnode refid="7635" relation="include">
        </childnode>
        <childnode refid="7634" relation="include">
        </childnode>
        <childnode refid="7631" relation="include">
        </childnode>
        <childnode refid="7590" relation="include">
        </childnode>
        <childnode refid="7637" relation="include">
        </childnode>
        <childnode refid="7643" relation="include">
        </childnode>
        <childnode refid="7588" relation="include">
        </childnode>
        <childnode refid="7640" relation="include">
        </childnode>
        <childnode refid="7619" relation="include">
        </childnode>
      </node>
      <node id="7622">
        <label>Half-inl.h</label>
        <link refid="_half-inl_8h_source"/>
        <childnode refid="7585" relation="include">
        </childnode>
        <childnode refid="7612" relation="include">
        </childnode>
        <childnode refid="7618" relation="include">
        </childnode>
      </node>
      <node id="7598">
        <label>stdexcept</label>
      </node>
      <node id="7659">
        <label>ATen/TensorOperators.h</label>
        <link refid="_tensor_operators_8h_source"/>
        <childnode refid="7625" relation="include">
        </childnode>
        <childnode refid="7646" relation="include">
        </childnode>
        <childnode refid="7634" relation="include">
        </childnode>
        <childnode refid="7597" relation="include">
        </childnode>
        <childnode refid="7598" relation="include">
        </childnode>
      </node>
      <node id="7633">
        <label>numeric</label>
      </node>
      <node id="7629">
        <label>ATen/TensorImpl.h</label>
        <link refid="_tensor_impl_8h_source"/>
        <childnode refid="7604" relation="include">
        </childnode>
        <childnode refid="7588" relation="include">
        </childnode>
        <childnode refid="7603" relation="include">
        </childnode>
        <childnode refid="7606" relation="include">
        </childnode>
        <childnode refid="7591" relation="include">
        </childnode>
      </node>
      <node id="7617">
        <label>ATen/Half.h</label>
        <link refid="_half_8h_source"/>
        <childnode refid="7585" relation="include">
        </childnode>
        <childnode refid="7618" relation="include">
        </childnode>
        <childnode refid="7597" relation="include">
        </childnode>
        <childnode refid="7619" relation="include">
        </childnode>
        <childnode refid="7598" relation="include">
        </childnode>
        <childnode refid="7592" relation="include">
        </childnode>
        <childnode refid="7620" relation="include">
        </childnode>
        <childnode refid="7621" relation="include">
        </childnode>
        <childnode refid="7622" relation="include">
        </childnode>
      </node>
      <node id="7603">
        <label>ATen/Retainable.h</label>
        <link refid="_retainable_8h_source"/>
        <childnode refid="7604" relation="include">
        </childnode>
      </node>
      <node id="7628">
        <label>ATen/TensorBase.h</label>
        <link refid="_tensor_base_8h_source"/>
        <childnode refid="7629" relation="include">
        </childnode>
        <childnode refid="7630" relation="include">
        </childnode>
      </node>
      <node id="7597">
        <label>string</label>
      </node>
      <node id="7662">
        <label>ATen/DimVector.h</label>
        <link refid="_dim_vector_8h_source"/>
        <childnode refid="7608" relation="include">
        </childnode>
        <childnode refid="7627" relation="include">
        </childnode>
      </node>
      <node id="7663">
        <label>ATen/OptionsGuard.h</label>
        <link refid="_options_guard_8h_source"/>
        <childnode refid="7605" relation="include">
        </childnode>
        <childnode refid="7649" relation="include">
        </childnode>
        <childnode refid="7606" relation="include">
        </childnode>
        <childnode refid="7656" relation="include">
        </childnode>
        <childnode refid="7591" relation="include">
        </childnode>
      </node>
      <node id="7666">
        <label>ATen/ExpandUtils.h</label>
        <link refid="_expand_utils_8h_source"/>
        <childnode refid="7646" relation="include">
        </childnode>
        <childnode refid="7590" relation="include">
        </childnode>
        <childnode refid="7596" relation="include">
        </childnode>
        <childnode refid="7602" relation="include">
        </childnode>
        <childnode refid="7667" relation="include">
        </childnode>
      </node>
      <node id="7587">
        <label>ATen/Allocator.h</label>
        <link refid="_allocator_8h_source"/>
        <childnode refid="7588" relation="include">
        </childnode>
        <childnode refid="7589" relation="include">
        </childnode>
        <childnode refid="7590" relation="include">
        </childnode>
        <childnode refid="7603" relation="include">
        </childnode>
        <childnode refid="7605" relation="include">
        </childnode>
        <childnode refid="7624" relation="include">
        </childnode>
      </node>
      <node id="7643">
        <label>ATen/CUDAStream.h</label>
        <link refid="_c_u_d_a_stream_8h_source"/>
      </node>
      <node id="7655">
        <label>ATen/DeviceGuard.h</label>
        <link refid="_device_guard_8h_source"/>
        <childnode refid="7605" relation="include">
        </childnode>
        <childnode refid="7590" relation="include">
        </childnode>
        <childnode refid="7606" relation="include">
        </childnode>
        <childnode refid="7646" relation="include">
        </childnode>
        <childnode refid="7637" relation="include">
        </childnode>
        <childnode refid="7599" relation="include">
        </childnode>
      </node>
      <node id="7600">
        <label>exception</label>
      </node>
      <node id="7589">
        <label>stddef.h</label>
      </node>
      <node id="7630">
        <label>ATen/UndefinedTensor.h</label>
        <link refid="_undefined_tensor_8h_source"/>
        <childnode refid="7629" relation="include">
        </childnode>
      </node>
      <node id="7661">
        <label>ATen/Dispatch.h</label>
        <link refid="_dispatch_8h_source"/>
        <childnode refid="7590" relation="include">
        </childnode>
        <childnode refid="7617" relation="include">
        </childnode>
        <childnode refid="7634" relation="include">
        </childnode>
      </node>
      <node id="7609">
        <label>AlignOf.h</label>
        <link refid="_align_of_8h_source"/>
        <childnode refid="7599" relation="include">
        </childnode>
      </node>
      <node id="7644">
        <label>ATen/Storage.h</label>
        <link refid="_storage_8h_source"/>
        <childnode refid="7625" relation="include">
        </childnode>
        <childnode refid="7645" relation="include">
        </childnode>
      </node>
      <node id="7601">
        <label>ostream</label>
      </node>
      <node id="7586">
        <label>ATen/CPUGeneral.h</label>
        <link refid="_c_p_u_general_8h_source"/>
        <childnode refid="7585" relation="include">
        </childnode>
      </node>
      <node id="7634">
        <label>ATen/Type.h</label>
      </node>
      <node id="7607">
        <label>ATen/ArrayRef.h</label>
        <link refid="_array_ref_8h_source"/>
        <childnode refid="7590" relation="include">
        </childnode>
        <childnode refid="7608" relation="include">
        </childnode>
        <childnode refid="7615" relation="include">
        </childnode>
        <childnode refid="7613" relation="include">
        </childnode>
        <childnode refid="7616" relation="include">
        </childnode>
      </node>
      <node id="7650">
        <label>ATen/TensorGeometry.h</label>
        <link refid="_tensor_geometry_8h_source"/>
        <childnode refid="7634" relation="include">
        </childnode>
        <childnode refid="7651" relation="include">
        </childnode>
      </node>
      <node id="7647">
        <label>ATen/SparseTensorRef.h</label>
        <link refid="_sparse_tensor_ref_8h_source"/>
      </node>
      <node id="7585">
        <label>ATen/ATenGeneral.h</label>
        <link refid="_a_ten_general_8h_source"/>
      </node>
      <node id="7651">
        <label>ATen/WrapDimUtils.h</label>
        <link refid="_wrap_dim_utils_8h_source"/>
        <childnode refid="7629" relation="include">
        </childnode>
        <childnode refid="7602" relation="include">
        </childnode>
      </node>
      <node id="7648">
        <label>ATen/TensorAccessor.h</label>
        <link refid="_tensor_accessor_8h_source"/>
        <childnode refid="7599" relation="include">
        </childnode>
        <childnode refid="7627" relation="include">
        </childnode>
        <childnode refid="7606" relation="include">
        </childnode>
      </node>
      <node id="7632">
        <label>typeinfo</label>
      </node>
      <node id="7639">
        <label>cstdio</label>
      </node>
      <node id="7667">
        <label>tuple</label>
      </node>
      <node id="7624">
        <label>ATen/detail/UniqueVoidPtr.h</label>
        <link refid="_unique_void_ptr_8h_source"/>
        <childnode refid="7588" relation="include">
        </childnode>
        <childnode refid="7585" relation="include">
        </childnode>
      </node>
      <node id="7616">
        <label>vector</label>
      </node>
      <node id="7660">
        <label>ATen/TensorMethods.h</label>
      </node>
      <node id="7657">
        <label>THNN/Reduction.h</label>
      </node>
      <node id="7614">
        <label>new</label>
      </node>
      <node id="7592">
        <label>utility</label>
      </node>
      <node id="7615">
        <label>array</label>
      </node>
      <node id="7602">
        <label>sstream</label>
      </node>
      <node id="7668">
        <label>ATen/native/sparse/SparseUtils.h</label>
        <link refid="_sparse_utils_8h_source"/>
        <childnode refid="7584" relation="include">
        </childnode>
        <childnode refid="7665" relation="include">
        </childnode>
        <childnode refid="7669" relation="include">
        </childnode>
      </node>
      <node id="7652">
        <label>ATen/Functions.h</label>
        <link refid="build_2aten_2src_2_a_ten_2_functions_8h_source"/>
        <childnode refid="7625" relation="include">
        </childnode>
        <childnode refid="7634" relation="include">
        </childnode>
        <childnode refid="7646" relation="include">
        </childnode>
        <childnode refid="7644" relation="include">
        </childnode>
        <childnode refid="7635" relation="include">
        </childnode>
        <childnode refid="7653" relation="include">
        </childnode>
        <childnode refid="7654" relation="include">
        </childnode>
        <childnode refid="7655" relation="include">
        </childnode>
        <childnode refid="7656" relation="include">
        </childnode>
        <childnode refid="7657" relation="include">
        </childnode>
      </node>
      <node id="7654">
        <label>ATen/NativeFunctions.h</label>
      </node>
      <node id="7621">
        <label>iosfwd</label>
      </node>
      <node id="7611">
        <label>cstdlib</label>
      </node>
      <node id="7669">
        <label>TH/THGeneral.h</label>
      </node>
      <node id="7623">
        <label>iostream</label>
      </node>
      <node id="7599">
        <label>cstddef</label>
      </node>
      <node id="7641">
        <label>unordered_map</label>
      </node>
      <node id="7640">
        <label>mutex</label>
      </node>
      <node id="7583">
        <label>/Users/robkunkle/fork/goodlux/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp</label>
        <link refid="_sparse_tensor_math_8cpp"/>
        <childnode refid="7584" relation="include">
        </childnode>
        <childnode refid="7665" relation="include">
        </childnode>
        <childnode refid="7666" relation="include">
        </childnode>
        <childnode refid="7654" relation="include">
        </childnode>
        <childnode refid="7668" relation="include">
        </childnode>
        <childnode refid="7670" relation="include">
        </childnode>
      </node>
      <node id="7584">
        <label>ATen/ATen.h</label>
        <link refid="_a_ten_8h_source"/>
        <childnode refid="7585" relation="include">
        </childnode>
        <childnode refid="7586" relation="include">
        </childnode>
        <childnode refid="7587" relation="include">
        </childnode>
        <childnode refid="7625" relation="include">
        </childnode>
        <childnode refid="7634" relation="include">
        </childnode>
        <childnode refid="7635" relation="include">
        </childnode>
        <childnode refid="7636" relation="include">
        </childnode>
        <childnode refid="7644" relation="include">
        </childnode>
        <childnode refid="7646" relation="include">
        </childnode>
        <childnode refid="7605" relation="include">
        </childnode>
        <childnode refid="7650" relation="include">
        </childnode>
        <childnode refid="7652" relation="include">
        </childnode>
        <childnode refid="7658" relation="include">
        </childnode>
        <childnode refid="7659" relation="include">
        </childnode>
        <childnode refid="7660" relation="include">
        </childnode>
        <childnode refid="7661" relation="include">
        </childnode>
        <childnode refid="7662" relation="include">
        </childnode>
        <childnode refid="7655" relation="include">
        </childnode>
        <childnode refid="7656" relation="include">
        </childnode>
        <childnode refid="7649" relation="include">
        </childnode>
        <childnode refid="7663" relation="include">
        </childnode>
        <childnode refid="7664" relation="include">
        </childnode>
      </node>
      <node id="7638">
        <label>ATen/Registry.h</label>
        <link refid="_registry_8h_source"/>
        <childnode refid="7610" relation="include">
        </childnode>
        <childnode refid="7639" relation="include">
        </childnode>
        <childnode refid="7611" relation="include">
        </childnode>
        <childnode refid="7596" relation="include">
        </childnode>
        <childnode refid="7588" relation="include">
        </childnode>
        <childnode refid="7640" relation="include">
        </childnode>
        <childnode refid="7641" relation="include">
        </childnode>
        <childnode refid="7597" relation="include">
        </childnode>
        <childnode refid="7616" relation="include">
        </childnode>
        <childnode refid="7642" relation="include">
        </childnode>
        <childnode refid="7585" relation="include">
        </childnode>
      </node>
      <node id="7590">
        <label>ATen/Error.h</label>
        <link refid="_error_8h_source"/>
        <childnode refid="7585" relation="include">
        </childnode>
        <childnode refid="7591" relation="include">
        </childnode>
        <childnode refid="7599" relation="include">
        </childnode>
        <childnode refid="7600" relation="include">
        </childnode>
        <childnode refid="7601" relation="include">
        </childnode>
        <childnode refid="7602" relation="include">
        </childnode>
        <childnode refid="7597" relation="include">
        </childnode>
      </node>
      <node id="7656">
        <label>ATen/TensorOptions.h</label>
        <link refid="_tensor_options_8h_source"/>
        <childnode refid="7636" relation="include">
        </childnode>
        <childnode refid="7605" relation="include">
        </childnode>
        <childnode refid="7655" relation="include">
        </childnode>
        <childnode refid="7649" relation="include">
        </childnode>
        <childnode refid="7606" relation="include">
        </childnode>
        <childnode refid="7646" relation="include">
        </childnode>
        <childnode refid="7634" relation="include">
        </childnode>
        <childnode refid="7599" relation="include">
        </childnode>
        <childnode refid="7621" relation="include">
        </childnode>
        <childnode refid="7592" relation="include">
        </childnode>
      </node>
      <node id="7646">
        <label>ATen/Tensor.h</label>
        <link refid="build_2aten_2src_2_a_ten_2tensor_8h_source"/>
        <childnode refid="7635" relation="include">
        </childnode>
        <childnode refid="7625" relation="include">
        </childnode>
        <childnode refid="7606" relation="include">
        </childnode>
        <childnode refid="7647" relation="include">
        </childnode>
        <childnode refid="7644" relation="include">
        </childnode>
        <childnode refid="7648" relation="include">
        </childnode>
        <childnode refid="7628" relation="include">
        </childnode>
        <childnode refid="7629" relation="include">
        </childnode>
        <childnode refid="7631" relation="include">
        </childnode>
        <childnode refid="7605" relation="include">
        </childnode>
        <childnode refid="7649" relation="include">
        </childnode>
        <childnode refid="7591" relation="include">
        </childnode>
      </node>
      <node id="7593">
        <label>type_traits</label>
      </node>
      <node id="7649">
        <label>ATen/Layout.h</label>
        <link refid="_layout_8h_source"/>
        <childnode refid="7606" relation="include">
        </childnode>
        <childnode refid="7590" relation="include">
        </childnode>
        <childnode refid="7623" relation="include">
        </childnode>
      </node>
      <node id="7608">
        <label>ATen/SmallVector.h</label>
        <link refid="_small_vector_8h_source"/>
        <childnode refid="7609" relation="include">
        </childnode>
        <childnode refid="7610" relation="include">
        </childnode>
        <childnode refid="7595" relation="include">
        </childnode>
        <childnode refid="7599" relation="include">
        </childnode>
        <childnode refid="7611" relation="include">
        </childnode>
        <childnode refid="7612" relation="include">
        </childnode>
        <childnode refid="7594" relation="include">
        </childnode>
        <childnode refid="7613" relation="include">
        </childnode>
        <childnode refid="7588" relation="include">
        </childnode>
        <childnode refid="7614" relation="include">
        </childnode>
        <childnode refid="7593" relation="include">
        </childnode>
        <childnode refid="7592" relation="include">
        </childnode>
        <childnode refid="7585" relation="include">
        </childnode>
      </node>
      <node id="7610">
        <label>algorithm</label>
      </node>
      <node id="7635">
        <label>ATen/Generator.h</label>
        <link refid="_generator_8h_source"/>
        <childnode refid="7627" relation="include">
        </childnode>
      </node>
      <node id="7612">
        <label>cstring</label>
      </node>
      <node id="7670">
        <label>TH/THBlasUtils.h</label>
      </node>
      <node id="7588">
        <label>memory</label>
      </node>
      <node id="7594">
        <label>initializer_list</label>
      </node>
      <node id="7658">
        <label>ATen/Formatting.h</label>
        <link refid="_formatting_8h_source"/>
        <childnode refid="7623" relation="include">
        </childnode>
        <childnode refid="7634" relation="include">
        </childnode>
        <childnode refid="7625" relation="include">
        </childnode>
      </node>
    </incdepgraph>
    <innernamespace refid="namespaceat">at</innernamespace>
    <innernamespace refid="namespaceat_1_1native">at::native</innernamespace>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <programlisting>
<codeline lineno="1"><highlight class="preprocessor">#include<sp/>&lt;ATen/ATen.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="2"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/SparseTensorImpl.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="3"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/ExpandUtils.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="4"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/NativeFunctions.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="5"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;ATen/native/sparse/SparseUtils.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="6"><highlight class="normal"></highlight></codeline>
<codeline lineno="7"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;TH/THBlasUtils.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="8"><highlight class="normal"></highlight></codeline>
<codeline lineno="9"><highlight class="normal"></highlight><highlight class="keyword">namespace<sp/></highlight><highlight class="normal"><ref refid="namespaceat" kindref="compound">at</ref><sp/>{<sp/></highlight><highlight class="keyword">namespace<sp/></highlight><highlight class="normal">native<sp/>{</highlight></codeline>
<codeline lineno="10"><highlight class="normal"></highlight></codeline>
<codeline lineno="11"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="12"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Utility<sp/>functions</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="13"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="14"><highlight class="normal"></highlight></codeline>
<codeline lineno="15"><highlight class="normal"></highlight><highlight class="keyword">namespace<sp/></highlight><highlight class="normal">{</highlight></codeline>
<codeline lineno="16"><highlight class="normal"><sp/><sp/>LongTensor<sp/>_to_csr(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>int64_t*<sp/>indices,<sp/>int64_t<sp/>dim,<sp/>int64_t<sp/>nnz)<sp/>{</highlight></codeline>
<codeline lineno="17"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>h,<sp/>i,<sp/>hp0,<sp/>hp1;</highlight></codeline>
<codeline lineno="18"><highlight class="normal"><sp/><sp/><sp/><sp/>LongTensor<sp/>csr<sp/>=<sp/>native::zeros({dim<sp/>+<sp/>1},<sp/>kLong);</highlight></codeline>
<codeline lineno="19"><highlight class="normal"></highlight></codeline>
<codeline lineno="20"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>eliminate<sp/>this<sp/>conditional<sp/>when<sp/>zero-size<sp/>dims<sp/>supported<sp/>correctly</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="21"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(nnz<sp/>&gt;<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="22"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>csr_accessor<sp/>=<sp/>csr.accessor&lt;int64_t,<sp/>1&gt;();</highlight></codeline>
<codeline lineno="23"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Convert<sp/>the<sp/>sparse<sp/>matrix<sp/>to<sp/>CSR<sp/>format</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="24"><highlight class="normal"></highlight><highlight class="preprocessor">#pragma<sp/>omp<sp/>parallel<sp/>for<sp/>private(i,<sp/>h,<sp/>hp0,<sp/>hp1)<sp/>schedule(static)<sp/>if<sp/>(nnz<sp/>&gt;<sp/>10000)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="25"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(i=0;<sp/>i&lt;nnz;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="26"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>hp0<sp/>=<sp/>indices[i];</highlight></codeline>
<codeline lineno="27"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>hp1<sp/>=<sp/>(i+1<sp/>==<sp/>nnz)<sp/>?<sp/><sp/>dim<sp/>:<sp/>indices[i+1];</highlight></codeline>
<codeline lineno="28"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(hp0<sp/>!=<sp/>hp1)<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(h<sp/>=<sp/>hp0;<sp/>h<sp/>&lt;<sp/>hp1;<sp/>h++)<sp/>{</highlight></codeline>
<codeline lineno="29"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>csr_accessor[h+1]<sp/>=<sp/>i+1;</highlight></codeline>
<codeline lineno="30"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="31"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="32"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="33"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>csr;</highlight></codeline>
<codeline lineno="34"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="35"><highlight class="normal"></highlight></codeline>
<codeline lineno="36"><highlight class="normal">}</highlight></codeline>
<codeline lineno="37"><highlight class="normal"></highlight></codeline>
<codeline lineno="38"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="39"><highlight class="normal"></highlight><highlight class="comment">//<sp/>zero_(SparseTensor)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="40"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="41"><highlight class="normal"></highlight></codeline>
<codeline lineno="42"><highlight class="normal"></highlight><highlight class="comment">//<sp/>hummu<sp/>hummu</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="43"><highlight class="normal">SparseTensor&amp;<sp/>zero_sparse_(SparseTensor&amp;<sp/></highlight><highlight class="keyword">self</highlight><highlight class="normal">)<sp/>{</highlight></codeline>
<codeline lineno="44"><highlight class="normal"><sp/><sp/>AT_ASSERT(</highlight><highlight class="keyword">self</highlight><highlight class="normal">.is_sparse());</highlight></codeline>
<codeline lineno="45"><highlight class="normal"></highlight></codeline>
<codeline lineno="46"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>NB:<sp/>You<sp/>must<sp/>use<sp/>_get_sparse_impl(self)-&gt;indices()</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="47"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>and<sp/>not<sp/>self._indices(),<sp/>because<sp/>the<sp/>latter<sp/>will<sp/>possibly</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="48"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>return<sp/>a<sp/>view<sp/>(which<sp/>means<sp/>that<sp/>the<sp/>in-place<sp/>operation<sp/>will</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="49"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>not<sp/>work).</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="50"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(_get_sparse_impl(</highlight><highlight class="keyword">self</highlight><highlight class="normal">)-&gt;indices().numel())<sp/>{</highlight></codeline>
<codeline lineno="51"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>To<sp/>be<sp/>fixed<sp/>when<sp/>we<sp/>support<sp/>zero-size<sp/>dims</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="52"><highlight class="normal"><sp/><sp/><sp/><sp/>_get_sparse_impl(</highlight><highlight class="keyword">self</highlight><highlight class="normal">)-&gt;indices().resize_({0});</highlight></codeline>
<codeline lineno="53"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="54"><highlight class="normal"></highlight></codeline>
<codeline lineno="55"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(_get_sparse_impl(</highlight><highlight class="keyword">self</highlight><highlight class="normal">)-&gt;values().numel())<sp/>{</highlight></codeline>
<codeline lineno="56"><highlight class="normal"><sp/><sp/><sp/><sp/>_get_sparse_impl(</highlight><highlight class="keyword">self</highlight><highlight class="normal">)-&gt;values().resize_({0});</highlight></codeline>
<codeline lineno="57"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="58"><highlight class="normal"><sp/><sp/>_get_sparse_impl(</highlight><highlight class="keyword">self</highlight><highlight class="normal">)-&gt;set_nnz(0);</highlight></codeline>
<codeline lineno="59"><highlight class="normal"><sp/><sp/>_get_sparse_impl(</highlight><highlight class="keyword">self</highlight><highlight class="normal">)-&gt;set_coalesced(</highlight><highlight class="keyword">true</highlight><highlight class="normal">);<sp/></highlight><highlight class="comment">//<sp/>NB:<sp/>This<sp/>is<sp/>new</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="60"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">self</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="61"><highlight class="normal">}</highlight></codeline>
<codeline lineno="62"><highlight class="normal"></highlight></codeline>
<codeline lineno="63"><highlight class="normal"></highlight><highlight class="comment">//<sp/>NB:<sp/>Don&apos;t<sp/>need<sp/>zeros,<sp/>zeros_like,<sp/>already<sp/>implemented<sp/>in<sp/>TensorFactories</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="64"><highlight class="normal"></highlight></codeline>
<codeline lineno="65"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="66"><highlight class="normal"></highlight><highlight class="comment">//<sp/>mul(SparseTensor,<sp/>Scalar)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="67"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="68"><highlight class="normal"></highlight></codeline>
<codeline lineno="69"><highlight class="normal">SparseTensor&amp;<sp/>mul_out_sparse_scalar(SparseTensor&amp;<sp/>r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>t,<sp/>Scalar<sp/>value)<sp/>{</highlight></codeline>
<codeline lineno="70"><highlight class="normal"><sp/><sp/>AT_ASSERT(r.is_sparse());</highlight></codeline>
<codeline lineno="71"><highlight class="normal"><sp/><sp/>AT_ASSERT(t.is_sparse());</highlight></codeline>
<codeline lineno="72"><highlight class="normal"></highlight></codeline>
<codeline lineno="73"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(isSameTensor(r,<sp/>t))<sp/>{</highlight></codeline>
<codeline lineno="74"><highlight class="normal"><sp/><sp/><sp/><sp/>r._values().mul_(value);</highlight></codeline>
<codeline lineno="75"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="76"><highlight class="normal"><sp/><sp/><sp/><sp/>r.resize_as_(t);</highlight></codeline>
<codeline lineno="77"><highlight class="normal"><sp/><sp/><sp/><sp/>r._indices().resize_as_(t._indices());</highlight></codeline>
<codeline lineno="78"><highlight class="normal"><sp/><sp/><sp/><sp/>r._indices().copy_(t._indices());</highlight></codeline>
<codeline lineno="79"><highlight class="normal"><sp/><sp/><sp/><sp/>Tensor<sp/>r_values<sp/>=<sp/>r._values();<sp/></highlight><highlight class="comment">//<sp/>Sigh...<sp/>needed<sp/>because<sp/>mul_out<sp/>takes<sp/>Tensor&amp;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="80"><highlight class="normal"><sp/><sp/><sp/><sp/>at::mul_out(r_values,<sp/>t._values(),<sp/>value);</highlight></codeline>
<codeline lineno="81"><highlight class="normal"><sp/><sp/><sp/><sp/>_get_sparse_impl(r)-&gt;set_nnz(t._nnz());</highlight></codeline>
<codeline lineno="82"><highlight class="normal"><sp/><sp/><sp/><sp/>_get_sparse_impl(r)-&gt;set_coalesced(t.is_coalesced());</highlight></codeline>
<codeline lineno="83"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="84"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="85"><highlight class="normal">}</highlight></codeline>
<codeline lineno="86"><highlight class="normal"></highlight></codeline>
<codeline lineno="87"><highlight class="normal">SparseTensor<sp/>mul_sparse_scalar(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>t,<sp/>Scalar<sp/>value)<sp/>{</highlight></codeline>
<codeline lineno="88"><highlight class="normal"><sp/><sp/>SparseTensor<sp/>r<sp/>=<sp/>t.type().tensor();</highlight></codeline>
<codeline lineno="89"><highlight class="normal"><sp/><sp/>mul_out_sparse_scalar(r,<sp/>t,<sp/>value);</highlight></codeline>
<codeline lineno="90"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="91"><highlight class="normal">}</highlight></codeline>
<codeline lineno="92"><highlight class="normal"></highlight></codeline>
<codeline lineno="93"><highlight class="normal">SparseTensor&amp;<sp/>mul_sparse_scalar_(SparseTensor&amp;<sp/>t,<sp/>Scalar<sp/>v)<sp/>{</highlight></codeline>
<codeline lineno="94"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>mul_out_sparse_scalar(t,<sp/>t,<sp/>v);</highlight></codeline>
<codeline lineno="95"><highlight class="normal">}</highlight></codeline>
<codeline lineno="96"><highlight class="normal"></highlight></codeline>
<codeline lineno="97"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="98"><highlight class="normal"></highlight><highlight class="comment">//<sp/>log1p(SparseTensor)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="99"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="100"><highlight class="normal"></highlight></codeline>
<codeline lineno="101"><highlight class="normal"></highlight><highlight class="comment">//<sp/>TODO:<sp/>add<sp/>in-place<sp/>variant</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="102"><highlight class="normal"></highlight></codeline>
<codeline lineno="103"><highlight class="normal">SparseTensor&amp;<sp/>log1p_out_sparse(SparseTensor&amp;<sp/>r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>t)<sp/>{</highlight></codeline>
<codeline lineno="104"><highlight class="normal"><sp/><sp/>AT_ASSERT(r.is_sparse());</highlight></codeline>
<codeline lineno="105"><highlight class="normal"><sp/><sp/>AT_ASSERT(t.is_sparse());</highlight></codeline>
<codeline lineno="106"><highlight class="normal"></highlight></codeline>
<codeline lineno="107"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(isSameTensor(r,<sp/>t))<sp/>{</highlight></codeline>
<codeline lineno="108"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>don&apos;t<sp/>have<sp/>in-place<sp/>log1p<sp/>for<sp/>uncoalesced<sp/>input<sp/>because<sp/>coalesce()<sp/>is<sp/>not<sp/>in-place</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="109"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_CHECK(</highlight></codeline>
<codeline lineno="110"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>r.is_coalesced(),<sp/></highlight><highlight class="stringliteral">&quot;log1p:<sp/>in-place<sp/>on<sp/>uncoalesced<sp/>tensors<sp/>is<sp/>not<sp/>supported<sp/>yet!&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="111"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="112"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="113"><highlight class="normal"><sp/><sp/><sp/><sp/>r<sp/>=<sp/>raw_copy_sparse_(r,<sp/>t.coalesce());</highlight></codeline>
<codeline lineno="114"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="115"><highlight class="normal"><sp/><sp/>r._values().log1p_();</highlight></codeline>
<codeline lineno="116"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="117"><highlight class="normal">}</highlight></codeline>
<codeline lineno="118"><highlight class="normal"></highlight></codeline>
<codeline lineno="119"><highlight class="normal">SparseTensor&amp;<sp/>log1p_sparse_(SparseTensor&amp;<sp/>t)<sp/>{</highlight></codeline>
<codeline lineno="120"><highlight class="normal"><sp/><sp/>AT_CHECK(t.is_coalesced(),<sp/></highlight><highlight class="stringliteral">&quot;log1p:<sp/>in-place<sp/>on<sp/>uncoalesced<sp/>tensors<sp/>is<sp/>not<sp/>supported<sp/>yet!&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="121"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>log1p_out_sparse(t,<sp/>t);</highlight></codeline>
<codeline lineno="122"><highlight class="normal">}</highlight></codeline>
<codeline lineno="123"><highlight class="normal"></highlight></codeline>
<codeline lineno="124"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="125"><highlight class="normal"></highlight><highlight class="comment">//<sp/>pow(SparseTensor,<sp/>Scalar)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="126"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="127"><highlight class="normal"></highlight></codeline>
<codeline lineno="128"><highlight class="normal"></highlight><highlight class="comment">//<sp/>TODO:<sp/>add<sp/>in-place<sp/>variant</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="129"><highlight class="normal"></highlight></codeline>
<codeline lineno="130"><highlight class="normal">SparseTensor&amp;<sp/>pow_out_sparse_scalar(SparseTensor&amp;<sp/>r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>t_,<sp/>Scalar<sp/>value)<sp/>{</highlight></codeline>
<codeline lineno="131"><highlight class="normal"><sp/><sp/>AT_ASSERT(r.is_sparse());</highlight></codeline>
<codeline lineno="132"><highlight class="normal"><sp/><sp/>AT_ASSERT(t_.is_sparse());</highlight></codeline>
<codeline lineno="133"><highlight class="normal"><sp/><sp/>AT_CHECK(value.toDouble()<sp/>!=<sp/>0,<sp/></highlight><highlight class="stringliteral">&quot;pow:<sp/>cannot<sp/>raise<sp/>to<sp/>zeroth<sp/>power<sp/>on<sp/>sparse<sp/>tensor;<sp/>it<sp/>would<sp/>make<sp/>the<sp/>result<sp/>tensor<sp/>dense&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="134"><highlight class="normal"></highlight></codeline>
<codeline lineno="135"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>This<sp/>coalesce<sp/>is<sp/>why<sp/>we<sp/>can&apos;t<sp/>easily<sp/>provide<sp/>an<sp/>inplace<sp/>variant</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="136"><highlight class="normal"><sp/><sp/>SparseTensor<sp/>t<sp/>=<sp/>t_.coalesce();</highlight></codeline>
<codeline lineno="137"><highlight class="normal"></highlight></codeline>
<codeline lineno="138"><highlight class="normal"><sp/><sp/>r.resize_as_(t);</highlight></codeline>
<codeline lineno="139"><highlight class="normal"><sp/><sp/>r._indices().resize_as_(t._indices());</highlight></codeline>
<codeline lineno="140"><highlight class="normal"><sp/><sp/>r._indices().copy_(t._indices());</highlight></codeline>
<codeline lineno="141"><highlight class="normal"><sp/><sp/>Tensor<sp/>r_values<sp/>=<sp/>r._values();<sp/></highlight><highlight class="comment">//<sp/>Sigh...<sp/>needed<sp/>because<sp/>pow_out<sp/>takes<sp/>Tensor&amp;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="142"><highlight class="normal"><sp/><sp/>at::pow_out(r_values,<sp/>t._values(),<sp/>value);</highlight></codeline>
<codeline lineno="143"><highlight class="normal"><sp/><sp/>_get_sparse_impl(r)-&gt;set_nnz(t._nnz());</highlight></codeline>
<codeline lineno="144"><highlight class="normal"><sp/><sp/>_get_sparse_impl(r)-&gt;set_coalesced(t.is_coalesced());</highlight></codeline>
<codeline lineno="145"><highlight class="normal"></highlight></codeline>
<codeline lineno="146"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="147"><highlight class="normal">}</highlight></codeline>
<codeline lineno="148"><highlight class="normal"></highlight></codeline>
<codeline lineno="149"><highlight class="normal">SparseTensor<sp/>pow_sparse_scalar(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>t,<sp/>Scalar<sp/>value)<sp/>{</highlight></codeline>
<codeline lineno="150"><highlight class="normal"><sp/><sp/>SparseTensor<sp/>r<sp/>=<sp/>t.type().tensor();</highlight></codeline>
<codeline lineno="151"><highlight class="normal"><sp/><sp/>pow_out_sparse_scalar(r,<sp/>t,<sp/>value);</highlight></codeline>
<codeline lineno="152"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="153"><highlight class="normal">}</highlight></codeline>
<codeline lineno="154"><highlight class="normal"></highlight></codeline>
<codeline lineno="155"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="156"><highlight class="normal"></highlight><highlight class="comment">//<sp/>div(SparseTensor,<sp/>Scalar)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="157"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="158"><highlight class="normal"></highlight></codeline>
<codeline lineno="159"><highlight class="normal">SparseTensor&amp;<sp/>div_out_sparse_scalar(SparseTensor&amp;<sp/>r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>t,<sp/>Scalar<sp/>value)<sp/>{</highlight></codeline>
<codeline lineno="160"><highlight class="normal"><sp/><sp/>AT_ASSERT(r.is_sparse());</highlight></codeline>
<codeline lineno="161"><highlight class="normal"><sp/><sp/>AT_ASSERT(t.is_sparse());</highlight></codeline>
<codeline lineno="162"><highlight class="normal"></highlight></codeline>
<codeline lineno="163"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(isSameTensor(r,<sp/>t))<sp/>{</highlight></codeline>
<codeline lineno="164"><highlight class="normal"><sp/><sp/><sp/><sp/>r._values().div_(value);</highlight></codeline>
<codeline lineno="165"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="166"><highlight class="normal"><sp/><sp/><sp/><sp/>r.resize_as_(t);</highlight></codeline>
<codeline lineno="167"><highlight class="normal"><sp/><sp/><sp/><sp/>r._indices().resize_as_(t._indices());</highlight></codeline>
<codeline lineno="168"><highlight class="normal"><sp/><sp/><sp/><sp/>r._indices().copy_(t._indices());</highlight></codeline>
<codeline lineno="169"><highlight class="normal"><sp/><sp/><sp/><sp/>Tensor<sp/>r_values<sp/>=<sp/>r._values();<sp/></highlight><highlight class="comment">//<sp/>Sigh...<sp/>needed<sp/>because<sp/>div_out<sp/>takes<sp/>Tensor&amp;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="170"><highlight class="normal"><sp/><sp/><sp/><sp/>at::div_out(r_values,<sp/>t._values(),<sp/>value);</highlight></codeline>
<codeline lineno="171"><highlight class="normal"><sp/><sp/><sp/><sp/>_get_sparse_impl(r)-&gt;set_nnz(t._nnz());</highlight></codeline>
<codeline lineno="172"><highlight class="normal"><sp/><sp/><sp/><sp/>_get_sparse_impl(r)-&gt;set_coalesced(t.is_coalesced());</highlight></codeline>
<codeline lineno="173"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="174"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="175"><highlight class="normal">}</highlight></codeline>
<codeline lineno="176"><highlight class="normal"></highlight></codeline>
<codeline lineno="177"><highlight class="normal">SparseTensor<sp/>div_sparse_scalar(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>t,<sp/>Scalar<sp/>value)<sp/>{</highlight></codeline>
<codeline lineno="178"><highlight class="normal"><sp/><sp/>SparseTensor<sp/>r<sp/>=<sp/>t.type().tensor();</highlight></codeline>
<codeline lineno="179"><highlight class="normal"><sp/><sp/>div_out_sparse_scalar(r,<sp/>t,<sp/>value);</highlight></codeline>
<codeline lineno="180"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="181"><highlight class="normal">}</highlight></codeline>
<codeline lineno="182"><highlight class="normal"></highlight></codeline>
<codeline lineno="183"><highlight class="normal">SparseTensor&amp;<sp/>div_sparse_scalar_(SparseTensor&amp;<sp/>t,<sp/>Scalar<sp/>value)<sp/>{</highlight></codeline>
<codeline lineno="184"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>div_out_sparse_scalar(t,<sp/>t,<sp/>value);</highlight></codeline>
<codeline lineno="185"><highlight class="normal">}</highlight></codeline>
<codeline lineno="186"><highlight class="normal"></highlight></codeline>
<codeline lineno="187"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="188"><highlight class="normal"></highlight><highlight class="comment">//<sp/>norm(SparseTensor,<sp/>Scalar)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="189"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="190"><highlight class="normal"></highlight></codeline>
<codeline lineno="191"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Only<sp/>supports<sp/>floating<sp/>point,<sp/>FYI</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="192"><highlight class="normal">Tensor<sp/>norm_sparse(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/></highlight><highlight class="keyword">self</highlight><highlight class="normal">,<sp/>Scalar<sp/>value)<sp/>{</highlight></codeline>
<codeline lineno="193"><highlight class="normal"><sp/><sp/>AT_ASSERT(</highlight><highlight class="keyword">self</highlight><highlight class="normal">.is_sparse());</highlight></codeline>
<codeline lineno="194"><highlight class="normal"></highlight></codeline>
<codeline lineno="195"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">self</highlight><highlight class="normal">.coalesce()._values().norm(value);</highlight></codeline>
<codeline lineno="196"><highlight class="normal">}</highlight></codeline>
<codeline lineno="197"><highlight class="normal"></highlight></codeline>
<codeline lineno="198"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="199"><highlight class="normal"></highlight><highlight class="comment">//<sp/>add(SparseTensor,<sp/>SparseTensor,<sp/>Scalar)<sp/><sp/>[broadcasts]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="200"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="201"><highlight class="normal"></highlight></codeline>
<codeline lineno="202"><highlight class="normal">SparseTensor&amp;<sp/>s_add_out_sparse_cpu(SparseTensor&amp;<sp/>r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>src,<sp/>Scalar<sp/>value)<sp/>{</highlight></codeline>
<codeline lineno="203"><highlight class="normal"><sp/><sp/>AT_ASSERT(r.is_sparse());</highlight></codeline>
<codeline lineno="204"><highlight class="normal"><sp/><sp/>AT_ASSERT(t.is_sparse());</highlight></codeline>
<codeline lineno="205"><highlight class="normal"><sp/><sp/>AT_ASSERT(!t.is_cuda());<sp/><sp/></highlight><highlight class="comment">//<sp/>the<sp/>dispatch<sp/>argument</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="206"><highlight class="normal"><sp/><sp/>AT_CHECK(!r.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;add:<sp/>expected<sp/>&apos;out&apos;<sp/>to<sp/>be<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="207"><highlight class="normal"><sp/><sp/>AT_CHECK(!src.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;add:<sp/>expected<sp/>&apos;other&apos;<sp/>to<sp/>be<sp/>a<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>a<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="208"><highlight class="normal"></highlight></codeline>
<codeline lineno="209"><highlight class="normal"><sp/><sp/>AT_CHECK(t.sizes().<ref refid="classat_1_1_array_ref_1a0feda741d9a2e73f563a67028827f6fa" kindref="member">equals</ref>(src.sizes()),<sp/></highlight><highlight class="stringliteral">&quot;add:<sp/>expected<sp/>sizes<sp/>of<sp/>&apos;self&apos;<sp/>and<sp/>&apos;other&apos;<sp/>to<sp/>match,<sp/>but<sp/>&quot;</highlight><highlight class="normal">,<sp/>t.sizes(),<sp/></highlight><highlight class="stringliteral">&quot;<sp/>!=<sp/>&quot;</highlight><highlight class="normal">,<sp/>src.sizes());</highlight></codeline>
<codeline lineno="210"><highlight class="normal"></highlight></codeline>
<codeline lineno="211"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(src._nnz()<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="212"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>raw_copy_sparse_(r,<sp/>t);</highlight></codeline>
<codeline lineno="213"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="214"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(t._nnz()<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="215"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>mul_out_sparse_scalar(r,<sp/>src,<sp/>value);</highlight></codeline>
<codeline lineno="216"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="217"><highlight class="normal"></highlight></codeline>
<codeline lineno="218"><highlight class="normal"><sp/><sp/>AT_CHECK(_is_same_density(t,<sp/>src),<sp/></highlight><highlight class="stringliteral">&quot;add:<sp/>expected<sp/>&apos;self&apos;<sp/>and<sp/>&apos;other&apos;<sp/>to<sp/>have<sp/>same<sp/>density,<sp/>but<sp/>&apos;self&apos;<sp/>has<sp/>&quot;</highlight><highlight class="normal">,<sp/>t._sparseDims(),<sp/></highlight><highlight class="stringliteral">&quot;<sp/>sparse<sp/>dimensions<sp/>while<sp/>&apos;other&apos;<sp/>has<sp/>&quot;</highlight><highlight class="normal">,<sp/>src._sparseDims(),<sp/></highlight><highlight class="stringliteral">&quot;<sp/>sparse<sp/>dimensions&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="219"><highlight class="normal"></highlight></codeline>
<codeline lineno="220"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>saving<sp/>those<sp/>because<sp/>they<sp/>can<sp/>be<sp/>overwritten<sp/>when<sp/>doing<sp/>in-place<sp/>operations</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="221"><highlight class="normal"><sp/><sp/>int64_t<sp/>t_nnz<sp/>=<sp/>t._nnz(),<sp/>s_nnz<sp/>=<sp/>src._nnz(),<sp/>max_nnz<sp/>=<sp/>t_nnz<sp/>+<sp/>s_nnz;</highlight></codeline>
<codeline lineno="222"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>t_coalesced<sp/>=<sp/>t.is_coalesced(),<sp/>s_coalesced<sp/>=<sp/>src.is_coalesced();</highlight></codeline>
<codeline lineno="223"><highlight class="normal"><sp/><sp/>int64_t<sp/>sparseDims<sp/>=<sp/>src._sparseDims();</highlight></codeline>
<codeline lineno="224"><highlight class="normal"><sp/><sp/>LongTensor<sp/>t_indices<sp/>=<sp/>t._indices();</highlight></codeline>
<codeline lineno="225"><highlight class="normal"><sp/><sp/>Tensor<sp/>t_values<sp/>=<sp/>t._values();</highlight></codeline>
<codeline lineno="226"><highlight class="normal"><sp/><sp/>LongTensor<sp/>src_indices<sp/>=<sp/>src._indices();</highlight></codeline>
<codeline lineno="227"><highlight class="normal"><sp/><sp/>Tensor<sp/>s_values<sp/>=<sp/>src._values();</highlight></codeline>
<codeline lineno="228"><highlight class="normal"><sp/><sp/>LongTensor<sp/>r_indices<sp/>=<sp/>t_indices.type().tensor({sparseDims,<sp/>max_nnz});</highlight></codeline>
<codeline lineno="229"><highlight class="normal"><sp/><sp/>Tensor<sp/>r_values<sp/>=<sp/>_new_values_with_size_of(s_values,<sp/>max_nnz).zero_();</highlight></codeline>
<codeline lineno="230"><highlight class="normal"><sp/><sp/>r.resize_as_(src);</highlight></codeline>
<codeline lineno="231"><highlight class="normal"><sp/><sp/>_get_sparse_impl(r)-&gt;set_indices_and_values(r_indices,<sp/>r_values);<sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>sigh</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="232"><highlight class="normal"></highlight></codeline>
<codeline lineno="233"><highlight class="normal"><sp/><sp/>int64_t<sp/>blockSize<sp/>=<sp/>r_values.stride(0);</highlight></codeline>
<codeline lineno="234"><highlight class="normal"><sp/><sp/>int64_t<sp/>cmp,<sp/>d;</highlight></codeline>
<codeline lineno="235"><highlight class="normal"><sp/><sp/>int64_t<sp/>r_i<sp/>=<sp/>0,<sp/>t_i<sp/>=<sp/>0,<sp/>s_i<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="236"><highlight class="normal"></highlight></codeline>
<codeline lineno="237"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>NB:<sp/>relies<sp/>on<sp/>nnz<sp/>tests<sp/>above</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="238"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>t_indices_accessor<sp/>=<sp/>t_indices.accessor&lt;int64_t,<sp/>2&gt;();</highlight></codeline>
<codeline lineno="239"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>r_indices_accessor<sp/>=<sp/>r_indices.accessor&lt;int64_t,<sp/>2&gt;();</highlight></codeline>
<codeline lineno="240"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>src_indices_accessor<sp/>=<sp/>src_indices.accessor&lt;int64_t,<sp/>2&gt;();</highlight></codeline>
<codeline lineno="241"><highlight class="normal"></highlight></codeline>
<codeline lineno="242"><highlight class="normal"><sp/><sp/>AT_DISPATCH_ALL_TYPES(</highlight></codeline>
<codeline lineno="243"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>t_values.type(),<sp/></highlight><highlight class="stringliteral">&quot;cadd_sparse&quot;</highlight><highlight class="normal">,<sp/>[&amp;]<sp/>{</highlight></codeline>
<codeline lineno="244"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scalar_t*<sp/>t_values_ptr<sp/>=<sp/>t_values.data&lt;scalar_t&gt;();</highlight></codeline>
<codeline lineno="245"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scalar_t*<sp/>s_values_ptr<sp/>=<sp/>s_values.data&lt;scalar_t&gt;();</highlight></codeline>
<codeline lineno="246"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scalar_t*<sp/>r_values_ptr<sp/>=<sp/>r_values.data&lt;scalar_t&gt;();</highlight></codeline>
<codeline lineno="247"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scalar_t<sp/>cast_value<sp/>=<sp/>value.to&lt;scalar_t&gt;();</highlight></codeline>
<codeline lineno="248"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">while</highlight><highlight class="normal"><sp/>(t_i<sp/>&lt;<sp/>t_nnz<sp/>||<sp/>s_i<sp/>&lt;<sp/>s_nnz)<sp/>{</highlight></codeline>
<codeline lineno="249"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(t_i<sp/>&gt;=<sp/>t_nnz)<sp/>{</highlight></codeline>
<codeline lineno="250"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cmp<sp/>=<sp/>-1;</highlight></codeline>
<codeline lineno="251"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(s_i<sp/>&gt;=<sp/>s_nnz)<sp/>{</highlight></codeline>
<codeline lineno="252"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cmp<sp/>=<sp/>1;</highlight></codeline>
<codeline lineno="253"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="254"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cmp<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="255"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>sparseDims;<sp/>d++)<sp/>{</highlight></codeline>
<codeline lineno="256"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(t_indices_accessor[d][t_i]<sp/>&lt;<sp/>src_indices_accessor[d][s_i])<sp/>{</highlight></codeline>
<codeline lineno="257"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cmp<sp/>=<sp/>1;</highlight></codeline>
<codeline lineno="258"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="259"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="260"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(t_indices_accessor[d][t_i]<sp/>&gt;<sp/>src_indices_accessor[d][s_i])<sp/>{</highlight></codeline>
<codeline lineno="261"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cmp<sp/>=<sp/>-1;</highlight></codeline>
<codeline lineno="262"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="263"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="264"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="265"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="266"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cmp<sp/>&gt;=<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="267"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>sparseDims;<sp/>d++)<sp/>{</highlight></codeline>
<codeline lineno="268"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>r_indices_accessor[d][r_i]<sp/>=<sp/>t_indices_accessor[d][t_i];</highlight></codeline>
<codeline lineno="269"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="270"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>THBlas_axpy&lt;scalar_t&gt;(blockSize,<sp/>1,</highlight></codeline>
<codeline lineno="271"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>t_values_ptr<sp/>+<sp/>t_i<sp/>*<sp/>blockSize,<sp/>1,</highlight></codeline>
<codeline lineno="272"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>r_values_ptr<sp/>+<sp/>r_i<sp/>*<sp/>blockSize,<sp/>1);</highlight></codeline>
<codeline lineno="273"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>t_i++;</highlight></codeline>
<codeline lineno="274"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="275"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cmp<sp/>&lt;=<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="276"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>sparseDims;<sp/>d++)<sp/>{</highlight></codeline>
<codeline lineno="277"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>r_indices_accessor[d][r_i]<sp/>=<sp/>src_indices_accessor[d][s_i];</highlight></codeline>
<codeline lineno="278"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="279"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>THBlas_axpy&lt;scalar_t&gt;(blockSize,<sp/>cast_value,</highlight></codeline>
<codeline lineno="280"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s_values_ptr<sp/>+<sp/>s_i<sp/>*<sp/>blockSize,<sp/>1,</highlight></codeline>
<codeline lineno="281"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>r_values_ptr<sp/>+<sp/>r_i<sp/>*<sp/>blockSize,<sp/>1);</highlight></codeline>
<codeline lineno="282"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s_i++;</highlight></codeline>
<codeline lineno="283"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="284"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>r_i++;</highlight></codeline>
<codeline lineno="285"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="286"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="287"><highlight class="normal"><sp/><sp/>);</highlight></codeline>
<codeline lineno="288"><highlight class="normal"></highlight></codeline>
<codeline lineno="289"><highlight class="normal"><sp/><sp/>_get_sparse_impl(r)-&gt;set_nnz(r_i);</highlight></codeline>
<codeline lineno="290"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>I<sp/>think<sp/>it<sp/>may<sp/>be<sp/>possible<sp/>to<sp/>track<sp/>inside<sp/>the<sp/>loop<sp/>and</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="291"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>detect<sp/>when<sp/>we<sp/>are<sp/>uncoalesced<sp/>(e.g.,<sp/>by<sp/>observing<sp/>that<sp/>an</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="292"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>index<sp/>goes<sp/>backwards)<sp/>which<sp/>may<sp/>be<sp/>more<sp/>precise<sp/>than<sp/>using<sp/>the</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="293"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>coalesced<sp/>flag<sp/>here.<sp/><sp/>But<sp/>this<sp/>is<sp/>easy.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="294"><highlight class="normal"><sp/><sp/>_get_sparse_impl(r)-&gt;set_coalesced(t_coalesced<sp/>&amp;&amp;<sp/>s_coalesced);</highlight></codeline>
<codeline lineno="295"><highlight class="normal"></highlight></codeline>
<codeline lineno="296"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="297"><highlight class="normal">}</highlight></codeline>
<codeline lineno="298"><highlight class="normal"></highlight></codeline>
<codeline lineno="299"><highlight class="normal">SparseTensor<sp/>s_add_sparse_cpu(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>src,<sp/>Scalar<sp/>alpha)<sp/>{</highlight></codeline>
<codeline lineno="300"><highlight class="normal"><sp/><sp/>SparseTensor<sp/>r<sp/>=<sp/>t.type().tensor();</highlight></codeline>
<codeline lineno="301"><highlight class="normal"><sp/><sp/>s_add_out_sparse_cpu(r,<sp/>t,<sp/>src,<sp/>alpha);</highlight></codeline>
<codeline lineno="302"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="303"><highlight class="normal">}</highlight></codeline>
<codeline lineno="304"><highlight class="normal"></highlight></codeline>
<codeline lineno="305"><highlight class="normal">SparseTensor&amp;<sp/>s_add_sparse_cpu_(SparseTensor&amp;<sp/>t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>src,<sp/>Scalar<sp/>alpha)<sp/>{</highlight></codeline>
<codeline lineno="306"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>s_add_out_sparse_cpu(t,<sp/>t,<sp/>src,<sp/>alpha);</highlight></codeline>
<codeline lineno="307"><highlight class="normal">}</highlight></codeline>
<codeline lineno="308"><highlight class="normal"></highlight></codeline>
<codeline lineno="309"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="310"><highlight class="normal"></highlight><highlight class="comment">//<sp/>add(Tensor,<sp/>SparseTensor,<sp/>Scalar)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="311"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/>formerly<sp/>known<sp/>as<sp/>spcadd</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="312"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="313"><highlight class="normal"></highlight></codeline>
<codeline lineno="314"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal"><sp/>&lt;</highlight><highlight class="keyword">typename</highlight><highlight class="normal"><sp/>scalar_t&gt;</highlight></codeline>
<codeline lineno="315"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>add_dense_sparse_worker_cpu(Tensor&amp;<sp/>r,<sp/>Scalar<sp/>value,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>sparse,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>indices,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>values)<sp/>{</highlight></codeline>
<codeline lineno="316"><highlight class="normal"><sp/><sp/>int64_t<sp/>k;</highlight></codeline>
<codeline lineno="317"><highlight class="normal"></highlight></codeline>
<codeline lineno="318"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>indices_accessor<sp/>=<sp/>indices.accessor&lt;int64_t,<sp/>2&gt;();</highlight></codeline>
<codeline lineno="319"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>values_accessor<sp/>=<sp/>values.accessor&lt;scalar_t,<sp/>1&gt;();</highlight></codeline>
<codeline lineno="320"><highlight class="normal"></highlight></codeline>
<codeline lineno="321"><highlight class="normal"><sp/><sp/>scalar_t*<sp/>r_ptr<sp/>=<sp/>r.data&lt;scalar_t&gt;();</highlight></codeline>
<codeline lineno="322"><highlight class="normal"><sp/><sp/>scalar_t<sp/>cast_value<sp/>=<sp/>value.to&lt;scalar_t&gt;();</highlight></codeline>
<codeline lineno="323"><highlight class="normal"></highlight></codeline>
<codeline lineno="324"><highlight class="normal"></highlight><highlight class="preprocessor"><sp/><sp/>#pragma<sp/>omp<sp/>parallel<sp/>for<sp/>private(k)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="325"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(k<sp/>=<sp/>0;<sp/>k<sp/>&lt;<sp/>sparse._nnz();<sp/>k++)<sp/>{</highlight></codeline>
<codeline lineno="326"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>index<sp/>=<sp/>r.storage_offset();</highlight></codeline>
<codeline lineno="327"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(int64_t<sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>sparse._sparseDims();<sp/>d++)<sp/>{</highlight></codeline>
<codeline lineno="328"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>index<sp/>+=<sp/>r.stride(d)<sp/>*<sp/>indices_accessor[d][k];</highlight></codeline>
<codeline lineno="329"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="330"><highlight class="normal"><sp/><sp/><sp/><sp/>r_ptr[index]<sp/>+=<sp/>cast_value<sp/>*<sp/>values_accessor[k];</highlight></codeline>
<codeline lineno="331"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="332"><highlight class="normal">}</highlight></codeline>
<codeline lineno="333"><highlight class="normal"></highlight></codeline>
<codeline lineno="334"><highlight class="normal">Tensor&amp;<sp/>add_out_dense_sparse_cpu(Tensor&amp;<sp/>r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>dense,<sp/>SparseTensorRef<sp/>sparse__,<sp/>Scalar<sp/>value)<sp/>{</highlight></codeline>
<codeline lineno="335"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>sparse_<sp/>=<sp/>sparse__.tref;</highlight></codeline>
<codeline lineno="336"><highlight class="normal"></highlight></codeline>
<codeline lineno="337"><highlight class="normal"><sp/><sp/>AT_ASSERT(!r.is_sparse());</highlight></codeline>
<codeline lineno="338"><highlight class="normal"><sp/><sp/>AT_ASSERT(!dense.is_sparse());</highlight></codeline>
<codeline lineno="339"><highlight class="normal"><sp/><sp/>AT_ASSERT(sparse_.is_sparse());</highlight></codeline>
<codeline lineno="340"><highlight class="normal"></highlight></codeline>
<codeline lineno="341"><highlight class="normal"><sp/><sp/>AT_ASSERT(!dense.is_cuda());<sp/></highlight><highlight class="comment">//<sp/>dispatch<sp/>argument</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="342"><highlight class="normal"><sp/><sp/>AT_CHECK(!r.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;add:<sp/>expected<sp/>&apos;out&apos;<sp/>to<sp/>be<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="343"><highlight class="normal"><sp/><sp/>AT_CHECK(!sparse_.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;add:<sp/>expected<sp/>&apos;other&apos;<sp/>to<sp/>be<sp/>a<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>a<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="344"><highlight class="normal"></highlight></codeline>
<codeline lineno="345"><highlight class="normal"><sp/><sp/>AT_CHECK(dense.sizes().equals(sparse_.sizes()),<sp/></highlight><highlight class="stringliteral">&quot;add:<sp/>expected<sp/>&apos;self&apos;<sp/>and<sp/>&apos;other&apos;<sp/>to<sp/>have<sp/>same<sp/>size,<sp/>but<sp/>self<sp/>has<sp/>size<sp/>&quot;</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="346"><highlight class="normal"><sp/><sp/><sp/><sp/>dense.sizes(),<sp/></highlight><highlight class="stringliteral">&quot;<sp/>while<sp/>other<sp/>has<sp/>size<sp/>&quot;</highlight><highlight class="normal">,<sp/>sparse_.sizes(),<sp/></highlight><highlight class="stringliteral">&quot;<sp/>(FYI:<sp/>dense-sparse<sp/>addition<sp/>does<sp/>not<sp/>currently<sp/>support<sp/>broadcasting)&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="347"><highlight class="normal"></highlight></codeline>
<codeline lineno="348"><highlight class="normal"><sp/><sp/>r.resize_as_(dense);</highlight></codeline>
<codeline lineno="349"><highlight class="normal"><sp/><sp/>SparseTensor<sp/>sparse<sp/>=<sp/>sparse_.coalesce();</highlight></codeline>
<codeline lineno="350"><highlight class="normal"></highlight></codeline>
<codeline lineno="351"><highlight class="normal"><sp/><sp/>LongTensor<sp/>indices<sp/>=<sp/>sparse._indices();</highlight></codeline>
<codeline lineno="352"><highlight class="normal"><sp/><sp/>Tensor<sp/>values<sp/>=<sp/>sparse._values();</highlight></codeline>
<codeline lineno="353"><highlight class="normal"><sp/><sp/>int64_t<sp/>nDim<sp/>=<sp/>dense.dim();</highlight></codeline>
<codeline lineno="354"><highlight class="normal"><sp/><sp/>int64_t<sp/>nDimI<sp/>=<sp/>sparse._sparseDims();</highlight></codeline>
<codeline lineno="355"><highlight class="normal"></highlight></codeline>
<codeline lineno="356"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!isSameTensor(r,<sp/>dense))<sp/>r.copy_(dense);</highlight></codeline>
<codeline lineno="357"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(sparse._nnz()<sp/>==<sp/>0)<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="358"><highlight class="normal"></highlight></codeline>
<codeline lineno="359"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>accessors<sp/>rely<sp/>on<sp/>nnz<sp/>test</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="360"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(nDim<sp/>&gt;<sp/>nDimI)<sp/>{</highlight></codeline>
<codeline lineno="361"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>indices_accessor<sp/>=<sp/>indices.accessor&lt;int64_t,<sp/>2&gt;();</highlight></codeline>
<codeline lineno="362"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(int64_t<sp/>k<sp/>=<sp/>0;<sp/>k<sp/>&lt;<sp/>sparse._nnz();<sp/>k++)<sp/>{</highlight></codeline>
<codeline lineno="363"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>Tensor<sp/>dstBuffer<sp/>=<sp/>r;</highlight></codeline>
<codeline lineno="364"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(int64_t<sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>sparse._sparseDims();<sp/>d++)<sp/>{</highlight></codeline>
<codeline lineno="365"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dstBuffer<sp/>=<sp/>dstBuffer.select(0,<sp/>indices_accessor[d][k]);</highlight></codeline>
<codeline lineno="366"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="367"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>Tensor<sp/>srcBuffer<sp/>=<sp/>values.select(0,<sp/>k);</highlight></codeline>
<codeline lineno="368"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>dstBuffer.add_(srcBuffer,<sp/>value);</highlight></codeline>
<codeline lineno="369"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="370"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="371"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_DISPATCH_ALL_TYPES(</highlight></codeline>
<codeline lineno="372"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>values.type(),<sp/></highlight><highlight class="stringliteral">&quot;add_dense_sparse&quot;</highlight><highlight class="normal">,<sp/>[&amp;]<sp/>{</highlight></codeline>
<codeline lineno="373"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>add_dense_sparse_worker_cpu&lt;scalar_t&gt;(r,<sp/>value,<sp/>sparse,<sp/>indices,<sp/>values);</highlight></codeline>
<codeline lineno="374"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>});</highlight></codeline>
<codeline lineno="375"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="376"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="377"><highlight class="normal">}</highlight></codeline>
<codeline lineno="378"><highlight class="normal"></highlight></codeline>
<codeline lineno="379"><highlight class="normal">Tensor<sp/>add_dense_sparse_cpu(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>t,<sp/>SparseTensorRef<sp/>src,<sp/>Scalar<sp/>alpha)<sp/>{</highlight></codeline>
<codeline lineno="380"><highlight class="normal"><sp/><sp/>Tensor<sp/>r<sp/>=<sp/>t.type().tensor();</highlight></codeline>
<codeline lineno="381"><highlight class="normal"><sp/><sp/>add_out_dense_sparse_cpu(r,<sp/>t,<sp/>src,<sp/>alpha);</highlight></codeline>
<codeline lineno="382"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="383"><highlight class="normal">}</highlight></codeline>
<codeline lineno="384"><highlight class="normal"></highlight></codeline>
<codeline lineno="385"><highlight class="normal">Tensor&amp;<sp/>add_dense_sparse_cpu_(Tensor&amp;<sp/>t,<sp/>SparseTensorRef<sp/>src,<sp/>Scalar<sp/>alpha)<sp/>{</highlight></codeline>
<codeline lineno="386"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>add_out_dense_sparse_cpu(t,<sp/>t,<sp/>src,<sp/>alpha);</highlight></codeline>
<codeline lineno="387"><highlight class="normal">}</highlight></codeline>
<codeline lineno="388"><highlight class="normal"></highlight></codeline>
<codeline lineno="389"><highlight class="normal"></highlight></codeline>
<codeline lineno="390"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="391"><highlight class="normal"></highlight><highlight class="comment">//<sp/>sub(SparseTensor,<sp/>SparseTensor,<sp/>Scalar)<sp/><sp/>[broadcasts]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="392"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="393"><highlight class="normal"></highlight></codeline>
<codeline lineno="394"><highlight class="normal">SparseTensor&amp;<sp/>s_sub_out_sparse_cpu(SparseTensor&amp;<sp/>r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>src,<sp/>Scalar<sp/>value)<sp/>{</highlight></codeline>
<codeline lineno="395"><highlight class="normal"><sp/><sp/>AT_ASSERT(!t.is_cuda());<sp/></highlight><highlight class="comment">//<sp/>dispatch<sp/>argument</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="396"><highlight class="normal"><sp/><sp/>AT_CHECK(!r.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;sub:<sp/>expected<sp/>&apos;out&apos;<sp/>to<sp/>be<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="397"><highlight class="normal"><sp/><sp/>AT_CHECK(!src.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;sub:<sp/>expected<sp/>&apos;other&apos;<sp/>to<sp/>be<sp/>a<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>a<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="398"><highlight class="normal"></highlight></codeline>
<codeline lineno="399"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>UGH...<sp/>We&apos;re<sp/>doing<sp/>two<sp/>dispatches<sp/>on<sp/>scalar<sp/>type<sp/>here<sp/>for<sp/>no<sp/>good<sp/>reason.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="400"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>NB:<sp/>I<sp/>tried<sp/>adding<sp/>an<sp/>operator-<sp/>to<sp/>Scalar,<sp/>but<sp/>there<sp/>isn&apos;t<sp/>any<sp/>good<sp/>way</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="401"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>to<sp/>negate<sp/>the<sp/>tensor,<sp/>because<sp/>I<sp/>have<sp/>a<sp/>TensorBase...</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="402"><highlight class="normal"><sp/><sp/>AT_DISPATCH_ALL_TYPES(</highlight></codeline>
<codeline lineno="403"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>t.type(),<sp/></highlight><highlight class="stringliteral">&quot;sub_sparse&quot;</highlight><highlight class="normal">,<sp/>[&amp;]<sp/>{</highlight></codeline>
<codeline lineno="404"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scalar_t<sp/>cast_value<sp/>=<sp/>value.to&lt;scalar_t&gt;();</highlight></codeline>
<codeline lineno="405"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s_add_out_sparse_cpu(r,<sp/>t,<sp/>src,<sp/>-cast_value);</highlight></codeline>
<codeline lineno="406"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="407"><highlight class="normal"><sp/><sp/>);</highlight></codeline>
<codeline lineno="408"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="409"><highlight class="normal">}</highlight></codeline>
<codeline lineno="410"><highlight class="normal"></highlight></codeline>
<codeline lineno="411"><highlight class="normal">SparseTensor<sp/>s_sub_sparse_cpu(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>src,<sp/>Scalar<sp/>alpha)<sp/>{</highlight></codeline>
<codeline lineno="412"><highlight class="normal"><sp/><sp/>SparseTensor<sp/>r<sp/>=<sp/>t.type().tensor();</highlight></codeline>
<codeline lineno="413"><highlight class="normal"><sp/><sp/>s_sub_out_sparse_cpu(r,<sp/>t,<sp/>src,<sp/>alpha);</highlight></codeline>
<codeline lineno="414"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="415"><highlight class="normal">}</highlight></codeline>
<codeline lineno="416"><highlight class="normal"></highlight></codeline>
<codeline lineno="417"><highlight class="normal">SparseTensor&amp;<sp/>s_sub_sparse_cpu_(SparseTensor&amp;<sp/>t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>src,<sp/>Scalar<sp/>alpha)<sp/>{</highlight></codeline>
<codeline lineno="418"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>s_sub_out_sparse_cpu(t,<sp/>t,<sp/>src,<sp/>alpha);</highlight></codeline>
<codeline lineno="419"><highlight class="normal">}</highlight></codeline>
<codeline lineno="420"><highlight class="normal"></highlight></codeline>
<codeline lineno="421"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="422"><highlight class="normal"></highlight><highlight class="comment">//<sp/>mul(SparseTensor,<sp/>SparseTensor,<sp/>Scalar)<sp/><sp/>[broadcasts]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="423"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="424"><highlight class="normal"></highlight></codeline>
<codeline lineno="425"><highlight class="normal">SparseTensor&amp;<sp/>s_mul_out_sparse_cpu(SparseTensor&amp;<sp/>r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>t_,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>src_)<sp/>{</highlight></codeline>
<codeline lineno="426"><highlight class="normal"><sp/><sp/>AT_CHECK(t_.sizes().<ref refid="classat_1_1_array_ref_1a0feda741d9a2e73f563a67028827f6fa" kindref="member">equals</ref>(src_.sizes()),<sp/></highlight><highlight class="stringliteral">&quot;mul<sp/>operands<sp/>have<sp/>incompatible<sp/>sizes&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="427"><highlight class="normal"><sp/><sp/>AT_ASSERT(!t_.is_cuda());<sp/></highlight><highlight class="comment">//<sp/>dispatch<sp/>argument</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="428"><highlight class="normal"><sp/><sp/>AT_CHECK(!r.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;mul:<sp/>expected<sp/>&apos;out&apos;<sp/>to<sp/>be<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="429"><highlight class="normal"><sp/><sp/>AT_CHECK(!src_.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;mul:<sp/>expected<sp/>&apos;other&apos;<sp/>to<sp/>be<sp/>a<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>a<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="430"><highlight class="normal"></highlight></codeline>
<codeline lineno="431"><highlight class="normal"><sp/><sp/>AT_CHECK(t_.sizes().<ref refid="classat_1_1_array_ref_1a0feda741d9a2e73f563a67028827f6fa" kindref="member">equals</ref>(src_.sizes()),<sp/></highlight><highlight class="stringliteral">&quot;mul:<sp/>expected<sp/>&apos;self&apos;<sp/>and<sp/>&apos;other&apos;<sp/>to<sp/>have<sp/>same<sp/>sizes,<sp/>but<sp/>&quot;</highlight><highlight class="normal">,<sp/>t_.sizes(),<sp/></highlight><highlight class="stringliteral">&quot;<sp/>!=<sp/>&quot;</highlight><highlight class="normal">,<sp/>src_.sizes());</highlight></codeline>
<codeline lineno="432"><highlight class="normal"></highlight></codeline>
<codeline lineno="433"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(src_._nnz()<sp/>==<sp/>0<sp/>||<sp/>t_._nnz()<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="434"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r.zero_();</highlight></codeline>
<codeline lineno="435"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="436"><highlight class="normal"></highlight></codeline>
<codeline lineno="437"><highlight class="normal"><sp/><sp/>SparseTensor<sp/>t<sp/>=<sp/>t_.coalesce();</highlight></codeline>
<codeline lineno="438"><highlight class="normal"><sp/><sp/>SparseTensor<sp/>src<sp/>=<sp/>src_.coalesce();</highlight></codeline>
<codeline lineno="439"><highlight class="normal"></highlight></codeline>
<codeline lineno="440"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>saving<sp/>those<sp/>because<sp/>they<sp/>can<sp/>be<sp/>overwritten<sp/>when<sp/>doing<sp/>in-place<sp/>operations</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="441"><highlight class="normal"><sp/><sp/>int64_t<sp/>t_nnz<sp/>=<sp/>t._nnz(),<sp/>s_nnz<sp/>=<sp/>src._nnz();</highlight></codeline>
<codeline lineno="442"><highlight class="normal"><sp/><sp/>int64_t<sp/>max_nnz<sp/>=<sp/>std::min(t_nnz,<sp/>s_nnz);<sp/><sp/></highlight><highlight class="comment">//<sp/>multiply<sp/>by<sp/>zero<sp/>is<sp/>zero,<sp/>and<sp/>can<sp/>be<sp/>dropped</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="443"><highlight class="normal"><sp/><sp/>int64_t<sp/>sparseDims<sp/>=<sp/>src._sparseDims();</highlight></codeline>
<codeline lineno="444"><highlight class="normal"><sp/><sp/>LongTensor<sp/>t_indices<sp/>=<sp/>t._indices();</highlight></codeline>
<codeline lineno="445"><highlight class="normal"><sp/><sp/>Tensor<sp/>t_values<sp/>=<sp/>t._values();</highlight></codeline>
<codeline lineno="446"><highlight class="normal"><sp/><sp/>LongTensor<sp/>src_indices<sp/>=<sp/>src._indices();</highlight></codeline>
<codeline lineno="447"><highlight class="normal"><sp/><sp/>Tensor<sp/>s_values<sp/>=<sp/>src._values();</highlight></codeline>
<codeline lineno="448"><highlight class="normal"><sp/><sp/>LongTensor<sp/>r_indices<sp/>=<sp/>t_indices.type().tensor({sparseDims,<sp/>max_nnz});</highlight></codeline>
<codeline lineno="449"><highlight class="normal"><sp/><sp/>Tensor<sp/>r_values<sp/>=<sp/>_new_values_with_size_of(t_values,<sp/>max_nnz).zero_();</highlight></codeline>
<codeline lineno="450"><highlight class="normal"><sp/><sp/>r.resize_as_(src);</highlight></codeline>
<codeline lineno="451"><highlight class="normal"><sp/><sp/>_get_sparse_impl(r)-&gt;set_indices_and_values(r_indices,<sp/>r_values);<sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>sigh</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="452"><highlight class="normal"></highlight></codeline>
<codeline lineno="453"><highlight class="normal"><sp/><sp/>int64_t<sp/>match,<sp/>d;</highlight></codeline>
<codeline lineno="454"><highlight class="normal"><sp/><sp/>int64_t<sp/>r_i<sp/>=<sp/>0,<sp/>t_i<sp/>=<sp/>0,<sp/>s_i<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="455"><highlight class="normal"></highlight></codeline>
<codeline lineno="456"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>NB:<sp/>relies<sp/>on<sp/>nnz<sp/>test<sp/>above</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="457"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>t_indices_accessor<sp/>=<sp/>t_indices.accessor&lt;int64_t,<sp/>2&gt;();</highlight></codeline>
<codeline lineno="458"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>r_indices_accessor<sp/>=<sp/>r_indices.accessor&lt;int64_t,<sp/>2&gt;();</highlight></codeline>
<codeline lineno="459"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>src_indices_accessor<sp/>=<sp/>src_indices.accessor&lt;int64_t,<sp/>2&gt;();</highlight></codeline>
<codeline lineno="460"><highlight class="normal"></highlight></codeline>
<codeline lineno="461"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Check<sp/>if<sp/>we<sp/>can<sp/>find<sp/>matching<sp/>indices,<sp/>and<sp/>if<sp/>so,<sp/>write<sp/>an</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="462"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>entry<sp/>to<sp/>the<sp/>result<sp/>indices<sp/>vector.<sp/><sp/>Returns<sp/>true<sp/>if<sp/>matching</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="463"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>indices<sp/>were<sp/>found.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="464"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>index_preamble<sp/>=<sp/>[&amp;]()<sp/>{</highlight></codeline>
<codeline lineno="465"><highlight class="normal"><sp/><sp/><sp/><sp/>match<sp/>=<sp/>1;</highlight></codeline>
<codeline lineno="466"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>sparseDims;<sp/>d++)<sp/>{</highlight></codeline>
<codeline lineno="467"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(t_indices_accessor[d][t_i]<sp/>&lt;<sp/>src_indices_accessor[d][s_i])<sp/>{</highlight></codeline>
<codeline lineno="468"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>t_i++;</highlight></codeline>
<codeline lineno="469"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>match<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="470"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="471"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="472"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(t_indices_accessor[d][t_i]<sp/>&gt;<sp/>src_indices_accessor[d][s_i])<sp/>{</highlight></codeline>
<codeline lineno="473"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s_i++;</highlight></codeline>
<codeline lineno="474"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>match<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="475"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="476"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="477"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="478"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!match)<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">false</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="479"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>sparseDims;<sp/>d++)<sp/>{</highlight></codeline>
<codeline lineno="480"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>r_indices_accessor[d][r_i]<sp/>=<sp/>t_indices_accessor[d][t_i];</highlight></codeline>
<codeline lineno="481"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="482"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">true</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="483"><highlight class="normal"><sp/><sp/>};</highlight></codeline>
<codeline lineno="484"><highlight class="normal"></highlight></codeline>
<codeline lineno="485"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(t_values.dim()<sp/>&gt;<sp/>1)<sp/>{</highlight></codeline>
<codeline lineno="486"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">while</highlight><highlight class="normal"><sp/>(t_i<sp/>&lt;<sp/>t_nnz<sp/>&amp;&amp;<sp/>s_i<sp/>&lt;<sp/>s_nnz)<sp/>{</highlight></codeline>
<codeline lineno="487"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!index_preamble())<sp/></highlight><highlight class="keywordflow">continue</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="488"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>r_values.select(0,<sp/>r_i).addcmul_(t_values.select(0,<sp/>t_i),<sp/>s_values.select(0,<sp/>s_i));</highlight></codeline>
<codeline lineno="489"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>r_i++;</highlight></codeline>
<codeline lineno="490"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>t_i++;</highlight></codeline>
<codeline lineno="491"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>s_i++;</highlight></codeline>
<codeline lineno="492"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="493"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="494"><highlight class="normal"><sp/><sp/><sp/><sp/>AT_DISPATCH_ALL_TYPES(</highlight></codeline>
<codeline lineno="495"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>r_values.type(),<sp/></highlight><highlight class="stringliteral">&quot;mul_out_sparse&quot;</highlight><highlight class="normal">,<sp/>[&amp;]<sp/>{</highlight></codeline>
<codeline lineno="496"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>r_accessor<sp/>=<sp/>r_values.accessor&lt;scalar_t,<sp/>1&gt;();</highlight></codeline>
<codeline lineno="497"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>t_accessor<sp/>=<sp/>t_values.accessor&lt;scalar_t,<sp/>1&gt;();</highlight></codeline>
<codeline lineno="498"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>s_accessor<sp/>=<sp/>s_values.accessor&lt;scalar_t,<sp/>1&gt;();</highlight></codeline>
<codeline lineno="499"><highlight class="normal"></highlight></codeline>
<codeline lineno="500"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">while</highlight><highlight class="normal"><sp/>(t_i<sp/>&lt;<sp/>t_nnz<sp/>&amp;&amp;<sp/>s_i<sp/>&lt;<sp/>s_nnz)<sp/>{</highlight></codeline>
<codeline lineno="501"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!index_preamble())<sp/></highlight><highlight class="keywordflow">continue</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="502"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>r_accessor[r_i]<sp/>=<sp/>t_accessor[t_i]<sp/>*<sp/>s_accessor[s_i];</highlight></codeline>
<codeline lineno="503"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>r_i++;</highlight></codeline>
<codeline lineno="504"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>t_i++;</highlight></codeline>
<codeline lineno="505"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s_i++;</highlight></codeline>
<codeline lineno="506"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="507"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="508"><highlight class="normal"><sp/><sp/><sp/><sp/>);</highlight></codeline>
<codeline lineno="509"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="510"><highlight class="normal"></highlight></codeline>
<codeline lineno="511"><highlight class="normal"><sp/><sp/>_get_sparse_impl(r)-&gt;set_nnz(r_i);</highlight></codeline>
<codeline lineno="512"><highlight class="normal"><sp/><sp/>_get_sparse_impl(r)-&gt;set_coalesced(</highlight><highlight class="keyword">true</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="513"><highlight class="normal"></highlight></codeline>
<codeline lineno="514"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="515"><highlight class="normal">}</highlight></codeline>
<codeline lineno="516"><highlight class="normal"></highlight></codeline>
<codeline lineno="517"><highlight class="normal">SparseTensor<sp/>s_mul_sparse_cpu(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>src)<sp/>{</highlight></codeline>
<codeline lineno="518"><highlight class="normal"><sp/><sp/>SparseTensor<sp/>r<sp/>=<sp/>t.type().tensor();</highlight></codeline>
<codeline lineno="519"><highlight class="normal"><sp/><sp/>s_mul_out_sparse_cpu(r,<sp/>t,<sp/>src);</highlight></codeline>
<codeline lineno="520"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="521"><highlight class="normal">}</highlight></codeline>
<codeline lineno="522"><highlight class="normal"></highlight></codeline>
<codeline lineno="523"><highlight class="normal">SparseTensor&amp;<sp/>s_mul_sparse_cpu_(SparseTensor&amp;<sp/>t,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>src)<sp/>{</highlight></codeline>
<codeline lineno="524"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>s_mul_out_sparse_cpu(t,<sp/>t,<sp/>src);</highlight></codeline>
<codeline lineno="525"><highlight class="normal">}</highlight></codeline>
<codeline lineno="526"><highlight class="normal"></highlight></codeline>
<codeline lineno="527"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="528"><highlight class="normal"></highlight><highlight class="comment">//<sp/>addmm(Tensor,<sp/>SparseTensorRef,<sp/>Tensor,<sp/>Scalar,<sp/>Scalar)<sp/><sp/>[broadcasts]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="529"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="530"><highlight class="normal"></highlight></codeline>
<codeline lineno="531"><highlight class="normal"></highlight><highlight class="comment">//<sp/>NB:<sp/>OMP<sp/>pragmas<sp/>have<sp/>to<sp/>get<sp/>their<sp/>own<sp/>functions;<sp/>can&apos;t<sp/>put<sp/>them<sp/>in<sp/>lambdas</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="532"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal"><sp/>&lt;</highlight><highlight class="keyword">typename</highlight><highlight class="normal"><sp/>scalar_t&gt;</highlight></codeline>
<codeline lineno="533"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>s_addmm_out_sparse_dense_worker(int64_t<sp/>nnz,<sp/>int64_t<sp/>dim_i,<sp/>int64_t<sp/>dim_j,<sp/>int64_t<sp/>dim_k,<sp/>Tensor&amp;<sp/>r,<sp/>Scalar<sp/>beta,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>t,<sp/>Scalar<sp/>alpha,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>csr,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>indices,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>values,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>dense)<sp/>{</highlight></codeline>
<codeline lineno="534"><highlight class="normal"><sp/><sp/>int64_t<sp/>h,<sp/>i;</highlight></codeline>
<codeline lineno="535"><highlight class="normal"></highlight></codeline>
<codeline lineno="536"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>r_<sp/>=<sp/>alpha<sp/>*<sp/>sparse<sp/>*<sp/>dense</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="537"><highlight class="normal"><sp/><sp/>scalar_t<sp/>cast_alpha<sp/>=<sp/>alpha.to&lt;scalar_t&gt;();</highlight></codeline>
<codeline lineno="538"><highlight class="normal"><sp/><sp/>scalar_t<sp/>cast_beta<sp/>=<sp/>beta.to&lt;scalar_t&gt;();</highlight></codeline>
<codeline lineno="539"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cast_beta<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="540"><highlight class="normal"><sp/><sp/><sp/><sp/>r.zero_();</highlight></codeline>
<codeline lineno="541"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cast_beta<sp/>==<sp/>1)<sp/>{</highlight></codeline>
<codeline lineno="542"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!isSameTensor(r,<sp/>t))<sp/>{</highlight></codeline>
<codeline lineno="543"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>r.copy_(t);</highlight></codeline>
<codeline lineno="544"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="545"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="546"><highlight class="normal"><sp/><sp/><sp/><sp/>at::mul_out(r,<sp/>t,<sp/>beta);</highlight></codeline>
<codeline lineno="547"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="548"><highlight class="normal"></highlight></codeline>
<codeline lineno="549"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>csr_accessor<sp/>=<sp/>csr.accessor&lt;int64_t,<sp/>1&gt;();</highlight></codeline>
<codeline lineno="550"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>indices_accessor<sp/>=<sp/>indices.accessor&lt;int64_t,<sp/>2&gt;();</highlight></codeline>
<codeline lineno="551"><highlight class="normal"></highlight></codeline>
<codeline lineno="552"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>values_accessor<sp/>=<sp/>values.accessor&lt;scalar_t,<sp/>1&gt;();</highlight></codeline>
<codeline lineno="553"><highlight class="normal"><sp/><sp/>scalar_t*<sp/>dense_ptr<sp/>=<sp/>dense.data&lt;scalar_t&gt;();</highlight></codeline>
<codeline lineno="554"><highlight class="normal"><sp/><sp/>scalar_t*<sp/>r_ptr<sp/>=<sp/>r.data&lt;scalar_t&gt;();</highlight></codeline>
<codeline lineno="555"><highlight class="normal"></highlight></codeline>
<codeline lineno="556"><highlight class="normal"><sp/><sp/>int64_t<sp/>dense_stride0<sp/>=<sp/>dense.stride(0);</highlight></codeline>
<codeline lineno="557"><highlight class="normal"><sp/><sp/>int64_t<sp/>dense_stride1<sp/>=<sp/>dense.stride(1);</highlight></codeline>
<codeline lineno="558"><highlight class="normal"><sp/><sp/>int64_t<sp/>r_stride0<sp/>=<sp/>r.stride(0);</highlight></codeline>
<codeline lineno="559"><highlight class="normal"><sp/><sp/>int64_t<sp/>r_stride1<sp/>=<sp/>r.stride(1);</highlight></codeline>
<codeline lineno="560"><highlight class="normal"></highlight><highlight class="preprocessor">#pragma<sp/>omp<sp/>parallel<sp/>for<sp/>private(h,<sp/>i)<sp/>schedule(static)<sp/>if<sp/>(nnz<sp/>&gt;<sp/>10000)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="561"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(h<sp/>=<sp/>0;<sp/>h<sp/>&lt;<sp/>dim_i;<sp/>h++)<sp/>{</highlight></codeline>
<codeline lineno="562"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>i_start<sp/>=<sp/>csr_accessor[h];</highlight></codeline>
<codeline lineno="563"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>i_end<sp/>=<sp/>csr_accessor[h+1];</highlight></codeline>
<codeline lineno="564"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(i<sp/>=<sp/>i_start;<sp/>i<sp/>&lt;<sp/>i_end;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="565"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>scalar_t<sp/>val<sp/>=<sp/>values_accessor[i];</highlight></codeline>
<codeline lineno="566"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>int64_t<sp/>col<sp/>=<sp/>indices_accessor[1][i];</highlight></codeline>
<codeline lineno="567"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(col<sp/>&gt;=<sp/>0<sp/>&amp;&amp;<sp/>col<sp/>&lt;<sp/>dim_j)<sp/>{</highlight></codeline>
<codeline lineno="568"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>THBlas_axpy&lt;scalar_t&gt;(dim_k,</highlight></codeline>
<codeline lineno="569"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cast_alpha<sp/>*<sp/>val,</highlight></codeline>
<codeline lineno="570"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dense_ptr<sp/>+<sp/>col<sp/>*<sp/>dense_stride0,<sp/>dense_stride1,</highlight></codeline>
<codeline lineno="571"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>r_ptr<sp/>+<sp/>h<sp/>*<sp/>r_stride0,<sp/>r_stride1);</highlight></codeline>
<codeline lineno="572"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="573"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>AT_ERROR(</highlight><highlight class="stringliteral">&quot;addmm:<sp/>index<sp/>out<sp/>of<sp/>bound:<sp/>&quot;</highlight><highlight class="normal">,<sp/>col,<sp/></highlight><highlight class="stringliteral">&quot;<sp/>not<sp/>between<sp/>1<sp/>and<sp/>&quot;</highlight><highlight class="normal">,<sp/>dim_j);</highlight></codeline>
<codeline lineno="574"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="575"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="576"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="577"><highlight class="normal">};</highlight></codeline>
<codeline lineno="578"><highlight class="normal"></highlight></codeline>
<codeline lineno="579"><highlight class="normal">Tensor&amp;<sp/>s_addmm_out_sparse_dense_cpu(</highlight></codeline>
<codeline lineno="580"><highlight class="normal"><sp/><sp/><sp/><sp/>Tensor&amp;<sp/>r,</highlight></codeline>
<codeline lineno="581"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>t,</highlight></codeline>
<codeline lineno="582"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>sparse_,</highlight></codeline>
<codeline lineno="583"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>dense,</highlight></codeline>
<codeline lineno="584"><highlight class="normal"><sp/><sp/><sp/><sp/>Scalar<sp/>beta,</highlight></codeline>
<codeline lineno="585"><highlight class="normal"><sp/><sp/><sp/><sp/>Scalar<sp/>alpha</highlight></codeline>
<codeline lineno="586"><highlight class="normal">)<sp/>{</highlight></codeline>
<codeline lineno="587"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>This<sp/>error<sp/>message<sp/>seems<sp/>awfully<sp/>opaque</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="588"><highlight class="normal"><sp/><sp/>AT_ASSERT(!t.is_cuda());</highlight></codeline>
<codeline lineno="589"><highlight class="normal"><sp/><sp/>AT_CHECK(!r.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;addmm:<sp/>expected<sp/>&apos;out&apos;<sp/>to<sp/>be<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="590"><highlight class="normal"><sp/><sp/>AT_CHECK(!sparse_.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;addmm:<sp/>expected<sp/>&apos;mat1&apos;<sp/>to<sp/>be<sp/>a<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>a<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="591"><highlight class="normal"><sp/><sp/>AT_CHECK(!dense.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;addmm:<sp/>expected<sp/>&apos;mat2&apos;<sp/>to<sp/>be<sp/>a<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>a<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="592"><highlight class="normal"></highlight></codeline>
<codeline lineno="593"><highlight class="normal"><sp/><sp/>AT_CHECK(sparse_._sparseDims()<sp/>==<sp/>2,<sp/></highlight><highlight class="stringliteral">&quot;addmm:<sp/>matrices<sp/>expected,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>sparse_._sparseDims(),<sp/></highlight><highlight class="stringliteral">&quot;D<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="594"><highlight class="normal"><sp/><sp/>AT_CHECK(sparse_._denseDims()<sp/>==<sp/>0,<sp/></highlight><highlight class="stringliteral">&quot;addmm:<sp/>scalar<sp/>values<sp/>expected,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>sparse_._denseDims(),<sp/></highlight><highlight class="stringliteral">&quot;D<sp/>values&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="595"><highlight class="normal"><sp/><sp/>AT_CHECK(dense.numel()<sp/>!=<sp/>0,<sp/></highlight><highlight class="stringliteral">&quot;addmm:<sp/>matrices<sp/>expected,<sp/>got<sp/>empty<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="596"><highlight class="normal"><sp/><sp/>AT_CHECK(dense.dim()<sp/>==<sp/>2,<sp/></highlight><highlight class="stringliteral">&quot;addmm:<sp/>matrices<sp/>expected,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>dense.dim(),<sp/></highlight><highlight class="stringliteral">&quot;D<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="597"><highlight class="normal"></highlight></codeline>
<codeline lineno="598"><highlight class="normal"><sp/><sp/>SparseTensor<sp/>sparse<sp/>=<sp/>sparse_.coalesce();</highlight></codeline>
<codeline lineno="599"><highlight class="normal"></highlight></codeline>
<codeline lineno="600"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>ixj<sp/>*<sp/>jxk<sp/>=<sp/>ixk</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="601"><highlight class="normal"><sp/><sp/>int64_t<sp/>dim_i<sp/>=<sp/>sparse.size(0);</highlight></codeline>
<codeline lineno="602"><highlight class="normal"><sp/><sp/>int64_t<sp/>dim_j<sp/>=<sp/>sparse.size(1);</highlight></codeline>
<codeline lineno="603"><highlight class="normal"><sp/><sp/>int64_t<sp/>dim_k<sp/>=<sp/>dense.size(1);</highlight></codeline>
<codeline lineno="604"><highlight class="normal"></highlight></codeline>
<codeline lineno="605"><highlight class="normal"><sp/><sp/>AT_CHECK(dense.size(0)<sp/>==<sp/>dim_j,</highlight></codeline>
<codeline lineno="606"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;addmm:<sp/>Argument<sp/>#3<sp/>(dense):<sp/>Expected<sp/>dim<sp/>0<sp/>size<sp/>&quot;</highlight><highlight class="normal">,<sp/>dim_j,<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>dense.size(0));</highlight></codeline>
<codeline lineno="607"><highlight class="normal"><sp/><sp/>AT_CHECK(t.size(0)<sp/>==<sp/>dim_i,</highlight></codeline>
<codeline lineno="608"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;addmm:<sp/>Argument<sp/>#1<sp/>(t):<sp/>Expected<sp/>dim<sp/>0<sp/>size<sp/>&quot;</highlight><highlight class="normal">,<sp/>dim_i,<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>t.size(0));</highlight></codeline>
<codeline lineno="609"><highlight class="normal"><sp/><sp/>AT_CHECK(t.size(1)<sp/>==<sp/>dim_k,</highlight></codeline>
<codeline lineno="610"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;addmm:<sp/>Argument<sp/>#1<sp/>(t):<sp/>Expected<sp/>dim<sp/>1<sp/>size<sp/>&quot;</highlight><highlight class="normal">,<sp/>dim_k,<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>t.size(1));</highlight></codeline>
<codeline lineno="611"><highlight class="normal"></highlight></codeline>
<codeline lineno="612"><highlight class="normal"><sp/><sp/>r.resize_({dim_i,<sp/>dim_k});</highlight></codeline>
<codeline lineno="613"><highlight class="normal"></highlight></codeline>
<codeline lineno="614"><highlight class="normal"><sp/><sp/>int64_t<sp/>nnz<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>=<sp/>sparse._nnz();</highlight></codeline>
<codeline lineno="615"><highlight class="normal"></highlight></codeline>
<codeline lineno="616"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(nnz<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="617"><highlight class="normal"><sp/><sp/><sp/><sp/>at::mul_out(r,<sp/>t,<sp/>beta);</highlight></codeline>
<codeline lineno="618"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="619"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="620"><highlight class="normal"></highlight></codeline>
<codeline lineno="621"><highlight class="normal"><sp/><sp/>LongTensor<sp/>indices<sp/>=<sp/>sparse._indices();</highlight></codeline>
<codeline lineno="622"><highlight class="normal"><sp/><sp/>Tensor<sp/>values<sp/><sp/><sp/><sp/><sp/><sp/>=<sp/>sparse._values();</highlight></codeline>
<codeline lineno="623"><highlight class="normal"><sp/><sp/>LongTensor<sp/>csr<sp/>=<sp/>_to_csr(indices.data&lt;int64_t&gt;(),<sp/>dim_i,<sp/>nnz);</highlight></codeline>
<codeline lineno="624"><highlight class="normal"></highlight></codeline>
<codeline lineno="625"><highlight class="normal"><sp/><sp/>AT_DISPATCH_ALL_TYPES(</highlight></codeline>
<codeline lineno="626"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>values.type(),<sp/></highlight><highlight class="stringliteral">&quot;addmm_sparse_dense&quot;</highlight><highlight class="normal">,<sp/>[&amp;]<sp/>{</highlight></codeline>
<codeline lineno="627"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s_addmm_out_sparse_dense_worker&lt;scalar_t&gt;(nnz,<sp/>dim_i,<sp/>dim_j,<sp/>dim_k,<sp/>r,<sp/>beta,<sp/>t,<sp/>alpha,<sp/>csr,<sp/>indices,<sp/>values,<sp/>dense);</highlight></codeline>
<codeline lineno="628"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="629"><highlight class="normal"><sp/><sp/>);</highlight></codeline>
<codeline lineno="630"><highlight class="normal"></highlight></codeline>
<codeline lineno="631"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="632"><highlight class="normal"></highlight></codeline>
<codeline lineno="633"><highlight class="normal">}</highlight></codeline>
<codeline lineno="634"><highlight class="normal"></highlight></codeline>
<codeline lineno="635"><highlight class="normal">Tensor<sp/>s_addmm_sparse_dense_cpu(</highlight></codeline>
<codeline lineno="636"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>t,</highlight></codeline>
<codeline lineno="637"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>sparse,</highlight></codeline>
<codeline lineno="638"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>dense,</highlight></codeline>
<codeline lineno="639"><highlight class="normal"><sp/><sp/><sp/><sp/>Scalar<sp/>beta,</highlight></codeline>
<codeline lineno="640"><highlight class="normal"><sp/><sp/><sp/><sp/>Scalar<sp/>alpha</highlight></codeline>
<codeline lineno="641"><highlight class="normal">)<sp/>{</highlight></codeline>
<codeline lineno="642"><highlight class="normal"><sp/><sp/>Tensor<sp/>r<sp/>=<sp/>t.type().tensor();</highlight></codeline>
<codeline lineno="643"><highlight class="normal"><sp/><sp/>s_addmm_out_sparse_dense_cpu(r,<sp/>t,<sp/>sparse,<sp/>dense,<sp/>beta,<sp/>alpha);</highlight></codeline>
<codeline lineno="644"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="645"><highlight class="normal">}</highlight></codeline>
<codeline lineno="646"><highlight class="normal"></highlight></codeline>
<codeline lineno="647"><highlight class="normal">Tensor&amp;<sp/>s_addmm_sparse_dense_cpu_(</highlight></codeline>
<codeline lineno="648"><highlight class="normal"><sp/><sp/><sp/><sp/>Tensor&amp;<sp/>t,</highlight></codeline>
<codeline lineno="649"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>sparse,</highlight></codeline>
<codeline lineno="650"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>dense,</highlight></codeline>
<codeline lineno="651"><highlight class="normal"><sp/><sp/><sp/><sp/>Scalar<sp/>beta,</highlight></codeline>
<codeline lineno="652"><highlight class="normal"><sp/><sp/><sp/><sp/>Scalar<sp/>alpha</highlight></codeline>
<codeline lineno="653"><highlight class="normal">)<sp/>{</highlight></codeline>
<codeline lineno="654"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>s_addmm_out_sparse_dense_cpu(t,<sp/>t,<sp/>sparse,<sp/>dense,<sp/>beta,<sp/>alpha);</highlight></codeline>
<codeline lineno="655"><highlight class="normal">}</highlight></codeline>
<codeline lineno="656"><highlight class="normal"></highlight></codeline>
<codeline lineno="657"><highlight class="normal"></highlight></codeline>
<codeline lineno="658"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="659"><highlight class="normal"></highlight><highlight class="comment">//<sp/>hspmm(SparseTensor<sp/>mat1,<sp/>Tensor<sp/>mat2)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="660"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="661"><highlight class="normal"></highlight></codeline>
<codeline lineno="662"><highlight class="normal">SparseTensor&amp;<sp/>hspmm_out_sparse_cpu(SparseTensor&amp;<sp/>r,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>sparse_,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>dense)<sp/>{</highlight></codeline>
<codeline lineno="663"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>Make<sp/>this<sp/>a<sp/>real<sp/>argument</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="664"><highlight class="normal"><sp/><sp/>Scalar<sp/>alpha<sp/>=<sp/>1;</highlight></codeline>
<codeline lineno="665"><highlight class="normal"></highlight></codeline>
<codeline lineno="666"><highlight class="normal"><sp/><sp/>AT_ASSERT(!sparse_.is_cuda());<sp/></highlight><highlight class="comment">//<sp/>dispatch<sp/>argument</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="667"><highlight class="normal"><sp/><sp/>AT_CHECK(!r.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;hspmm:<sp/>expected<sp/>&apos;out&apos;<sp/>to<sp/>be<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="668"><highlight class="normal"><sp/><sp/>AT_CHECK(!dense.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;hspmm:<sp/>expected<sp/>&apos;other&apos;<sp/>to<sp/>be<sp/>a<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>a<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="669"><highlight class="normal"></highlight></codeline>
<codeline lineno="670"><highlight class="normal"><sp/><sp/>AT_CHECK(sparse_._sparseDims()<sp/>==<sp/>2,</highlight></codeline>
<codeline lineno="671"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;hspmm:<sp/>Argument<sp/>#2:<sp/>matrices<sp/>expected,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>sparse_._sparseDims(),<sp/></highlight><highlight class="stringliteral">&quot;D<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="672"><highlight class="normal"><sp/><sp/>AT_CHECK(sparse_._denseDims()<sp/>==<sp/>0,</highlight></codeline>
<codeline lineno="673"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;hspmm:<sp/>Argument<sp/>#2:<sp/>scalar<sp/>values<sp/>expected,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>sparse_._denseDims(),<sp/></highlight><highlight class="stringliteral">&quot;D<sp/>values&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="674"><highlight class="normal"><sp/><sp/>AT_CHECK(dense.dim()<sp/>==<sp/>2,</highlight></codeline>
<codeline lineno="675"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;hspmm:<sp/>Argument<sp/>#3:<sp/>matrices<sp/>expected,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>dense.dim(),<sp/></highlight><highlight class="stringliteral">&quot;D<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="676"><highlight class="normal"></highlight></codeline>
<codeline lineno="677"><highlight class="normal"><sp/><sp/>int64_t<sp/>m<sp/>=<sp/>sparse_.size(0);</highlight></codeline>
<codeline lineno="678"><highlight class="normal"><sp/><sp/>int64_t<sp/>k<sp/>=<sp/>sparse_.size(1);</highlight></codeline>
<codeline lineno="679"><highlight class="normal"><sp/><sp/>int64_t<sp/>n<sp/>=<sp/>dense.size(1);</highlight></codeline>
<codeline lineno="680"><highlight class="normal"></highlight></codeline>
<codeline lineno="681"><highlight class="normal"><sp/><sp/>AT_CHECK(dense.size(0)<sp/>==<sp/>k,</highlight></codeline>
<codeline lineno="682"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;hspmm:<sp/>Argument<sp/>#3:<sp/>Expected<sp/>dim<sp/>0<sp/>size<sp/>&quot;</highlight><highlight class="normal">,<sp/>k,<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>dense.size(0));</highlight></codeline>
<codeline lineno="683"><highlight class="normal"></highlight></codeline>
<codeline lineno="684"><highlight class="normal"><sp/><sp/>_get_sparse_impl(r)-&gt;raw_resize_(1,<sp/>1,<sp/>{m,<sp/>n});</highlight></codeline>
<codeline lineno="685"><highlight class="normal"></highlight></codeline>
<codeline lineno="686"><highlight class="normal"><sp/><sp/>SparseTensor<sp/>sparse<sp/>=<sp/>sparse_.coalesce();</highlight></codeline>
<codeline lineno="687"><highlight class="normal"></highlight></codeline>
<codeline lineno="688"><highlight class="normal"><sp/><sp/>int64_t<sp/>nnz<sp/>=<sp/>sparse._nnz();</highlight></codeline>
<codeline lineno="689"><highlight class="normal"></highlight></codeline>
<codeline lineno="690"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(nnz<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="691"><highlight class="normal"><sp/><sp/><sp/><sp/>r.zero_();</highlight></codeline>
<codeline lineno="692"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="693"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="694"><highlight class="normal"></highlight></codeline>
<codeline lineno="695"><highlight class="normal"><sp/><sp/>LongTensor<sp/>indices<sp/>=<sp/>at::CPU(kLong).tensor({1,<sp/>nnz});</highlight></codeline>
<codeline lineno="696"><highlight class="normal"></highlight></codeline>
<codeline lineno="697"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Initialize<sp/>the<sp/>sparse<sp/>matrix<sp/>that<sp/>will<sp/>be<sp/>used<sp/>with<sp/>spaddmm<sp/>to<sp/>send<sp/>rows</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="698"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>from<sp/>the<sp/>dense<sp/>matrix<sp/>to<sp/>rows<sp/>of<sp/>the<sp/>output&apos;s<sp/>value<sp/>tensor</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="699"><highlight class="normal"><sp/><sp/>SparseTensor<sp/>newSparse<sp/>=<sp/>sparse.clone();</highlight></codeline>
<codeline lineno="700"><highlight class="normal"><sp/><sp/>LongTensor<sp/>spIndices<sp/>=<sp/>newSparse._indices();</highlight></codeline>
<codeline lineno="701"><highlight class="normal"><sp/><sp/>LongTensor<sp/>valueIndices<sp/>=<sp/>spIndices.select(0,<sp/>0);</highlight></codeline>
<codeline lineno="702"><highlight class="normal"></highlight></codeline>
<codeline lineno="703"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Compute<sp/>output<sp/>indices</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="704"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>valueIndices_accessor<sp/>=<sp/>valueIndices.accessor&lt;int64_t,<sp/>1&gt;();</highlight></codeline>
<codeline lineno="705"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>indices_accessor<sp/>=<sp/>indices.accessor&lt;int64_t,<sp/>2&gt;();</highlight></codeline>
<codeline lineno="706"><highlight class="normal"></highlight></codeline>
<codeline lineno="707"><highlight class="normal"><sp/><sp/>int64_t<sp/>i<sp/>=<sp/>-1,<sp/>prevIdx<sp/>=<sp/>-1;</highlight></codeline>
<codeline lineno="708"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(int64_t<sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;<sp/>nnz;<sp/>j++)<sp/>{</highlight></codeline>
<codeline lineno="709"><highlight class="normal"><sp/><sp/><sp/><sp/>int64_t<sp/>currIdx<sp/>=<sp/>valueIndices_accessor[j];</highlight></codeline>
<codeline lineno="710"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(currIdx<sp/>!=<sp/>prevIdx)<sp/>{</highlight></codeline>
<codeline lineno="711"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>indices_accessor[0][++i]<sp/>=<sp/>currIdx;</highlight></codeline>
<codeline lineno="712"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>prevIdx<sp/>=<sp/>currIdx;</highlight></codeline>
<codeline lineno="713"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="714"><highlight class="normal"><sp/><sp/><sp/><sp/>valueIndices_accessor[j]<sp/>=<sp/>i;</highlight></codeline>
<codeline lineno="715"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="716"><highlight class="normal"><sp/><sp/>int64_t<sp/>outNnz<sp/>=<sp/>i<sp/>+<sp/>1;</highlight></codeline>
<codeline lineno="717"><highlight class="normal"><sp/><sp/>indices.resize_({1,<sp/>outNnz});</highlight></codeline>
<codeline lineno="718"><highlight class="normal"><sp/><sp/>Tensor<sp/>values<sp/>=<sp/>dense.type().tensor({outNnz,<sp/>n});</highlight></codeline>
<codeline lineno="719"><highlight class="normal"><sp/><sp/>_get_sparse_impl(newSparse)-&gt;_sizes_mut()[0]<sp/>=<sp/>outNnz;<sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>use<sp/>something<sp/>safer</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="720"><highlight class="normal"></highlight></codeline>
<codeline lineno="721"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Compute<sp/>output<sp/>values<sp/>tensor<sp/>with<sp/>sparse<sp/>*<sp/>dense<sp/>multiplication</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="722"><highlight class="normal"><sp/><sp/>s_addmm_out_sparse_dense_cpu(values,<sp/>values,<sp/>newSparse,<sp/>dense,<sp/>0,<sp/>alpha);</highlight></codeline>
<codeline lineno="723"><highlight class="normal"><sp/><sp/>_get_sparse_impl(r)-&gt;set_indices_and_values(indices,<sp/>values);<sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>sigh</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="724"><highlight class="normal"></highlight></codeline>
<codeline lineno="725"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="726"><highlight class="normal">}</highlight></codeline>
<codeline lineno="727"><highlight class="normal"></highlight></codeline>
<codeline lineno="728"><highlight class="normal">SparseTensor<sp/>hspmm_sparse_cpu(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>sparse,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>dense)<sp/>{</highlight></codeline>
<codeline lineno="729"><highlight class="normal"><sp/><sp/>SparseTensor<sp/>r<sp/>=<sp/>sparse.type().tensor();</highlight></codeline>
<codeline lineno="730"><highlight class="normal"><sp/><sp/>hspmm_out_sparse_cpu(r,<sp/>sparse,<sp/>dense);</highlight></codeline>
<codeline lineno="731"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="732"><highlight class="normal">}</highlight></codeline>
<codeline lineno="733"><highlight class="normal"></highlight></codeline>
<codeline lineno="734"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="735"><highlight class="normal"></highlight><highlight class="comment">//<sp/>sspaddmm</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="736"><highlight class="normal"></highlight><highlight class="comment">//<sp/>--------------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="737"><highlight class="normal"></highlight></codeline>
<codeline lineno="738"><highlight class="normal">SparseTensor&amp;<sp/>_sspaddmm_out_cpu(</highlight></codeline>
<codeline lineno="739"><highlight class="normal"><sp/><sp/><sp/><sp/>SparseTensor&amp;<sp/>r,</highlight></codeline>
<codeline lineno="740"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>t,</highlight></codeline>
<codeline lineno="741"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SparseTensor&amp;<sp/>sparse_,</highlight></codeline>
<codeline lineno="742"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>dense,</highlight></codeline>
<codeline lineno="743"><highlight class="normal"><sp/><sp/><sp/><sp/>Scalar<sp/>beta,</highlight></codeline>
<codeline lineno="744"><highlight class="normal"><sp/><sp/><sp/><sp/>Scalar<sp/>alpha</highlight></codeline>
<codeline lineno="745"><highlight class="normal">)<sp/>{</highlight></codeline>
<codeline lineno="746"><highlight class="normal"><sp/><sp/>AT_ASSERT(!t.is_cuda());<sp/></highlight><highlight class="comment">//<sp/>dispatch<sp/>argument</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="747"><highlight class="normal"><sp/><sp/>AT_CHECK(!r.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;sspaddmm:<sp/>expected<sp/>&apos;out&apos;<sp/>to<sp/>be<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="748"><highlight class="normal"><sp/><sp/>AT_CHECK(!sparse_.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;sspaddmm:<sp/>expected<sp/>&apos;mat1&apos;<sp/>to<sp/>be<sp/>a<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>a<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="749"><highlight class="normal"><sp/><sp/>AT_CHECK(!dense.is_cuda(),<sp/></highlight><highlight class="stringliteral">&quot;sspaddmm:<sp/>expected<sp/>&apos;mat2&apos;<sp/>to<sp/>be<sp/>a<sp/>CPU<sp/>tensor,<sp/>but<sp/>got<sp/>a<sp/>CUDA<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="750"><highlight class="normal"></highlight></codeline>
<codeline lineno="751"><highlight class="normal"><sp/><sp/>AT_CHECK(sparse_._sparseDims()<sp/>==<sp/>2,</highlight></codeline>
<codeline lineno="752"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;sspaddmm:<sp/>Argument<sp/>#2:<sp/>matrices<sp/>expected,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>sparse_._sparseDims(),<sp/></highlight><highlight class="stringliteral">&quot;D<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="753"><highlight class="normal"><sp/><sp/>AT_CHECK(sparse_._denseDims()<sp/>==<sp/>0,</highlight></codeline>
<codeline lineno="754"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;sspaddmm:<sp/>Argument<sp/>#2:<sp/>scalar<sp/>values<sp/>expected,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>sparse_._denseDims(),<sp/></highlight><highlight class="stringliteral">&quot;D<sp/>values&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="755"><highlight class="normal"><sp/><sp/>AT_CHECK(dense.dim()<sp/>==<sp/>2,</highlight></codeline>
<codeline lineno="756"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;sspaddmm:<sp/>Argument<sp/>#2:<sp/>matrices<sp/>expected,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>dense.dim(),<sp/></highlight><highlight class="stringliteral">&quot;D<sp/>tensor&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="757"><highlight class="normal"></highlight></codeline>
<codeline lineno="758"><highlight class="normal"><sp/><sp/>SparseTensor<sp/>sparse<sp/>=<sp/>sparse_.coalesce();</highlight></codeline>
<codeline lineno="759"><highlight class="normal"></highlight></codeline>
<codeline lineno="760"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>ixj<sp/>*<sp/>jxk<sp/>=<sp/>ixk</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="761"><highlight class="normal"><sp/><sp/>int64_t<sp/>dim_i<sp/>=<sp/>sparse.size(0);</highlight></codeline>
<codeline lineno="762"><highlight class="normal"><sp/><sp/>int64_t<sp/>dim_j<sp/>=<sp/>sparse.size(1);</highlight></codeline>
<codeline lineno="763"><highlight class="normal"><sp/><sp/>int64_t<sp/>dim_k<sp/>=<sp/>dense.size(1);</highlight></codeline>
<codeline lineno="764"><highlight class="normal"></highlight></codeline>
<codeline lineno="765"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>NB:<sp/>This<sp/>has<sp/>to<sp/>occur<sp/>before<sp/>the<sp/>checks,<sp/>because<sp/>r<sp/>may<sp/>alias<sp/>t.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="766"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>See<sp/>test_saddmm</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="767"><highlight class="normal"><sp/><sp/>r.sparse_raw_resize_({dim_i,<sp/>dim_k},<sp/>2,<sp/>0);</highlight></codeline>
<codeline lineno="768"><highlight class="normal"></highlight></codeline>
<codeline lineno="769"><highlight class="normal"><sp/><sp/>AT_CHECK(dense.size(0)<sp/>==<sp/>dim_j,</highlight></codeline>
<codeline lineno="770"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;sspaddmm:<sp/>Argument<sp/>#3:<sp/>Expected<sp/>dim<sp/>0<sp/>size<sp/>&quot;</highlight><highlight class="normal">,<sp/>dim_j,<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>dense.size(0));</highlight></codeline>
<codeline lineno="771"><highlight class="normal"><sp/><sp/>AT_CHECK(t.size(0)<sp/>==<sp/>dim_i,</highlight></codeline>
<codeline lineno="772"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;sspaddmm:<sp/>Argument<sp/>#1:<sp/>Expected<sp/>dim<sp/>0<sp/>size<sp/>&quot;</highlight><highlight class="normal">,<sp/>dim_i,<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>t.size(0));</highlight></codeline>
<codeline lineno="773"><highlight class="normal"><sp/><sp/>AT_CHECK(t.size(1)<sp/>==<sp/>dim_k,</highlight></codeline>
<codeline lineno="774"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;sspaddmm:<sp/>Argument<sp/>#1:<sp/>Expected<sp/>dim<sp/>1<sp/>size<sp/>&quot;</highlight><highlight class="normal">,<sp/>dim_k,<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>got<sp/>&quot;</highlight><highlight class="normal">,<sp/>t.size(1));</highlight></codeline>
<codeline lineno="775"><highlight class="normal"></highlight></codeline>
<codeline lineno="776"><highlight class="normal"><sp/><sp/>int64_t<sp/>nnz<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>=<sp/>sparse._nnz();</highlight></codeline>
<codeline lineno="777"><highlight class="normal"><sp/><sp/>LongTensor<sp/>indices<sp/>=<sp/>sparse._indices();</highlight></codeline>
<codeline lineno="778"><highlight class="normal"><sp/><sp/>Tensor<sp/>values<sp/><sp/><sp/><sp/><sp/><sp/>=<sp/>sparse._values();</highlight></codeline>
<codeline lineno="779"><highlight class="normal"></highlight></codeline>
<codeline lineno="780"><highlight class="normal"><sp/><sp/>LongTensor<sp/>csr<sp/>=<sp/>_to_csr(indices.data&lt;int64_t&gt;(),<sp/>dim_i,<sp/>nnz);</highlight></codeline>
<codeline lineno="781"><highlight class="normal"></highlight></codeline>
<codeline lineno="782"><highlight class="normal"><sp/><sp/>int64_t<sp/>t_nnz<sp/>=<sp/>t._nnz();</highlight></codeline>
<codeline lineno="783"><highlight class="normal"><sp/><sp/>int64_t<sp/>r_nnz<sp/>=<sp/>nnz<sp/>*<sp/>dim_k<sp/>+<sp/>t_nnz;</highlight></codeline>
<codeline lineno="784"><highlight class="normal"><sp/><sp/>LongTensor<sp/>newi<sp/>=<sp/>native::empty({2,<sp/>r_nnz},<sp/>kLong);</highlight></codeline>
<codeline lineno="785"><highlight class="normal"><sp/><sp/>LongTensor<sp/>newv<sp/>=<sp/>native::zeros({r_nnz},<sp/>values.options());</highlight></codeline>
<codeline lineno="786"><highlight class="normal"></highlight></codeline>
<codeline lineno="787"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(t_nnz<sp/>!=<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="788"><highlight class="normal"><sp/><sp/><sp/><sp/>LongTensor<sp/>narrowi<sp/>=<sp/>newi.narrow(1,<sp/>0,<sp/>t_nnz);</highlight></codeline>
<codeline lineno="789"><highlight class="normal"><sp/><sp/><sp/><sp/>Tensor<sp/>narrowv<sp/>=<sp/>newv.narrow(0,<sp/>0,<sp/>t_nnz);</highlight></codeline>
<codeline lineno="790"><highlight class="normal"></highlight></codeline>
<codeline lineno="791"><highlight class="normal"><sp/><sp/><sp/><sp/>narrowi.copy_(t._indices());</highlight></codeline>
<codeline lineno="792"><highlight class="normal"><sp/><sp/><sp/><sp/>narrowv.copy_(t._values());</highlight></codeline>
<codeline lineno="793"><highlight class="normal"><sp/><sp/><sp/><sp/>newv.mul_(beta);</highlight></codeline>
<codeline lineno="794"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="795"><highlight class="normal"></highlight></codeline>
<codeline lineno="796"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>sparse<sp/>=<sp/>sparse<sp/>*<sp/>dense</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="797"><highlight class="normal"><sp/><sp/>int64_t<sp/>p<sp/>=<sp/>t_nnz;</highlight></codeline>
<codeline lineno="798"><highlight class="normal"></highlight></codeline>
<codeline lineno="799"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>csr_accessor<sp/>=<sp/>csr.accessor&lt;int64_t,<sp/>1&gt;();</highlight></codeline>
<codeline lineno="800"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>indices_accessor<sp/>=<sp/>indices.accessor&lt;int64_t,<sp/>2&gt;();</highlight></codeline>
<codeline lineno="801"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>newi_accessor<sp/>=<sp/>newi.accessor&lt;int64_t,<sp/>2&gt;();</highlight></codeline>
<codeline lineno="802"><highlight class="normal"></highlight></codeline>
<codeline lineno="803"><highlight class="normal"><sp/><sp/>int64_t<sp/>dense_stride0<sp/>=<sp/>dense.stride(0);</highlight></codeline>
<codeline lineno="804"><highlight class="normal"><sp/><sp/>int64_t<sp/>dense_stride1<sp/>=<sp/>dense.stride(1);</highlight></codeline>
<codeline lineno="805"><highlight class="normal"><sp/><sp/>int64_t<sp/>newv_stride0<sp/>=<sp/>newv.stride(0);</highlight></codeline>
<codeline lineno="806"><highlight class="normal"></highlight></codeline>
<codeline lineno="807"><highlight class="normal"><sp/><sp/>AT_DISPATCH_ALL_TYPES(</highlight></codeline>
<codeline lineno="808"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>values.type(),<sp/></highlight><highlight class="stringliteral">&quot;sspmm&quot;</highlight><highlight class="normal">,<sp/>[&amp;]<sp/>{</highlight></codeline>
<codeline lineno="809"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>values_accessor<sp/>=<sp/>values.accessor&lt;scalar_t,<sp/>1&gt;();</highlight></codeline>
<codeline lineno="810"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scalar_t*<sp/>dense_ptr<sp/>=<sp/>dense.data&lt;scalar_t&gt;();</highlight></codeline>
<codeline lineno="811"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scalar_t*<sp/>newv_ptr<sp/>=<sp/>newv.data&lt;scalar_t&gt;();</highlight></codeline>
<codeline lineno="812"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scalar_t<sp/>cast_alpha<sp/>=<sp/>alpha.to&lt;scalar_t&gt;();</highlight></codeline>
<codeline lineno="813"><highlight class="normal"></highlight></codeline>
<codeline lineno="814"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(int64_t<sp/>h<sp/>=<sp/>0;<sp/>h<sp/>&lt;<sp/>dim_i;<sp/>h++)<sp/>{</highlight></codeline>
<codeline lineno="815"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>int64_t<sp/>i_start<sp/>=<sp/>csr_accessor[h];</highlight></codeline>
<codeline lineno="816"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>int64_t<sp/>i_end<sp/>=<sp/>csr_accessor[h+1];</highlight></codeline>
<codeline lineno="817"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(int64_t<sp/>i<sp/>=<sp/>i_start;<sp/>i<sp/>&lt;<sp/>i_end;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="818"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scalar_t<sp/>val<sp/>=<sp/>values_accessor[i];</highlight></codeline>
<codeline lineno="819"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>int64_t<sp/>col<sp/>=<sp/>indices_accessor[1][i];</highlight></codeline>
<codeline lineno="820"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(col<sp/>&gt;=<sp/>0<sp/>&amp;&amp;<sp/>col<sp/>&lt;<sp/>dim_j)<sp/>{</highlight></codeline>
<codeline lineno="821"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>THBlas_axpy&lt;scalar_t&gt;(dim_k,</highlight></codeline>
<codeline lineno="822"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cast_alpha<sp/>*<sp/>val,</highlight></codeline>
<codeline lineno="823"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dense_ptr<sp/>+<sp/>col<sp/>*<sp/>dense_stride0,<sp/>dense_stride1,</highlight></codeline>
<codeline lineno="824"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>newv_ptr<sp/>+<sp/>p<sp/>*<sp/>newv_stride0,<sp/>1);</highlight></codeline>
<codeline lineno="825"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="826"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>AT_ERROR(</highlight><highlight class="stringliteral">&quot;index<sp/>out<sp/>of<sp/>bound.<sp/>sspmm:<sp/>&quot;</highlight><highlight class="normal">,<sp/>col,<sp/></highlight><highlight class="stringliteral">&quot;<sp/>not<sp/>between<sp/>1<sp/>and<sp/>&quot;</highlight><highlight class="normal">,<sp/>dim_j);</highlight></codeline>
<codeline lineno="827"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="828"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="829"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Fill<sp/>up<sp/>the<sp/>indices<sp/>with<sp/>the<sp/>right<sp/>values</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="830"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(i_start<sp/>!=<sp/>i_end)<sp/>{</highlight></codeline>
<codeline lineno="831"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(int64_t<sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>dim_k;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="832"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>newi_accessor[0][p+i]<sp/>=<sp/>h;</highlight></codeline>
<codeline lineno="833"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>newi_accessor[1][p+i]<sp/>=<sp/>i;</highlight></codeline>
<codeline lineno="834"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="835"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>p<sp/>+=<sp/>dim_k;</highlight></codeline>
<codeline lineno="836"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="837"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="838"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="839"><highlight class="normal"><sp/><sp/>);</highlight></codeline>
<codeline lineno="840"><highlight class="normal"></highlight></codeline>
<codeline lineno="841"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>to<sp/>avoid<sp/>a<sp/>clone</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="842"><highlight class="normal"><sp/><sp/>_get_sparse_impl(r)-&gt;set_indices(newi);</highlight></codeline>
<codeline lineno="843"><highlight class="normal"><sp/><sp/>_get_sparse_impl(r)-&gt;set_values(newv);</highlight></codeline>
<codeline lineno="844"><highlight class="normal"><sp/><sp/>_get_sparse_impl(r)-&gt;set_nnz(p);</highlight></codeline>
<codeline lineno="845"><highlight class="normal"></highlight></codeline>
<codeline lineno="846"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>r;</highlight></codeline>
<codeline lineno="847"><highlight class="normal">}</highlight></codeline>
<codeline lineno="848"><highlight class="normal"></highlight></codeline>
<codeline lineno="849"><highlight class="normal"></highlight><highlight class="comment">//<sp/>sparse,<sp/>sparse,<sp/>sparse,<sp/>dense,<sp/>real,<sp/>real<sp/>-&gt;<sp/>sparse</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="850"><highlight class="normal">Tensor&amp;<sp/>_sspaddmm_out_only_sparse(Tensor&amp;<sp/>result,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/></highlight><highlight class="keyword">self</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="851"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>mat1,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>mat2,<sp/>Scalar<sp/>beta,<sp/>Scalar<sp/>alpha)<sp/>{</highlight></codeline>
<codeline lineno="852"><highlight class="normal"><sp/><sp/>AT_ERROR(</highlight><highlight class="stringliteral">&quot;tensor.sspaddmm(...)<sp/>can<sp/>only<sp/>be<sp/>called<sp/>on<sp/>sparse<sp/>tensors&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="853"><highlight class="normal">}</highlight></codeline>
<codeline lineno="854"><highlight class="normal"></highlight></codeline>
<codeline lineno="855"><highlight class="normal"></highlight><highlight class="comment">//<sp/>sparse,<sp/>dense<sp/>-&gt;<sp/>sparse</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="856"><highlight class="normal">Tensor<sp/>smm(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/></highlight><highlight class="keyword">self</highlight><highlight class="normal">,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>mat2)<sp/>{</highlight></codeline>
<codeline lineno="857"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>result<sp/>=<sp/></highlight><highlight class="keyword">self</highlight><highlight class="normal">.type().tensor();</highlight></codeline>
<codeline lineno="858"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">self</highlight><highlight class="normal">.type().sspaddmm_out(result,<sp/>result,<sp/></highlight><highlight class="keyword">self</highlight><highlight class="normal">,<sp/>mat2,<sp/>0.0,<sp/>1.0);</highlight></codeline>
<codeline lineno="859"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>result;</highlight></codeline>
<codeline lineno="860"><highlight class="normal">}</highlight></codeline>
<codeline lineno="861"><highlight class="normal"></highlight></codeline>
<codeline lineno="862"><highlight class="normal"></highlight><highlight class="comment">//<sp/>sparse,<sp/>sparse,<sp/>dense,<sp/>real,<sp/>real<sp/>-&gt;<sp/>sparse</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="863"><highlight class="normal">Tensor<sp/>sspaddmm(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/></highlight><highlight class="keyword">self</highlight><highlight class="normal">,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>mat1,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>Tensor&amp;<sp/>mat2,</highlight></codeline>
<codeline lineno="864"><highlight class="normal"><sp/><sp/><sp/><sp/>Scalar<sp/>beta,<sp/>Scalar<sp/>alpha)<sp/>{</highlight></codeline>
<codeline lineno="865"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>result<sp/>=<sp/></highlight><highlight class="keyword">self</highlight><highlight class="normal">.type().tensor();</highlight></codeline>
<codeline lineno="866"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">self</highlight><highlight class="normal">.type().sspaddmm_out(result,<sp/></highlight><highlight class="keyword">self</highlight><highlight class="normal">,<sp/>mat1,<sp/>mat2,<sp/>beta,<sp/>alpha);</highlight></codeline>
<codeline lineno="867"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>result;</highlight></codeline>
<codeline lineno="868"><highlight class="normal">}</highlight></codeline>
<codeline lineno="869"><highlight class="normal"></highlight></codeline>
<codeline lineno="870"><highlight class="normal">}}<sp/></highlight><highlight class="comment">//<sp/>namespace<sp/>at::native</highlight><highlight class="normal"></highlight></codeline>
    </programlisting>
    <location file="/Users/robkunkle/fork/goodlux/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp"/>
  </compounddef>
</doxygen>
